[{"id":0,"href":"/docs/SE/hugo/hello/","title":"Hello GitHub","section":"Hugo Tips","content":" github 에서 블로그 만들기 # hugo 로컬 빌드를 해서 public 을 submodule 으로 다른 repo 에 push 하는 방식 대신,\ngithub action 을 이용하여 1개 repo에서 main 을 빌드 후 gh-pages 브랜치로 deploy 하는 방식 사용\n아래 관련 지식 보유 가정\n기본 적인 SSG (Static Site Generator) Brew, Git, GitHub, VSCode, Hugo 설치 및 사용 방법 (Mac) Markdown, YAML, Mermaid 등 Editor : Scrivener, VSCode (Markdown) SSG : HUGO (theme : hugo-book) REPO : github (github.com/smjune/smjune.github.io),\ngitlab (backup : gitlab.com/smjune/smjune.gitlab.io) WEB hosting : smjune.github.io (GitHub Pages) Project Settings | Pages | Build and Deploy | branches : gh-pages 설정 로컬에서는 \u0026lsquo;hugo server\u0026rsquo; 을 이용하여 확인 후 push 함 Build \u0026amp; Deploy : github actions / gitlab CI/CD github pages 만들기 # https://docs.github.com/en/pages/\ngithub pages 종류 # 1. 개인/ORG github Pages 2. 프로젝트 github Pages flowchart LR; A[Create a blog with git]--\u003eB{is it a Personal or ORG?}; classDef white color:#022e1f,fill:#fff; classDef black color:#fff,fill:#000; B--YES--\u003eC[\"Personal or ORG\\n https://ACCOUNT.gitxxx.io/\"]:::white; C--blog only--\u003eE[\"Personal \u0026 Hugo Project\\n : git과 hugo가 동일 root\"]; C--project \u0026 blog--\u003eF[\"Personal \u0026 git project\\n : git하위 sorce, hugo 폴더 존재\"]; B--NO--\u003eD[\"Code Project\\n https://ACCOUNT.gitxxx.io/PROJECT\"]:::black; D--project = hugo--\u003eG[\"Code Project \u0026 Hug Project\\n git과 hugo가 동일 root\"]; D--project \u0026 hugo--\u003eH[\"Code Project \u0026 Hug Project\\n git하위 source, hugo 폴더 존재\"]; 1. 개인 Page (Blog) : UserAccont.github.io # Base URL : https://UserAccount.github.io/\nRepo 주소 : https://github.com/UserAccount/UserAccount.github.io.git\n해당 repo 는 pages 을 위한 repo 이므로 hugo project = git project 으로 생성한다. $ hugo new site hugo_project $ cd hugo_project $ git init $ git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke $ echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; config.toml // edit BaseURL and title $ hugo new posts/sample.md // edit sample.md $ hugo server // Be sure it works. if not, correct it $ git remote add origin https://github.com/UserAccount/UserAccount.github.io.git $ git add . $ git commit -m \u0026#39;initiate project\u0026#39; $ git push origin main // browse https://UserAccount.github.io/ 폴더 구조\nhugo project 을 git (github) 로 관리한다고 생각하면 된다.\nproject root 에서 hugo 와 git 명령어를 사용할 수 있다.\nproject folder (git, hugo) ├─.git ├─.gitmodules ├─.github │ └─workflows │ └─gh-pages.yml ├─congif.toml ├─themes │ └─themes folder (submodule) ├─content │ ├─posts │ │ ├─main.md │ │ └─... │ └─... ├─... └─readme.md Created from https://arthursonzogni.com/Diagon/#Tree\n2. 프로젝트 Page (Blog) UserAccont.github.io/Project # Base URL : https://UserAccount.github.io/Project\nRepo 주소 : https://github.com/UserAcount/Project.git\n해당 repo 는 git 프로젝트 안에 source code 와 hugo 을 포함한다. // 기존 git project 에서 $ hugo new site hugo_project $ cd hugo_project $ git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke $ echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; config.toml // edit BaseURL and title $ hugo new posts/sample.md // edit sample.md $ hugo server // Be sure it works. if not, correct it $ cd .. $ git add . $ git commit -m \u0026#39;initiate project\u0026#39; $ git push origin main // browse https://UserAccount.github.io/Project 폴더 구조\n프로젝트의 main branch 기본구조는 아래와 같이 구성된다.\n프로젝트는 source code folder와 hugo 폴더를 갖는다.\n따라서 git 명령어는 project root 에서, hugo 명령어는 hugo 폴더로 이동후 사용한다.\npages 을 deploy 하는 github action 은 .github/workflows/gh-pages.yml 이다.\nhugo folder 는 \u0026rsquo; $ hugo new site hugo \u0026rsquo; 로 생성한다.\ntheme 는 \u0026rsquo; $ git submodule add [submoduel.git] themes/[theme name] \u0026rsquo;\n각 page 는 \u0026rsquo; $ hugo new xxx/xxx.md \u0026rsquo; 로 생성한다.\n프로젝트 gh-pages 브랜치는 hugo 가 빌드된 Web Site (html) 만 존재한다.\nproject folder (git) ├─.git ├─.gitmodules ├─.github │ └─workflows │ └─gh-pages.yml ├─Source Code folder │ ├─lib │ │ ├─utillib.lib │ │ └─... │ ├─build │ │ ├─.buildscript │ │ └─... │ ├─main.cpp │ └─... ├─hugo project folder (hugo) │ ├─congif.toml │ ├─themes │ │ └─themes folder (submodule) │ ├─content │ │ ├─posts │ │ │ ├─main.md │ │ │ └─... │ │ └─... │ └─... ├─... └─readme.md Created from https://arthursonzogni.com/Diagon/#Tree\n\u0026#x1f4a1; Idea\nbranch 으로 구분하는 방법도 생각해 보았으나, (main, hugo, gh-pages)\n- main branch : soure code 파일 만 존재\n- hugo branch : hugo project 파일만 존재\n- gh-pasges branch : hugo build 결과 (html) 파일만 존재\n동일한 수정에 대한 commit 을 main 브랜치 (source code 수정) 와\nhugo 브랜치 (page 수정 ) 에 각각 1번씩 총 2번을 수행해야 하므로 보류\n3. GitHub Actions to build and deploy the hugo project # .github/workflows/gh-pages.yml 생성 \u0026#x1f4dd; 사용한는 GitHub Actions\nactions/checkout@v3\npeaceiris/actions-hugo\npeaceiris/actions-gh-pages\n- uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.110.0\u0026#39; # 혹은 \u0026#39;latest\u0026#39; https://github.com/peaceiris/actions-gh-pages\n작성시 주의 할 점\nproject page 인 경우, hugo 프로젝트가 git 프로젝트 하위로 설정 되어 있으므로\n1. hugo 업데이트 일때만 pages workflow 실행\n2. hugo 폴더로 이동하여 hugo 명령어 사용\n을 명확하게 구분하여야 한다.\non: push: # branches: # - main # Set a branch to deploy paths: - \u0026#39;.github/workflows/gh-pages.yml\u0026#39; // olny deploy when workflow and hugo folder are updated. - \u0026#39;Hugo/**\u0026#39; ... - name: Build run: | cd hugo_project // hugo 프로젝트로 이동 hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v. if: ${{ github.ref == \u0026#39;refs/heads/main\u0026#39; }} // branch 확인 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./hugu_project/public // hugo project 하위 public 폴더 사용 ... push 을 main 으로 설정할 경우, 2개 (CI 와 Github Pages) workflow 실행이 되는 것을\npaths 로 설정하여 hugo 폴더 업데이트 때 Github Pages workflow 만 실행되도록 변경\n4. local branch and remote # Hello_world$ git branch -avv * main bcb809a [github/main] change name of .gitlab-ci remotes/github/gh-pages 309c2bd deploy: 41dfa412c2cd0ebdfd7675d7bd4604b8a07761bb remotes/github/main bcb809a change name of .gitlab-ci remotes/gitlab/main bcb809a change name of .gitlab-ci Hello_world$ _ /labmain 과 gitlab/labmain 은 삭제/\nmain 은 remote 로 github (github.com/smjune/smjung.github.io) 의 main 브랜치를 트랙킹 git push github main, git fetch, git pull remote 로 gitlab (gitlab.com/smjune/smjune.gitlab.io) main 도 등록되어 있으므로 git push gitlab main 5. 최종 작업 순서 # sequenceDiagram participant gitlab participant Local participant github links gitlab: {\"pages\": \"https://smjune.gitlab.io/\"} links github: {\"Pages\": \"https:/smjjune.github.io/\"} loop main job github--\u003e\u003eLocal: fetch (github) Local-\u003e\u003eLocal: edit a page on Hugo Local-\u003e\u003eLocal: add and commit on .git Local-\u003e\u003egithub: Push (github main) end Local-\u003e\u003egitlab: push gitlab main github--\u003e\u003eLocal: fetch (github) github-\u003e\u003egithub: edit a page on GitHub WEB UI github--\u003e\u003eLocal: fetch (github) github-\u003e\u003eLocal: pull (github main) Local-\u003e\u003egitlab: push gitlab main git fetch # 수정 하기 전에 항상 remote 을 받아서 local 을 업데이트 하자.\n(해당 로컬이 아닌 다른 로컬에서 업데이트 했을 수 있음)\n\u0026#x26a0;\u0026#xfe0f; pull 을 하지말고, fetch 로 현재 로컬과 리모트가 gap 이 있는지 확인 한후 pull 을 수행하여야 한다.\ngit status # Hello_world$ git status On branch main Your branch is up to date with \u0026#39;github/main\u0026#39;. Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: content/posts/gitlab.md no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) git add . # Hello_world$ git add . Hello_world$ git commit -m \u0026#39;update way to push\u0026#39; [main d7c0db2] update way to push Committer: myoungjune sung \u0026lt;myoungjunesung@myoungjune-sung-ui-iMac.local\u0026gt; Your name and email address were configured automatically based on your username and hostname. Please check that they are accurate. You can suppress this message by setting them explicitly. Run the following command and follow the instructions in your editor to edit your configuration file: git config --global --edit After doing this, you may fix the identity used for this commit with: git commit --amend --reset-author 1 file changed, 26 insertions(+), 1 deletion(-) git push (github main) # \u0026#x26a0;\u0026#xfe0f; github 을 origin remote 로 등록한 경우 git push 만 사용함.\nHello_world$ git push github main Enumerating objects: 11, done. Counting objects: 100% (11/11), done. Delta compression using up to 2 threads Compressing objects: 100% (5/5), done. Writing objects: 100% (6/6), 1.11 KiB | 1.11 MiB/s, done. Total 6 (delta 3), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (3/3), completed with 3 local objects. To https://github.com/smjune/smjune.github.io.git 2b0d320..d7c0db2 main -\u0026gt; main git push gitlab main # \u0026#x26a0;\u0026#xfe0f; 백업용으로 가끔 잊지 말고 push\nHello_world$ git push gitlab main Enumerating objects: 11, done. Counting objects: 100% (11/11), done. Delta compression using up to 2 threads Compressing objects: 100% (5/5), done. Writing objects: 100% (6/6), 1.11 KiB | 1.11 MiB/s, done. Total 6 (delta 3), reused 0 (delta 0), pack-reused 0 To https://gitlab.com/smjune/smjune.gitlab.io.git 2b0d320..d7c0db2 main -\u0026gt; main Hello_world$ git branch -avv * main d7c0db2 [github/main] update way to push remotes/github/gh-pages 309c2bd deploy: 41dfa412c2cd0ebdfd7675d7bd4604b8a07761bb remotes/github/main d7c0db2 update way to push remotes/gitlab/main d7c0db2 update way to push Hello_world$ 아래 github repo 에 Hello World 폴더가 있다.\nMy GIT HUB Repo 테마마다 설정값이 다르다. PaperMode 의 경우, front matter 로 설정한다.\n자세한것은 PaperMode 설정값 을 참조 한다.\n"},{"id":1,"href":"/docs/ENG/daily/","title":"Daily","section":"Eng.logging","content":"일일 영어 공부\n"},{"id":2,"href":"/docs/ENG/daily/daily1/","title":"Daily1","section":"Daily","content":"dialy 1\n"},{"id":3,"href":"/docs/","title":"Docs.logging","section":"Introduction","content":" 주요 작업 정리 (왼쪽 메뉴 사용) # "},{"id":4,"href":"/docs/ENG/grammarly/","title":"Grammarly","section":"Eng.logging","content":"주요 영어 문법 정리\n"},{"id":5,"href":"/docs/SE/hugo/book/","title":"Hugo-book Theme","section":"Hugo Tips","content":" Hugo-book 주요 사이트 # 기본 사이트 : https://themes.gohugo.io/themes/hugo-book/\nsample site : https://hugo-book-demo.netlify.app/\nRepository : https://github.com/alex-shpak/hugo-book\ndocs 폴더의 하위 폴더 기준으로 메뉴구성을 해 준다. 그 외 폴더 (예: Posts) 는 hugo.yml, 혹은 front matter 에 \u0026lsquo;menu\u0026rsquo; 로 별도 구성해야 한다. 해당 폴더에서 하위 폴더 구조를 지원하지 않는 이유는 뭘까? ( 다단계 구조 불가 ) - 2025.4.12 submodule update $ git submodule update \u0026ndash;init\n$ git submodule update \u0026ndash;remote \u0026ndash;merge\nhugo.yml for hugo-book # hugo-book 샘플 hugo.yml\n지금 사이트 설정 (yml, toml, json 지원) baseURL: https://smjune.github.io/ title: MyoungJune Sung says Hello Wrold theme: hugo-book # Book configuration disablePathToLower: true enableGitInfo: true # Set with \u0026#34;BookRepo\u0026#34; to used for \u0026#39;Last Modified\u0026#39; links. enableEmoji: true # use Emoji # Needed for mermaid/katex shortcodes markup: goldmark: renderer: unsafe: true tableOfContents: startLevel: 1 menu: # before: [] after: - name: \u0026#34;Github Repo\u0026#34; url: \u0026#34;https://github.com/smjune/\u0026#34; weight: 10 - name: \u0026#34;Powered by Hugo\u0026#34; url: \u0026#34;https://gohugo.io/\u0026#34; weight: 20 - name: \u0026#34;and hugo-book\u0026#34; url: \u0026#34;https://themes.gohugo.io/hugo-book//\u0026#34; weight: 30 params: # (Optional, default light) Sets color theme: light, dark or auto. # Theme \u0026#39;auto\u0026#39; switches between dark and light modes based on browser/os preferences BookTheme: \u0026#34;auto\u0026#34; # Set source repository location. # Used for \u0026#39;Last Modified\u0026#39; and \u0026#39;Edit this page\u0026#39; links. BookRepo: https://github.com/smjune/smjune.github.io # Configure the date format used on the pages # - In git information # - In blog posts BookDateFormat: \u0026#34;January 2, 2006\u0026#34; # (Optional, default none) Set the path to a logo for the book. If the logo is # /static/logo.png then the path would be \u0026#39;logo.png\u0026#39; # https://github.com/alex-shpak/hugo-book/pull/442 BookLogo : \u0026#39;logo.png\u0026#39; # you can add more option here \u0026#x1f44d; enableEmoji : true\nEmoji list Pages Front matter # 각 pages (md 파일) 에서 pages 에 대한 설정값을 조정한다.\n--- title: \u0026#34;Theme\u0026#34; weight: 1 # 메뉴에서 표시되는 순서 1 = 최우선 # bookFlatSection: false # bookToc: true # Table Of Content 표시 PaperMode에서 주로 사용 # bookHidden: false # bookCollapseSection: false # 메뉴에 하위 페이지가 있는 경우, 접힘표시 # bookComments: false # 해당 페이지의 comment 활성화 설정 (hugo.yml 설정보다 우선) # bookSearchExclude: false --- Categories \u0026amp; Tages # 각 페이지에서 해당 페이지에 대한 category 와 Tags 을 설정\nCategories: \u0026#34;Posted\u0026#34; Tags: [\u0026#34;Big Data\u0026#34;,\u0026#34;한글\u0026#34;,\u0026#34;Minority\u0026#34;,] 혹은\n+++ title = \u0026#34;iMAC, Late 2009 upgrade\u0026#34; description = \u0026#34;맥 업그레이드 관련 기록 저장, 테스트 페이지\u0026#34; tags = [ \u0026#34;iMac\u0026#34;, \u0026#34;Scrivener\u0026#34;, \u0026#34;Hi Sierra\u0026#34;, ] date = \u0026#34;2023-02-17T22:02:05+09:00\u0026#34; categories = [ \u0026#34;Mac\u0026#34;, ] BookComments=true +++ Blog thumbnail image # add Frontmatter\n\u0026#x1f4a1; blog 용 폴더에서 사용 (예: posts)\n--- image : /posts/images/xxx.image --- \u0026#x1f198; hugo-book QnA\n- 2025.4.16 [Feature] Image thumbnails for posts? · Issue #286 · alex-shpak/hugo-book\n\\themes\\hugo-book\\layouts\\partials\\docs\\post-meta.html 파일을.\n\\layouts\\partials\\docs\\post-meta.html 으로 복사하여. 아래 코드를 추가 해야 함.\n{{ with .Params.image }} \u0026lt;img src={{ . | relURL }} /\u0026gt; {{ end }} Customizing # Get image Center of pages # create $PROJECT/assets/_custom.scss add the following code into file .markdown img { display: block; margin-left: auto; margin-right: auto; max-width: 100%; height: auto; } \u0026#x1f198; hugo-book QnA\nShortcode # 각 페이지에서 사용할 다양한 문단 효과, 아래와 같은 형식으로 사용한다.\n자세한 내용은 샘플 사이트를 참고\n2025.04.12\n{{{\u0026lt; hint \u0026gt;}}}으로 사용하는 걸 {{{% hint %}}}으로 변경해야 함. section shortcode는 주로 페이지 목록 등을 표시하는 구조적인 용도로 사용되며, 내부 컨텐츠를 Markdown으로 렌더링할 필요가 없는 경우가 많음. 따라서 변경하지 않는 것이 안전.\nmermaid shortcode는 내부의 Mermaid 문법을 사용하여 다이어그램을 렌더링하여 Markdown 렌더링과는 별개이므로 변경할 필요가 없음.\n{{\u0026lt; \u0026#34;Shortcode name\u0026#34; \u0026gt;}} 내용 ... {{\u0026lt; /\u0026#34;Shortcode name\u0026#34; \u0026gt;}} Hint # info/warning/danger 로 색 구분 (파랑/노랑/빨강) 지원\n{{\u0026lt; hint [ info | warning | danger ] \u0026gt;}} 내용 ... {{\u0026lt; /hint \u0026gt;}} Details # 확장 되는 문단 표시 (expand 을 사용하는 대신) open 옵션을 사용할 경우 항상 확장된 형태로 표시 됨\n{{\u0026lt; details [ open ] \u0026gt;}} 내용 ... {{\u0026lt; /details \u0026gt;}} Mermaid # hugo.yml 에서 marmain 사용을 위해 \u0026ldquo;markup\u0026rdquo; 설정을 해야 한다.\nMermaid Docs\nMermaid live\nhugo 에서 제공하는 방식을 미리 theme에서 수정하였으므로, Theme방식을 따라야 한다.\n{{\u0026lt; mermaid [class=\u0026#34;text-center\u0026#34;] \u0026gt;}} Mermaid syntex 내용 ... {{\u0026lt; /mermaid \u0026gt;}} Section # 하위 폴더 내용을 간략하게 표시해 준다.\n{{\u0026lt; section \u0026gt;}} 2025.4.26 build 시 warning : section sortcode deprecated 됨.\nhugo v0.147.0+extended+withdeploy darwin/arm64 BuildDate=2025-04-25T15:26:28Z VendorInfo=brew WARN Section shortcode is deprecated and will be removed Deprecated section shorcode commit\nColumns # 한 페이지에 문단을 나눠서 표시 해둔다.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Tabs # 하나의 문단을 tab으로 구분하여 표시 해준다.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} partial # Comments # utterances 스크립트 생성\nhttps://utteranc.es/ 에서 가이하는 작성 방법에 따라 진행 \u0026#x1f4a1; repo 는 자신의 블로그 repo (yourAcount/yourAccount.github.io) 을 사용해도 되고, 별도 프로젝트 repo (yourAccount/yourRepo) 을 사용해도 된다.\n해당 repo 에 utterances app 을 설치 하지 않아도 보이긴함, 그러나 작동은 안됨 (ChatGPT 가 틀린듯)\n\u0026lt;script src=\u0026#34;https://utteranc.es/client.js\u0026#34; repo=\u0026#34;smjune/smjune.github.io\u0026#34; issue-term=\u0026#34;pathname\u0026#34; label=\u0026#34;Comment\u0026#34; theme=\u0026#34;github-light\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; \u0026#x26a0;\u0026#xfe0f; utterances app 을 설치하지 않으면, 아래와 같은 에러가 발생함\nError: utterances is not installed on smjune/smjune.github.io. If you own this repo, install the app. Read more about this change in the PR.\nutterances 스크립을 넣을 layouts 파일 일반적으로 theme 을 사용하기 때문에 theme 에서 사용하는 commnet layout 을 overriding 하여야 한다. hugo-book (theme) 의 경우 theme/hugo-book/layouts/docs/comments.html 을 사용하여 hugo internal comment (Disque) 을 사용하게 되는데, layouts/partials/docs/comments.html을 만들어 hugo-hook 에 있는것 보다 먼저 사용하게 해야 한다. \u0026#x1f4dd; theme 을 customizing 할때 theme 의 파일을 수정하는 것보다, 이렇게 hugo root 에서 부터 동일한 파일을 만들어 수정해야 한다. 로컬이나, github action 에 theme 을 업데이트 할때 수정한 파일이 원복되지 않게 하기 위해서 이다.\nhugo ├─layouts │ └─partials │ └─docs │ └─comments.html // theme 을 사용하지 않고 이 파일을 사용 └─themes └─hugo-book └─layouts └─partials └─docs └─comments.html // theme comment hugo-book theme comment 는 bookComments: true 가 디폴트 이며, 따라서 모든 page 에 자동으로 적용된다. 따라서, 각 페이지에서 \u0026ldquo;bookComments: false\u0026rdquo; 을 설정하여 comment 을 OFF 하여야 한다.\ntheme 가 없는 경우 utterance 스크립을 /layouts/partials/utterances.html 에 넣고, 각 pages (xxx.md) 에서 {{ partial \u0026ldquo;utterances.html\u0026rdquo; . }} 을 직접 호출하여야 한다. giscus # 자신의 repo에 Discussions 을 setting 에서 enable Giscus app 을 자신에 repo 에 설치 Giscus 셋업 에 가서 스크립트 생성 (hugo-book theme) add \u0026ldquo;layouts/partials/docs/comments.html\u0026rdquo; and paste code provided by your comments provider \u0026lt;script src=\u0026#34;https://giscus.app/client.js\u0026#34; data-repo=\u0026#34;YOUR_GITHUG_REPO\u0026#34; data-repo-id=\u0026#34;YOUR_REPO_ID\u0026#34; data-category=\u0026#34;Show and tell\u0026#34; data-category-id=\u0026#34;YOUR_CID\u0026#34; data-mapping=\u0026#34;pathname\u0026#34; data-strict=\u0026#34;0\u0026#34; data-reactions-enabled=\u0026#34;1\u0026#34; data-emit-metadata=\u0026#34;0\u0026#34; data-input-position=\u0026#34;bottom\u0026#34; data-theme=\u0026#34;preferred_color_scheme\u0026#34; data-lang=\u0026#34;en\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; hugo-book theme comment 는 bookComments: true 가 디폴트 이며, 따라서 모든 page 에 자동으로 적용된다. 따라서, 각 페이지에서 \u0026ldquo;bookComments: false\u0026rdquo; 을 설정하여 comment 을 OFF 하여야 한다. PaperMode theme comment 는 \u0026ldquo;layouts/partials/comments.html\u0026rdquo; 에 스크립트를 설치하고, comments: [true | false] 설정을 config (hugo.yml) 과 front matter 에서 설정한다.\n"},{"id":6,"href":"/docs/SE/repo/CI/localbuild/","title":"Local build","section":"Countinuous Integration","content":"지금 하는 이야기는 주로 2000년 초반 처음 SW 개발 일을 시작하면서 겪은 일이다.\n생각해보면, 장비도 비싸고, 사용하는 툴도 MS visual SourceSafe (1994)이거나, 당시 최신 툴인 Subversion (2000)정도여서 그때는 거기까지가 최선이였고, 어쩔수 없이 발생하는 업무 공백들은 많은 사람들이 젊음으로 매우고 있었다. 말 그대로 \u0026lsquo;라떼는\u0026hellip;\u0026rsquo; 이야기 이다.\n개발자가 로컬빌드를 하거나, 주로 여러 개발자의 소스가 VCS에 다 모아 졌을때, 빌드 담당자가 해당 소스를 빌드 서버로 다운받아 일괄 빌드을 한 후 결과를 게시하게 된다. (빌드서버는 개발자 PC 보다 HW spec이 좋았다. 그당시 workstation 급)\n게시된 결과가 테스터나, QA 담당자에게 전달되면, 이것을 다운로드 하여 확인하게 된다. 오류가 없는 경우 빌드 결과는 배포 되지만, 오류가 발견되는 경우 (빌드 깨짐) 개발자에게 공지가 되고 개발자는 이를 수정하여 소스를 다시 check-in 해야 한다.\n이런 경우 주로 빌드 시간이 정해져 있다. 개발단계에 따라 최초 빌드 일정을 정하거나, 어느정도 완성이 된 후로는 주기적으로 매주 화요일 오후 몇시 이거나, 어느정도 제품이 런치된 유지보수 단계인 경우는, XP programming 이 유행하던 당시, daily 빌드를 한다고, 매일 오후 3시 까지 모두 check-in 하고, 4시에 빌드해야 하는 룰 도 있었다.\n빌드가 완성이 되면, 그 다음음 빌드를 확인 하는 과정인데, 테스터나, QA 담당자가 진행한다. 앞에서 말했지만 주로 오후 늦게 빌드가 완성이 되고, 일부 개발자들은 바로 퇴근을 하기 때문에 개발자와 테스터의 사이가 좋을 수가 없었다. (The Phoenix project 책에서도 이런 조직내 갈들이 표현되어 있다.)\n간단하게 그 과정을 정리하면,\n- 소스를 VCS 에 업로드 한다. - 소스를 받아 로컬에서 빌드 한다. - 빌드 결과를 depoly 서버에 업로드 한다. - deploy 된 빌드를 download 해서 결과를 확인 한다. - 확인 결과를 게시 한다. - 게시된 빌드 결과에 따라 코드를 수정한다. - 수정된 소스를 다시 VCS 에 업로드 (version up) 한다. - 수정한 코드를 받아, 다시 빌드 한다. 이런 옛날 과정을 요즘 툴로 재연 (시뮬레이션) 해 보기로 했다.\n간단하게 hugo 을 이용해 프로젝트을 진행하고, github 으로 소스 관리를 진행한다.\n## create hugo project $ hugo new site localbuild $ cd localbuild ## git init localbuild $ git init ## add theme as a submodule localbuild $ git submodule add https://github.com/alex-shpak/hugo-book themes/hugo-book **update baseURL and theme of config.toml** ## create a page localbuild $ cp -R themes/hugo-book/exampleSite/content.en/* ./content ## push source (hugo project) repo localbuild $ git remote add origin https://github.com/smjune/localbuild.git localbuild $ git add . localbuild $ git commit -m \u0026#39;initiate project\u0026#39; localbuild $ git push origin main ## add submodule to deploy public folder localbuild $ git submodule add https://github.com/smjune/Webdoploy.git public ## build hugo project localbuild $ hugo ## upload public localbuild $ cd public localbuild/public $ git add . localbuild/public $ git commit -m \u0026#39;first deploy\u0026#39; localbuild/public $ git push localbuild/public $ cd .. localbuild $ ## workflow 1. update pages 2. build (localbuild) 3. add/commit/push public folder (localbuild/public) 4. add/commit/push hugo project (localbuild) ( echo \u0026#39;public/\u0026#39; \u0026gt;\u0026gt; .gitignore ) public submodule 오류\n"},{"id":7,"href":"/docs/SE/hugo/papermod/","title":"PaperMod Theme","section":"Hugo Tips","content":" 주요 사이트 # 기본 사이트 : https://github.com/adityatelange/hugo-PaperMod/wiki/FAQs\nsample site : https://adityatelange.github.io/hugo-PaperMod/\nRepository : https://github.com/adityatelange/hugo-PaperMod\nhugo 폴더의 posts, post 폴더 기준으로 메뉴구성을 해 준다. 그 외 폴더 (예: docs) 는 hugo.yml 의 params : mainSections: 에서 정의 한다. hugo.yml for hugo-book # paperMode 샘플 hugo.yml\n지금 사이트 설정 (yml, toml, json 지원) baseURL: https://smjune.github.io/Hello_world/ # languageCode: en-us title: MyoungJune Sung says Hello Wrold theme: \u0026#39;PaperMod\u0026#39; taxonomies: category: categories tags: tags series: series menu: # to display menu on top-left side of site. main: - name: Home url: /index.html weight: 1 - identifier: Categories name: categories url: categories/ weight: 5 - name: Series url: series/ weight: 5 - name: Tags url: tags/ weight: 10 - name: Archive url: archives/ weight: 20 - name: Search url: search/ weight: 30 - identifier: GitHub name: github repo url: https://github.com/smjune/Hello_world/ weight: 40 outputs: home: - HTML - RSS - JSON # is necessary Paras: defaultTheme: auto DateFormat: \u0026#34;January 2, 2006\u0026#34; ShowReadingTime: true ShowPostNavLinks: true ShowBreadCrumbs: true ShowCodeCopyButtons: true ShowToc: true # you can add more option here Site 예\nArchives \u0026amp; Search # Archives 가이드\nSearch 가이드\ntaxonomies # Categories \u0026amp; Tags, Series 는 branch bundle 로 구성한다.\n가이드\nPages Front matter # 각 pages (md 파일) 에서 pages 에 대한 설정값을 조정한다.\n샘플 front matter\nSeries : [\u0026quot; \u0026hellip; \u0026ldquo;] 의 형태로 작성해야 한다.\nCategories \u0026amp; Tags, Series # 각 페이지에서 해당 페이지에 대한 category 와 Tags, Series 을 설정\nCategories: [\u0026#34;Posted\u0026#34;] Tags: [\u0026#34;Big Data\u0026#34;,\u0026#34;한글\u0026#34;,\u0026#34;Minority\u0026#34;,] Series: [\u0026#34;Git\u0026#34;] Shortcode # Mermaid # 참고 사이트\ncreate \u0026ldquo;layouts/shortcodes/mermaid.html\u0026rdquo; add \u0026lt;div class=\u0026#34;mermaid\u0026#34;\u0026gt; {{ .Inner }} \u0026lt;/div\u0026gt; \u0026ldquo;$ cp themes/PaperMod/layouts/partials/extend_head.html layouts/partials/extend_head.html\u0026rdquo; add {{ if or .Params.mermaid .Site.Params.mermaid }} \u0026lt;!-- MermaidJS support --\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.bootcdn.net/ajax/libs/mermaid/9.1.6/mermaid.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; mermaid.initialize({ startOnLoad: true, theme: localStorage.getItem(\u0026#34;pref-theme\u0026#34;) === \u0026#34;dark\u0026#34; ? \u0026#34;dark\u0026#34; : \u0026#34;forest\u0026#34; }); \u0026lt;/script\u0026gt; {{ end }} add \u0026ldquo;mermaid: true\u0026rdquo; on front matter of pages. partial # Footer Series # Footer에 Series 표시 하기\nPapermod QnA\nCreate the file layouts/partial/series-posts.html with these contents\n{{/* From: https://npf.io/2014/08/making-it-a-series/ */}} {{- if .Params.series }} {{- $name := index .Params.series 0 }} \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;\u0026#34; id=\u0026#34;series\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;Part of the \u0026lt;em\u0026gt;{{$name}}\u0026lt;/em\u0026gt; series:\u0026lt;/p\u0026gt; {{- $name := $name | urlize }} {{- $series := index .Site.Taxonomies.series $name }} \u0026lt;ol reversed class=\u0026#34;series\u0026#34;\u0026gt; {{- range $series.Pages }} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{.Permalink}}\u0026#34;\u0026gt;{{.LinkTitle}}\u0026lt;/a\u0026gt;,\u0026amp;#32; {{- .Date.Format .Site.Params.DateFormat -}} \u0026lt;/li\u0026gt; {{- end }} \u0026lt;/ol\u0026gt; {{- end }} Copy themes/papermod/layouts/_default/single.html to layouts/_default/single.html\nPut the following in the footer section, just underneath \u0026lt;footer class=\u0026quot;post-footer\u0026quot;\u0026gt;\n{{- if .Params.series }} {{- partial \u0026#34;series-posts.html\u0026#34; . -}} {{- end }} Include the following in your post\u0026rsquo;s front matter.\nseries: [\u0026#34;Making our own executable packer\u0026#34;] Comments # giscus utterances 와 생성 방법이 동일하다.\nGiscus 셋업\nadd \u0026ldquo;layouts/partials/comments.html\u0026rdquo; and paste code provided by your comments provider\n\u0026lt;script src=\u0026#34;https://giscus.app/client.js\u0026#34; data-repo=\u0026#34;YOUR_REPO\u0026#34; data-repo-id=\u0026#34;YOUR_REPO_ID\u0026#34; data-category=\u0026#34;General\u0026#34; data-category-id=\u0026#34;DIC_kwDOBIoCYM4CUfX_\u0026#34; data-mapping=\u0026#34;pathname\u0026#34; data-strict=\u0026#34;0\u0026#34; data-reactions-enabled=\u0026#34;1\u0026#34; data-emit-metadata=\u0026#34;0\u0026#34; data-input-position=\u0026#34;bottom\u0026#34; data-theme=\u0026#34;preferred_color_scheme\u0026#34; data-lang=\u0026#34;en\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; async\u0026gt; \u0026lt;/script\u0026gt; also in config add this\nparams: comments: true "},{"id":8,"href":"/docs/SE/repo/gitlab/","title":"Push to Gitlab","section":"The Repo","content":" GitLab 으로 Deploy 하기 # github 에 deploy 했던 hugo project 을 git remote 만 추가하서 gitlab repo 에 push 하고,\ngitlab CI/CD 을 이용하여 build, deploy 하기\n결론 gitlab에서 repo 만들고, 단순히 remote 만 추가해서 바로 push 하면 될 줄 알았는데, gitlab 에서 main 생성시 initial commit 이 자동으로 생성되어 바로 push 할 수 없었다. (빈 브랜치 생성불가)\n로컬 main 기준으로 다른 브랜치 labmain 만든 후 push 한 후, main 을 지우고, labmain 를 기준으로 main 을 다시 생성 하여야 한다.\n(로컬과 같은 커밑 과 같은 브랜치명 필요) 서로 다른 값을 저장하는 config.toml 은 각 workflow (CI/CD) 스크립에서 자신에 맞게 copy 하는걸로 해결\ngithug : config.toml 을 그냥 사용하고 (어짜피 hugo server 할 때 config.toml 은 필요하니) gitlab : config_gitlab.toml -\u0026gt; config.toml (baseURL = \u0026lsquo;smjune.gitlab.io\u0026rsquo;)을 .gitlab-ci.yml에 추가 서로 다른 브랜치로 checkout 할때 없어지는 파일,폴더 (themes) 확인 deploy 는 .gitlab-ci.yml 을 수정해야 해야 하는데, 좀 시간이 필요하다. gitlab.com/smjune/smjune.io 만들기 # remote 만 추가해서 main 을 gitlab 에 push 했더니, gitlab 생성시 만들어 졌던 main 에 initial commit 으로 이름만 같고 서로 다른 브랜치가 되어 버림.\n따라서 로컬 main 을 이름을 바꿔서 gitlab에 push 한 후에, 기존 main 을 삭제하고, push 한 브랜치로 다시 main 을 gitlab Web 상에서 진행해야 했음 (다른방법이 있을까?)\n$ cd \u0026#39;exiting git project\u0026#39; $ git remote add gitlab https://gitlab.com/smjune/smjune.gitlab.io/ # origin 이란 이름 대신 gitlab 이란 이름으로 remote을 설정 $ git branch -M labmain $ git push -uf gitlab labmain # 현재 checkout 한 브랜치를 labmain 으로 변경하고, 이것을 gitlab 리모트와 연결 # 나중에 main 을 다시 github remote 와 연결해주어야 함. $ git checkout -b main smjune/main # github 에서 main 이란 브랜치명 사용 $ git branch labmain * main gitlab 에서 main 브랜치를 다시 만들기 # gitlab WEB 에서 main (474dbe7)을 삭제, labmain 을 기준으로 main 을 다시 만든다. Hello_world$ git branch -avv * labmain bcb809a [gitlab/labmain] change name of .gitlab-ci main bcb809a [github/main] change name of .gitlab-ci remotes/gitlab/labmain bcb809a change name of .gitlab-ci remotes/gitlab/main 474dbe7 Initial commit 474dbe7 가 아닌 bcb809a 커밋이 있는 gitlab/main 을 만들어야 함.\n로컬 fetch 후, labmain 을 gitlab/main 과 연결한다.\n생각해보니, gitlab Web 상태가 main (bcb809a)된 후, 아래 단계를 진행 하지 않아도 되었을듯 Hello_world$ git fetch gitlab From https://gitlab.com/smjune/smjune.gitlab.io + 474dbe7...bcb809a main -\u0026gt; gitlab/main (forced update) Hello_world$ git branch -avv * labmain bcb809a [gitlab/labmain] change name of .gitlab-ci main bcb809a [github/main] change name of .gitlab-ci remotes/gitlab/labmain bcb809a change name of .gitlab-ci remotes/gitlab/main bcb809a change name of .gitlab-ci Hello_world$ git branch -u gitlab/main labmain branch \u0026#39;labmain\u0026#39; set up to track \u0026#39;gitlab/main\u0026#39;. Hello_world$ git branch -avv * labmain bcb809a [gitlab/main] change name of .gitlab-ci main bcb809a [github/main] change name of .gitlab-ci remotes/gitlab/labmain bcb809a change name of .gitlab-ci remotes/gitlab/main bcb809a change name of .gitlab-ci WEB 에서 labmain 도 삭제 현재까지 작업 결과 # main 브랜치와 labmain 이 동일하고 (bcb809a), 각각 자신의 리모트에 연결되어 있음\nlabmain bcb809a [gitlab/main] change name of .gitlab-ci\nmain bcb809a [github/main] change name of .gitlab-ci\nlabmain, gitlab/main # gitlab 용 (gitlab 은 remote 이름, labmain 는 브랜치 이름)\nmain, github/main # github 용 (github 는 remote 이름, main 는 브랜치 이름)\n지금까지 작업 순서는\nupdate main branch checkout gitlabmain merge main\n이었지만, $ git checkout labmain M Hugo/content/posts/gitlab.md Switched to branch \u0026#39;labmain\u0026#39; Your branch is up to date with \u0026#39;gitlab/labmain\u0026#39;. $ git merge main Updating 5487806..11711a6 Fast-forward .github/workflows/gh-pages.yml | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) 리모트 (gitlab, github) 브랜치가 main 이고, commit 이 동일 (bcb809a) 하므로\ncheckout 하지 않고, 바로 github 와 gitlab 에 push 할 수 있다.\nupdate pages commit to local main push to github push to gitlab 이후 labmain 을 로컬, 리모트 트래킹 브랜치 모두 지움 Hello_world$ git push gitlab main Enumerating objects: 22, done. Counting objects: 100% (22/22), done. Delta compression using up to 2 threads Compressing objects: 100% (14/14), done. Writing objects: 100% (16/16), 3.27 KiB | 1.09 MiB/s, done. Total 16 (delta 6), reused 0 (delta 0), pack-reused 0 To https://gitlab.com/smjune/smjune.gitlab.io.git bcb809a..2b0d320 main -\u0026gt; main Hello_world$ git push github main Everything up-to-date Hello_world$ git branch -avv labmain 2b0d320 [gitlab/main] add how to update github and gitlab * main 2b0d320 [github/main] add how to update github and gitlab remotes/github/gh-pages 309c2bd deploy: 41dfa412c2cd0ebdfd7675d7bd4604b8a07761bb remotes/github/main 2b0d320 add how to update github and gitlab remotes/gitlab/labmain bcb809a change name of .gitlab-ci remotes/gitlab/main 2b0d320 add how to update github and gitlab Hello_world$ git barnch -d labmain Hello_world$ git barnch -d -r gitlab/labmain labmain 리모트 삭제 : \u0026lsquo;$ git branch -d -r gitlab/labmain\u0026rsquo;\n결국 원하는 형태\n로컬과 gitlab, github 모두 7afd5d6 으로 sync, gh-pages 브랜치도 7afd5d 으로 deplay 완료 Hello_world$ git branch -avv * main 7afd5d6 [github/main] add update git page with setup section remotes/github/gh-pages c53a420 deploy: 7afd5d6bc8d95476eea52ec6a4e60fd3d3642627 remotes/github/main 7afd5d6 add update git page with setup section remotes/gitlab/main 7afd5d6 add update git page with setup section 남아 있는 Gitlab 작업 : CI/CD 구성 # gitlab CI/CD 을 사용하려면 credit card로 인증해야 함. (2021. 5.16 이후 사용자 생성)\nhttps://insight.infograb.net/blog/2021/11/23/how-to-prevent-crypto-mining-abuse/\nPipeline failing? To keep GitLab spam and abuse free we ask that you verify your identity.\nUntil then, shared runners will be unavailable. Validate your account or use your own runners. github 용 config.toml 지우고, config_gitlab.toml 을 config.tolml 으로 복사 project root 가 아닌 hugo 폴더에 이동 하여 빌드해야 함. hugo/public 을 deploy 해야함.\nhttps://gohugo.io/hosting-and-deployment/hosting-on-gitlab/ pages: script: - cd Hugo # hugo 설치 폴더로 이동 - rm config.toml # 기존 (github 용) config 삭제 - cp config_gitlab.toml config.toml # gitlab용 config 복사 - hugo --minify # hugo build artifacts: paths: - Hugo/public "},{"id":9,"href":"/docs/ENG/","title":"Eng.logging","section":"Docs.logging","content":"영어관련 자료 모음\n"},{"id":10,"href":"/docs/SE/repo/CI/PostCI/","title":"Post CI","section":"Countinuous Integration","content":"2005년 부터 약 10년간 SW개발에 참여하지 않았기에 branch 와 git 을 2016년 다시 SW개발 조직에 되돌아 와서야 접하게 되었다. 개인적으로 그 10년을 그대로 SW개발 업무를 계속했었더라면 현재 나의 위치가 지금과 많이 달라졌을찌 종종 생각하게 된다. 빠르게 발전하고 매년 새로운 기술이 나온는 SW 분야에서 10년의 외도는 그야 말로 나를 신입사원으로 만들게 충분한 시간이였다. 그 나마 대학 전공과 취업 후 6년을 시간들을 되 집어보면서 \u0026lsquo;그때 그랬는데\u0026rsquo; 라는 생각이 어느정도 도움이 되는 부분도 있었고, \u0026lsquo;어 아직도 이렇게 하고 있네?\u0026rsquo; 하는 부분은 적잖이 있어 놀라기도 했다.\n예를 들자면, 막 초기 피처폰이 활성화 되기 시작할 때 떠났던 사람이 스마트폰이 주류가 되었을 때 되돌아 온것이니, 많은 것이 달라져 있었고, 처음부터 다시 배워야 할것 들이 너무 많았으며, 당장 내가 할 수 있는 일은 많지 않다.\n지금부터 할 이야기는 나의 그 공백의 시간에 일어 났던 일들이다.\nCI 개념이 최로로 나로면서\nsubmit 된 내용이 CI 툴에 의해 모니터링 되어 (혹은 WebHook 으로 호출) CI 툴 (서버) 에서 빌드, 테스트 되어 deploy 됨\nGithub self-hosted 는 항상 repos 을 listening 하고 있다.\nbare metal 서버\nvirtual 서버\n- 소스 코드를 VCS 에 업로드 한다 - VCS 로 부터 WebHook 혹은 Polling 을 통해 CI 서버가 빌드 한다. - 빌드 후 자동화된 테스트 를 수행한다. - 결과를 게시 한다. - 게시된 결과에 따라 코드를 수정한다. - 수정한 코드를 VCS 에 다시 업로드 한다. (version up) "},{"id":11,"href":"/docs/SE/repo/CI/Branch/","title":"Branches","section":"Countinuous Integration","content":"앞에서 말한 것 처럼 2016년이 되서야 다시 SW개발 업무를 다시 시작하게 되었으므로 나에게 branch 의 개념을 이해하는 것은, 군 제대 후 복학생으로 공업 수학의 미분을 푸는데 갑자기 인수분해가 되지 않았을때 느겼던 괴리감을 다시 한번 느끼게 해 주었다.\nsubmit 전에 어떻게 사전 검증을 할 것인가에 대하 대답으로\n브랜치 개념이 도입이 됨\n기존 post CI 가 적용된 브랜치를 운영 (dev) 하여\n확인이 완료된 change을 운영 브랜치 (main) 으로 merge\n- 각자 정해진 소스 트리 (branch) 에 소스를 업로드 한다. - 해당 브랜치로 부터 WebHook 혹은 Polling 을 통해 CI 서버가 빌드 한다. - 빌드 후 자동화된 테스트 를 수행한다. - 결과를 게시 한다. - 게시된 결과에 따라 코드를 수정한다. - 수정한 코드를 정해진 브랜치에 다시 업로드 한다. (version up) - 해당 브랜치로 부터 WebHook 혹은 Polling 을 통해 CI 서버가 빌드 한다. - 빌드 후 자동화된 테스트 를 수행한다. - 이상이 없는 경우 Code base 와 해당 브랜치를 merge 한다. - merge된 code base 을 다시 빌드, 테스트 한다. "},{"id":12,"href":"/docs/SE/hugo/gitbook/","title":"Gitbook","section":"Hugo Tips","content":" Gitbook # Hugo 처럼 로컬에서 빌드하여 별도 web hosting (github pages) 으로 publish 하는 방식으로 사용해도 되고,\ngitbook.com 에 접속하여 GUI을 이용하여 운영 할 수도 있다.\n(Web hosting 제공 : https://YOUR_ACCOUNT.gitbook.io/, 무료/유로)\n아래 내용은 gitbook-cli을 이용하여 Static site을 생성한 다음 별도 Web hosting 을 이용하는 방식을 기록함\n참고\n\u0026#x1f449; 정보\n2017년 이후로 gitbook-cli 가 업데이트을 지원하지 않음\nGoogle, MS 등 SW 개발 도규먼트들과 비슷한 형태로\n(gitbook 으로 작성된것이라고 들은것 같은데\u0026hellip; 확실치 않음.)\n그래도 그나마 눈에 익숙하고, 여러형태의 e-book 으로도 지원했던것 같다. (calibre 설치, 참조)\n설치 난이도 참조 와 github actions 지원이 좀 애매하다. 참조\nKnown Dependencies\nnode : v12.22.1 # works well in v16\nnpm : v6.14.12\ngitbook-cli : gitbook-cli@2.3.2\ngraceful-fs : 4.1.4 관련사이트\nhttps://github.com/GitbookIO/gitbook-cli\nhttps://docs.gitbook.com/integrations/github\nhttps://www.gitbook.com/\ninstall gitbook # Homebrew on MacOS (high sierra, 10.13.6)\n# 사전 Homebrew 설치 필요 / $brew update 을 해서 업데이트 하자 ... $ brew -v Homebrew 4.0.4 Homebrew/homebrew-core (git revision 25e07818a96; last commit 2023-02-28) $ brew install node # 해당 명령어로 오류가 나서 nvm 을 설치 하여 node 12.22.1 을 설치 ... nvm \u0026amp; Node 설치 # $ brew install nvm # 이후, 가이드에 따라 bash 환경 설정 ... $ nvm -v 0.39.3 # nvm 으로 gitbook dependencies 해결 node 버전 설치 $ nvm install 12.22.1 Downloading and installing node v12.22.1... Downloading https://nodejs.org/dist/v12.22.1/node-v12.22.1-darwin-x64.tar.xz... ######################################################################## 100.0% Computing checksum with shasum -a 256 Checksums matched! Now using node v12.22.1 (npm v6.14.12) Creating default alias: default -\u0026gt; 12.22.1 (-\u0026gt; v12.22.1) # 12.22.1 한개 설치되어서 설정하지 않아도 될듯한데, 혹시 모르니... $ nvm use 12.22.1 Now using node v12.22.1 (npm v6.14.12) $ node -v v12.22.1 gitbook-cli 설치 # $ npm i -g gitbook-cli $ gitbook init ... graceful-fs 오류 처리 \u0026#x26a0;\u0026#xfe0f; # gitbook QnA 을 참조해서 graceful-fs dependecies 을 해결하기 위해\n오류를 발생시킨 polyfills.js 찾아서 삭제후, 재설치하는 방식사용\n/Users/YOURACCOUNT/.nvm/versions/node/v12.22.1/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/ 에서 polyfills.js 삭제 $ wget https://raw.githubusercontent.com/isaacs/node-graceful-fs/168bdb8f0bb3174e8499d4bc5878deead4172c39/polyfills.js 실행 해서 해당 파일 재 설치 위의 결과로 아래와 같은 형태가 구성됨\n$ gitbook -V CLI version: 2.3.2 GitBook version: 3.2.3 $ ls README.md\tSUMMARY.md\t_book . # gitbook prj root ├── README.md # Introduction readme ├── SUMMARY.md # 목차 구성 파일 └── _book/ # gitbook serve 로 생성된 결과 파일 구성된 내용을 브라우저로 미리 볼 수 있다.\n$ gitbook serve # 서버가 아니다, 서브 $ gitbook serve Live reload server started on port: 35729 Press CTRL+C to quit ... info: 7 plugins are installed info: loading plugin \u0026#34;livereload\u0026#34;... OK info: loading plugin \u0026#34;highlight\u0026#34;... OK info: loading plugin \u0026#34;search\u0026#34;... OK info: loading plugin \u0026#34;lunr\u0026#34;... OK info: loading plugin \u0026#34;sharing\u0026#34;... OK info: loading plugin \u0026#34;fontsettings\u0026#34;... OK info: loading plugin \u0026#34;theme-default\u0026#34;... OK info: found 1 pages info: found 0 asset files info: \u0026gt;\u0026gt; generation finished with success in 0.7s ! Starting server ... Serving book on http://localhost:4000 # Ubuntu 도 아래 명령어로 오류가 나면, nvm 을 설치해서 사용해야 할듯. # $ sudo apt-get install nodejs npm localhost:4000 에서 결과 보기 docs 폴더로 운영 # SW 개발 프로젝트 하위 /docs 폴더로 gitbook 운영이 필요할때\n. # project root ├── book.json └── docs/ # gitbook root ├── README.md └── SUMMARY.md book.json 에 아래 내용 추가,\n{ \u0026#34;root\u0026#34;: \u0026#34;./docs\u0026#34; } gitbook-cli 는 2017년 4월 이후 더이상 지원 되지 않고 있어, 향후 어떻게 gitbook.com 과 차별을 두고 다시 지원을 하게 될찌 궁금하다. 예전고 같은 형태가 될찌, gitbook.com 전용 client tool 이 될찌. 2017년 기준 gitbook-cli (v2.3.2)을 사용하게 된다면 nvm 을 이용해서 최신 node 와 구분하여 사용할 수 밖에 없다. pyenv 처럼\nBook 구성 # README.md, SUMMARY.md, book.json (플러그인 설정) 등 기본적인 형태를 갖추게할 기본 파일들 구성 content 용 md 파일 구성 (Hugo의 index.md 처럼 README.md 을 이용하는 것으로 보임.) 상세 내용 참고 SUMMARY.md # 폴더에 readme 가 없으면 indent 가 더 들어간다. 혹시나 \u0026lsquo;gitbook\u0026rsquo; 이라는 폴더를 생성하지 말자. (_book 에서 사용함) 폴더명에 \u0026lsquo;공백\u0026rsquo;이 없도록 주의 하자. md 파일 링크 없이 목차를 구분하려면 \u0026lsquo;##\u0026rsquo; 사용 (예: \u0026lsquo;## Chapter 1\u0026rsquo;) 목차 구성 book.json # 전체적인 환경을 구성할 수 있도록 설정하는 파일으로 보임.\nplugin 설치 plugin 찾아서 설정하기\nbook.json 에 plugin 설정하고, \u0026ldquo;$gitbook install\u0026rdquo; 으로 설치.\n{ \u0026#34;plugins\u0026#34;: [ \u0026#34;code\u0026#34;, \u0026#34;hints\u0026#34;, \u0026#34;splitter\u0026#34;, \u0026#34;-sharing\u0026#34;, \u0026#34;chapter-fold\u0026#34;, \u0026#34;back-to-top-button\u0026#34;, \u0026#34;intopic-toc\u0026#34;, \u0026#34;insert-logo\u0026#34; ], \u0026#34;pluginsConfig\u0026#34;: { \u0026#34;intopic-toc\u0026#34;: { \u0026#34;label\u0026#34;: \u0026#34;Contents\u0026#34; }, \u0026#34;insert-logo\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;Path/to/my-logo.png\u0026#34;, \u0026#34;style\u0026#34;: \u0026#34;background: none;\u0026#34; } } } 설치 예 $ gitbook install ... info: runTopLevelLifecycles → 2 ▌ ╢█████████████████████████████████████████████████████████████████████████████████░░░╟ /Users/myoungjunesung/blog/gitbook ├── gitbook-plugin-back-to-top-button@0.1.4 ├── gitbook-plugin-chapter-fold@0.0.4 ├── gitbook-plugin-code@0.1.0 ├── gitbook-plugin-expand-active-chapter@1.0.0 ├── gitbook-plugin-flexible-alerts@1.0.4 ├── gitbook-plugin-insert-logo@0.1.5 ├── gitbook-plugin-intopic-toc@1.1.1 ├── gitbook-plugin-navigator@1.1.1 ├── gitbook-plugin-search@2.2.1 └── gitbook-plugin-splitter@0.0.8 $ Site view 오른쪽 Toc gitbook-plugin-intopic\n왼쪽 메뉴접기 gitbook-plugin-chapter-fold\nTop으로 가기 버튼 gitbook-plugin-back-to-top-button\n강조 블럭 gitbook-plugin-flexible-alerts\nNote, Tip, Warning, danger 4가지 callout(default) | flate 형태 지원\n사용법 : [!Note|style:flate]\n"},{"id":13,"href":"/docs/SE/hugo/","title":"Hugo Tips","section":"Job.logging","content":" Hugo (SSG) # https://gohugo.io/documentation/\n1. $ hugo new site [hugo project name] 으로 프로젝트 생성. 2. config.toml : baseURL, Title 과 Theme 을 수정. ( 혹은 hugo.yml) 3. themes : 사용할 Web theme 을 설치. ( git submodule 사용 ) 4. content : 폴더/파일.md 형태로 글 작성 및 구성. ( $ hugo new posts/hello.md ) 5. hugo server 으로 로컬 호스트 페이지 확인 ( md 파일에 draft : true 인 경우 -D 옵션 필요) 6. hugo server 가 실행 중이면, 저장하는 수정 내용이 바로 로컬 호스트 페이지에 반영됨 hugo.yml (config.toml) # v0.110.0 이상에서 지원, 하위 호환을 위해 기존 config.toml 도 사용 가능\ntheme 의 가이드에 따라 설정값들을 사용해야 한다.\n-2025.4.12\nv0.145.0 (latest) 으로 local 및 github actions (gh-pages.yml) 변경\n% brew upgrade hugo % hugo version hugo v0.145.0+extended+withdeploy darwin/arm64 BuildDate=2025-02-26T15:41:25Z VendorInfo=brew baseURL: https://smjune.github.io/ # 실제 접속 사이트 주소 title: MyoungJune Sung says Hello Wrold # 사이트 제목 theme: hugo-book # 랜더링 할 theme Emoji # \u0026#x1f44d; config 파일에 enableEmoji : true 추가\n\u0026lsquo;:emoji_name:\u0026rsquo; 으로 사용 Emoji list\nHighlight text # config 파일에 \u0026lsquo;[markup.goldmark.renderer] unsafe = true\u0026rsquo; 입력 형광강조 하고 싶은 문자열에 \u0026lt;mark\u0026gt; ... \u0026lt;/mark\u0026gt; 로 표시 Footnote 1 # 주석을 삽압하고 싶은 곳에 \u0026lsquo;[^footnote_ID]\u0026rsquo; 을 입력 page 맨 아래에 \u0026lsquo;[^footnote_ID]: 주석 설명\u0026rsquo; 을 입력\n\u0026#x1f44f; 주석 순서에 따라 차례대로 숫자가 입력됨 theme install # 각 theme 에서 제공하는 방식에 따라 설정\ngit submodule 로 theme 설치를 권장, 이후 업데이트 도 git submodule 사용\n# 최초 설치 $ git submodule add --depth=1 https://github.com/[theme Repos] themes/[theme name] # theme 요소를 찾지 못는 오류 발생시 theme 업데이트 / 프로젝트를 clone 하여 셋업할 때, workflow 설정시 필요 $ git submodule update --init # --recursive : submodule 이 중복으로 사용될때 $ git submodule update --remote --merge hugo server # -D : draft 까지 랜더링함\n-t [theme] : (config에 theme 미 설정시) 해당 theme로 랜더링함\n$ hugo server Start building sites … hugo v0.110.0+extended darwin/amd64 BuildDate=unknown | EN -------------------+----- Pages | 95 Paginator pages | 2 Non-page files | 38 Static files | 78 Processed images | 0 Aliases | 28 Sitemaps | 1 Cleaned | 0 Built in 730 ms Watching for changes in /Users/myoungjunesung/blog/github/Hello_world/Hugo/{archetypes,content,data,layouts,static,themes} Watching for config changes in /Users/myoungjunesung/blog/github/Hello_world/Hugo/hugo.yml Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop server 을 계속 실행해 놓고, md 파일을 수정후 저장하면 바로 반영되어 로컬 호스트에서 바로 확인 가능\nChange detected, rebuilding site. 2023-02-26 16:16:18.514 +0900 Source changed WRITE \u0026#34;/Users/myoungjunesung/blog/github/Hello_world/Hugo/content/docs/SE/hugo/theme.md\u0026#34; Total in 125 ms Bundles # 전체 글 구조를 잡을때, 가장 중요하게 생각해 하는 부분이 hugo 의 bundle 개념이다.\nLeaf 와 Branch 로 나눠지는대, 말 그대로 leaf bundle 은 말단 말뭉치 (?) 이므로,\n하위로 다른 구성요소를 갖을수 없다.\n반면 Branch bundle의 경우 하위로 다른 branch bundle 과 leaf bundle을 갖을 수 있다.\n자세한 차이점은 아래 표를 참고 하자\nindex.md vs _index.md 으로 구분하여 보면 된다.\nhttps://gohugo.io/content-management/page-bundles/\nLeaf Bundle Branch Bundle Usage Collection of content and attachments for single pages Collection of attachments for section pages (home page, section, taxonomy terms, taxonomy list) Index filename index.md 1 _index.md 1 Allowed Resources Page and non-page (like images, PDF, etc.) types Only non-page (like images, PDF, etc.) types Where can the Resources live? At any directory level within the leaf bundle directory. Only in the directory level of the branch bundle directory i.e. the directory containing the _index.md (ref). Layout type single list Nesting Does not allow nesting of more bundles under it Allows nesting of leaf or branch bundles under it Example content/posts/my-post/index.md content/posts/_index.md Content from non-index page files… Accessed only as page resources Accessed only as regular pages Menu # posts 항목에 book과 novel 이라는 페이지가 생성된다. content └─posts ├─_index.md # posts 가 리스트가 되기 위해 필요 ├─book.md # http://~/posts/book └─novel.md # http://~/posts/novel content 하위로 posts 와 docs 페이지가 생성된다.\ncontent ├─posts # http://~/posts │ ├─_index.md │ ├─book.md │ └─novel.md ├─docs.md # http://~/doc └─_index.md # content 가 list 가 되기 위해 필요 posts 항목에 book 페이지 만 생성 된다. contents └─posts └─book ├─index.md # http://posts/book/ └─novel.md # is not rendered. book 은 index.md 으로 leaf bundle 정의되어 하위 페이지를 갖을 수 없어 novel 은 표시되지 않는다.\nposts 항목에 book 페이지 와 book 하위로 novel 페이지 가 생성된다. contents └─posts └─book ├─_index.md └─novel.md # http://~/posts/book/novel posts 항목에 book 페이지 가 만들어 지고, 하위로 novel, essay 페이지가 만들어 진다. contents └─posts └─book ├─_index.md ├─novel # http://~/posts/book/novel │ └─index.md └─essay.md # httP://~posts/book/essay Lacal Image # Leaf bundle 은 하위로 images 폴더를 만들어 해당 페이지 에서 사용하는 이미지를 따로 저장하자.\nbranch bundle 은 _index.md 와 동일한 folder 위치에 이미지를 저장해야 한다.\n\u0026#x26a0;\u0026#xfe0f;참고 bundle 에 따른 이미지 관리\ncontents └─posts └─book ├─_index.md # ![이미지](./book.png) ├─book.png # book 이미지 ├─novel │ ├─index.md # ![이미지](./images/novel.png) │ └─images │ └─novel.png # novel 이미지 └─essay ├─index.md # # ![이미지](./images/essay.png) └─images └─essay.png # essay 이미지 hugo 폴더의 posts, post 폴더 기준으로 메뉴구성을 해 준다. 그 외 폴더 (예: docs) 는 hugo.yml 의 params : mainSections: 에서 정의 한다. https://www.markdownguide.org/extended-syntax/#footnotes\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":14,"href":"/docs/SE/repo/git/","title":"Git command Tips","section":"The Repo","content":" GIT 연습 Site # http://learngitbranching.js.org/\nhttps://backlogtool.com/git-guide/kr/\n$ level - 연습문제 초기 화면 (문제선택)\n$ sandbox - 빈 연습\n$ show solution - 해당보기\n$ reset - 해당 level 처음부터 다시\n$ undo - 1개 명령 취소\n$ git fakeTeamwork 1 - origin 에 1개 커밋 넣기\n\u0026#x31;\u0026#xfe0f;\u0026#x20e3; Set up # $ git clone -b [브랜치 | tag] [REPO URL] $ git remote add orgin [REPO URL] // origin 으로 REPO URL 등록 $ git remote rm orgin // origin 삭제 $ git submodule add [REPO RUL] [Local Folder Path] $ git submodule update // --init --recursive \u0026#x32;\u0026#xfe0f;\u0026#x20e3; branch # $ git branch -f bugfix HEAD~1 : bugfix 브랜치를 HEAD [혹은 브랜치 명] 1개 전 commit으로 이동 $ git branch -u origin/maser [Branch A] : 이미 있는 local Branch A (생략하면 현재 checkout branch) 가 origin/master 을 track함 --\u0026gt; git checkout --track 과 비교 $ git branch -d Branch A : local 에서만 Branch A 삭제 $ git branch -d -r origin/branch A : remote 트랙킹 브랜치를 로컬에서 삭제 (에, origin/featrue ) \u0026#x33;\u0026#xfe0f;\u0026#x20e3; checkout # $ git checkout branch A : Remote에 있는 branch A 에 대해 local 에 branch A 와 origin/branch A만들고, checkout. -\u0026gt; 로컬 branch A가 없고, 유일한 Remote에 branch A가 있다면 (\u0026#34;remotes/origin/branch A\u0026#34;가 있어야 함) $ git checkout HEAD~1 : HEAD [혹은 브랜치 명] 을 1개 commit 앞으로 이동, checkout $ git checkout origin/master : origin/master 가 있던 commit에서 HEAD을 만들고 checkout (Detached state) $ git checkout -b [Branch A] origin/master : Branch A을 만들고 origin/master을 tracking 함. $ git checkout --track origin/master : Local에 master(remote와 같은 이름의 브랜치)을 만들고 checkout 한 후 origin/master (Remote 브랜치)을 tracking 함. --\u0026gt; git branch -u 와 비교 \u0026#x34;\u0026#xfe0f;\u0026#x20e3; Others # $ git cherry-pick [commit-ID1] [commit-ID2] … : 현재 checkout된 브랜치에 C1, C2 을 넣어라 $ git rebase [Branch A] [Branch B] : branch A 아래로 Branch B (checkout) 를 옮긴다. (FF 가능하면 FF) $ git rebase [Branch A] : branch A 아래로 HEAD (checkout한 branch)를 옮긴다. (FF 가능하면 FF) $ git rebase -i HEAD~[몇 개 상위?] : X 개 뒤 Commit 들을 선택하여 새롭게 다시 지금 branch을 재구성한다. $ git pull --rebase origin/master : origin/master (생략시 현재 branch가 track 하는 remote 브랜치) fetch 하고 현재 checkout 된 branch 을 그 아래로 이동 = $ git fetch origin master + git rebase origin/master $ git reset HEAD~[몇 개 상위?] : HEAD가 있는 branch 을 ~ X개 뒤 commit으로 옮긴다. $ git revert HEAD : HEAD commit 을 다시 만든다 (commit --amend ?? 와 비슷?) \u0026#x35;\u0026#xfe0f;\u0026#x20e3; Merge # checkout 된 브랜치가 어떤 a branch(을) 와 Merge 해옴 Merge [ branch A] : checkout 된 branch 에 branch A 와 합쳐진 commit을 만든다. \u0026#x36;\u0026#xfe0f;\u0026#x20e3; Fetch/Pull/Push # 모든 Remote 에 모든 tracing 하는 브랜치 와 … Fetch/Pull/Push 언급한 Remote 에 모든 tracing 하는 브랜치 와 …Fetch/Pull/Push 언급한 Remote 에서/으로 소스 브랜치를 …Fetch/Pull/Push 소스 브랜치 : 타겟 브랜치 \u0026ndash;\u0026gt; gerrit 사용시 : $ git push origin [source]:refs/for/[target] \u0026#x26a0;\u0026#xfe0f; Fetch/pull 은 소스가 remote 이고, Push는 소스가 local 이다.\n$git pull remote remote_branch:local_branch\n$git push remote local_branch:remote_branch\nFetch/Pull/Push // 없으면, origin 으로 등록된 remote Fetch/Pull/Push [Remote] // 없으면, remote/현재브랜치 Fetch/Pull/Push [Remote] [source branch] // 여기까지만 사용하는것을 권장 Fetch/Pull/Push [Remote] [source]:[tartget] $ git fetch origin master~1:branchA : origin (Remote) master보다 1개 앞선 commit을 local에 branchA 브랜치로 만든다. (checkout 하지 않는다.) $ git fetch origin master : origin (Remote) 에 있는 master 을 local에 (origin/master) 업데이트 한다. (없으면 만든다. Checkout 하지 않는다.) $ git fetch origin :side : origin (Remote) 에 없는 side 브랜치를 Local에만 만든다 -\u0026gt; = *$ git branch side $ git fetch : 현재 checkout 된 브랜치의 origin (Remote) 업데이트 $ git pull origin master:branchA : origin (Remote) master 을 local에 branchA로 만들고 checkout된 브랜치가 branchA를 merge. = git fetch origin master:branchA + git merge branchA $ git pull origin master : origin (Remote) master 을 local에 Fetch하고 (origin/master 만들거나, 업데이트), checkout된 브랜치가 origin/maser를 Merge = fetch origin master + merge origin/master * $ git pull --rebase origin/master = $ git fetch origin master + git rebase origin/master $ git pull : 현재 checkout된 브랜치가 tracking하는 origin (Remote)을 업데이트하고, checkout된 브랜치가 tracking branch를 Merge = fetch origin [the checkouted branch] + merge origin/[the checkouted branch] $ git push origin HEAD:refs/for/main : 현재 HEAD 브랜치를 gerrit main 브랜치(를만들고)로 push 한후 (submit type에 따라 merge, rebase, cherry-pick 등을 함) -\u0026gt; HEAD가 있는 commit 위치로 origin/main 을 progress 시키겠다. $ git push origin HEAD^:master : local HEAD보다 1개 앞선 commit을 origin (Remote) 에 master 브랜치로 push (trancking을 만들지는 않음) -\u0026gt; HEAD 보다 1개 앞선 commit 으로 origin/master 을 progress 시키겠다. $ git push origin BranchA : origin (Remote) 에 로컬브랜치 BranchA 을 push 하고 track 함 (없으면 origin/BranchA도 만듬, checkout과 상관없음) -\u0026gt; BranchA 가 progress 한 만큼 서버 상태도 progress 한다. $ git push origin :side : origin (Remote) 에서 side 브랜치를 삭제한다. $ git push : 현재 checkout된 브랜치가 tracking 하는 origin 으로 (없으면 origin/~~을 만듦) 현재 checkout된 브랜치를 push = push origin [the checkouted branch]:origin/[the checkouted branch] "},{"id":15,"href":"/docs/SE/repo/CI/Presubmit/","title":"Presubmit","section":"Countinuous Integration","content":"branch 와 더불어 presubmit 은 병결로 빼먹은 진도를 따로 따라 잡아야 하는 상황과 비슷했다.\n브랜치가 많아 짐에 따라 브랜치 운영 전략 (Flow) 이 복잡해짐\n이에 바로 main 브랜치에 submit 하는 것을 기본으로\nsubmit 전 Work In Progress 단계를 제공함\n- code base 의 WIP 기능을 이용하여 소스를 업로드 한다. (refs/for/head, Sheves) - WIP 와 연결된 workflow 에 따라 빌드 및 테스트가 수행된다. - 결과를 게시한다. - 수정한 코드로 WIP 을 업데이트 한다. (patch-set, revision) - WIP 와 연결된 workflow 에 따라 빌드 및 테스트가 수행된다. - 이상이 없는 경우 Code base 에 submit 한다. (version up) - submit 된 change 기준으로 다시 빌드, 테스트 한다. (Postsubmit) MR/PR shleves refs/for/head\n"},{"id":16,"href":"/docs/SE/Tools/pyenv/","title":"Python with Pyenv","section":"Tools","content":" Pyenv 사용하기 # $ pyenv versions * system (set by /home/june.sung/.pyenv/version) 2.7.17 $ pyenv install --list $ pyenv install 3.6.9 * system (set by /home/june.sung/.pyenv/version) 2.7.17 3.6.9 $ pyenv shell 3.6.9 $ pyenv which python 3.6.9 (set by PYENV_VERSION environment variable) # $ pyevn [ global \u0026gt; local \u0026gt; shell ] X.X.X # cat ~/.pyenv/version | cat .pyton-version | echo $PYENV_VERSION # loacal 은 해당 폴더 아래 (set by ~폴더/.python-version) python 설정 (해당 폴더 나가면 해제) # Shell 은 해당 터미널 (set by PYENV_VERSION) 에 python 설정 (해당 터미널 나가면 해제) $ virtualevn -p $(pyenv which python) .venv # 바로 위 shell 에 설정한 python 을 사용 $ pyenv shell --unset # 현재 shell의 python 설정 해제 \u0026#x1f4dd;문제는 \u0026lsquo;global / local /shell\u0026rsquo; 중 어떤 python 설정을 현재 폴더에 가상환경 ( .venv)으로 만들것인가?\nPyenv 로 python version들을 설치 현재 python 환경 (local / shell) 설정 python3 -m venv 로 .venv 만든 후, (현재 python 환경이 반영됨) \u0026lsquo;\u0026ndash;unset\u0026rsquo; 으로 현재 python 설정 해제 source .venv/bin/activate 으로 가상환경 실행 # 여러가시 가상환경 지원 툴 1.pyenv # have to install by using script \u0026amp; edit $(Home)/.bashrc (curl https://pyenv.run | bash) 2.virtualenv # have to install with pip 3.pyenv-virtualenv # $ pyenv virtualenv XXXX XXXX 을 사용한다면 설치 (pyenv 모듈) 4.python3 -m venv (higher than 3.4, python3 모듈) pyenv 과 virtualenv 별도 사용 # $ virtualenv py271 --python=python2.7 Shell setup # $ pyenv shell 2.7.1 # 현재 shell 에 2.7.1 적용 $ pyenv which python # shell 확인 $ virtualenv -p $(pyenv which python) py271 # .venv $ pyenv shell -- unset # 현재 shell 해제 $ source py271/bin/activate # .venv/bin/activate (py271)$ ... (py271)$ pip freeze \u0026gt; requirements.txt (py271)$ pip install -r requirements.txt ... (py271)$ deactivate $ local setup : # local path에 적용하기 (해당 폴더를 빠저 나가면 해제)\n\u0026#x1f44f; shell 인 경우 해당 터미널을 빠저 나가면 해제됨\n$ python —version Python 0.0.0 $ mkdir test $ cd test /test$ pyenv local x.x.x /test$ python —version Python x.x.x /test$ pyenv versions System * X.X.X (set by /home-mc/june.sung/test/.python-version) /test$ cd .. /$python —version Python 0.0.0 /$ pyenv versions * System (set by /home-mc/june.sung/.pyenv/version) X.X.X global / local setup # \u0026#x1f44f; pyenv 의 virtualenv 모듈 사용\n$ pyenv versions $ pyenv install --list $ pyenv install 3.6.9 $ pyenv virtualenv -p 3.6.9 py369 $ pyenv versions * system (set by /home/june.sung/.pyenv/version) 2.7.17 3.6.9 3.6.9/envs/py369 py369 $ pyenv activate py369 ... (py369) $ pyenv deactivate $ pyenv local 을 이용한 로컬에 가상환경 구성 # /test$ pyenv local py369 (py3369)/test$ cd .. /$ Pyenv + python3 의 venv 모듈 사용 # \u0026#x1f44f; after Pyhon 3.3\npyenv 로 특정하지 않으면, python3 \u0026ndash;vesion 에 표시된 버전으로 생성됨\n$ pyenv versions # (set by ??? 표시로 구분) $ pyenv [global | local | shell ] X.X.X # $ pyenv which python # 어느 python 셋팅을 쓸것인가? $ python3 -m venv .venv # Python3 module venv # $ pyenv [global | local | shell ] -unset $ source .venv/bin/activate (.venv) $ ... (.venv) $ deactivate $ \u0026#x1f4dd; 결론\npyenv install X.X.X 으로 필요한 python 을 설치하고, pyenv shell X.X.X로 해당 shell 만 X.X.X로 셋업해서,\npython3 -m venv .venv 로 가상환경 만들어 사용 하고, shell 해제,\npyenv virtualenv 나 virtualenv 는 사용하지 말자. - 너무 많이 알면 헤깔린다.\npip install error # \u0026#x1f3e2; proxy setup\n$ vi .config/pip/pip.conf [global] proxy = http://xxx.xxx.xxx.xxx:8080 cert = /path/to/DXXXXXX.crt trusted-host = pypi.python.org pypi.org files.pythonhosted.org \u0026#x1f4bb; CLI\n$ pip install --prxoy http://xxx.xxx.xxx.xxx:8080 --trusted-host pypi.python.org --cert .\\DXXXXXX.crt Pyenv + uv 사용하기 (added 2025.4.13) # \u0026#x1f44f; Rust로 작성된 초고속 파이썬 패키지 관리자\nuv 소개 (공식문서) # uv는 pip, pip-tools, virtualenv를 모두 대체할 수 있는 통합 패키지 관리자입니다:\npip 대비 8-10배 빠른 의존성 해결 (캐시 사용 시 80-115배) 단일 바이너리로 제공되어 Python 설치와 독립적으로 동작 향상된 오류 진단 및 의존성 관리 기능 uv 설치 # $ curl -LsSf https://astral.sh/uv/install.sh | sh # 또는 homebrew 사용 $ brew install uv pyenv와 함께 사용하기 # # Python 버전 설정 $ pyenv local 3.11.0 # 가상환경 생성 및 활성화 $ uv venv .venv $ source .venv/bin/activate # 패키지 설치 (.venv) $ uv pip install pandas numpy (.venv) $ uv pip install -r requirements.txt # requirements.txt 생성/업데이트 (.venv) $ uv pip freeze \u0026gt; requirements.txt # 의존성 잠금 파일 생성 (선택사항) (.venv) $ uv pip compile requirements.txt -o requirements.lock $uv run main.py 처럼 장점이 있으나, 축약된 내용이 있어서 이해가 더 필요하다. uv tutorial youtub \u0026#x1f4a1; uv의 장점\n빠른 속도: 대규모 프로젝트에서 특히 효과적 향상된 의존성 관리: 더 명확한 오류 메시지 캐싱: 반복적인 설치 작업 최적화 pip 명령어와 호환: 기존 워크플로우 유지 가능 \u0026#x26a0;\u0026#xfe0f; 주의사항\nuv는 아직 개발 중인 도구이므로, 일부 기능이 변경될 수 있습니다 pip의 모든 기능을 완벽하게 대체하지는 않을 수 있습니다 프로젝트의 안정성이 중요한 경우, 기존 도구들과 함께 테스트 후 사용하세요 "},{"id":17,"href":"/docs/SE/repo/CI/CD/","title":"Delivery \u0026 Deployment","section":"Countinuous Integration","content":"SW 제품도 점차 서비스화 되면서 발전(?)하게 된 분야이다.\n기준에 package SW (shrinkwrap license) 에서 WEB 을 기반으로 한 서비스로 SW 제품의 성격이 변경되었다.\n기존에 박스를 사서 자시의 PC 에 설치하는 사용하는 것이 이제는 NW에 접속하여 온라인으로 사용하는 것이다.\nRTM (release to manufacturing) 이라고 해서 CD 로 구울 최후 SW 버전의 개념은, 기껏 HW 와 밀접하게 연관되어 있는 SW 로 한정되어 이제는 몇 남지 않아 보인다.\nshrinkwrap contract (license) : the seller considers to have been accepted by the buyer once the package is opened or the product used. deploy 을 어느 user 수준까지 제공하는냐.\n- 완료된 binary 을 누구에게 배포할 것인가?\n. 내부 / 외부\n. discrete (App) / countinuous (WEB))\n. 내부 user (tester, QA)\n. 외부 canary\nA/B\n단계적\n. DevOps\n"},{"id":18,"href":"/docs/SE/Tools/docker/","title":"Docker","section":"Tools","content":"docker 의 등장\nGithub runner 으로 생각해 보는 docker\nSelf-hosted (bare metal vs virtual)\nGithub-Hosted\n"},{"id":19,"href":"/docs/SE/repo/VCS/","title":"VCS","section":"The Repo","content":" 버전 관리 시스템의 진화 # 버전 관리 시스템(VCS)은 소프트웨어 개발에서 코드의 변경사항을 추적하고 관리하는 필수적인 도구입니다. 시대별로 발전해온 VCS의 특징과 장단점을 살펴보겠습니다.\n1. 1세대 VCS: Local VCS (1972~) # : 로컬 시스템에서 파일의 변경사항을 관리\n특징 # 단일 시스템에서 작동 파일 단위의 변경사항 추적 간단한 버전 관리 기능 장점 # 간단하고 빠른 작동 별도의 네트워크 불필요 즉각적인 버전 전환 단점 # 협업 기능 부재 백업의 어려움 버전 충돌 관리 불가능 대표 도구 # RCS (Revision Control System) SCCS (Source Code Control System) 2. 2세대 VCS: Centralized VCS (1986~) # : 중앙 서버를 통한 버전 관리\n특징 # 중앙 서버에 모든 버전 이력 저장 순차적인 버전 번호 부여 클라이언트-서버 모델 장점 # 팀 협업 가능 접근 권한 관리 용이 프로젝트 전체 파악 쉬움 단점 # 중앙 서버 의존성 네트워크 연결 필수 서버 장애 시 작업 불가 대표 도구 # CVS (Concurrent Versions System) SVN (Subversion) Perforce 3. 3세대 VCS: Distributed VCS (2005~) # : 분산형 버전 관리\n특징 # 전체 저장소 복제 로컬에서 커밋 가능 브랜치 작업 용이 고유한 해시 ID로 버전 관리 장점 # 오프라인 작업 가능 빠른 브랜칭과 머징 안정적인 백업 유연한 워크플로우 단점 # 학습 곡선이 높음 저장소 크기 증가 초기 클론 시간 증가 대표 도구 # Git Mercurial Bazaar 4. 4세대 VCS: Cloud-Native \u0026amp; AI-Enhanced VCS (2015~) # : 클라우드 네이티브 환경과 AI 통합\n특징 # 클라우드 기반 확장성 AI 지원 코드 리뷰 자동화된 워크플로우 대규모 코드베이스 최적화 장점 # 무제한 확장성 지능형 코드 분석 통합된 개발 환경 고성능 검색과 분석 단점 # 클라우드 의존성 비용 증가 가능성 보안 고려사항 증가 대표 도구 # VFSforGit (Microsoft) Piper (Google) Cloud Source Repositories VCS 발전 트렌드 # 협업 중심\n실시간 협업 기능 강화 코드 리뷰 프로세스 통합 소셜 코딩 플랫폼화 자동화와 지능화\nAI 기반 코드 분석 및 품질 평가 자동화된 테스트 통합 스마트 충돌 해결 GitHub Copilot 등 AI 코드 리뷰 도구 통합 취약점 자동 감지 및 수정 제안 클라우드 네이티브\n서버리스 아키텍처 컨테이너 통합 마이크로서비스 지원 분산 작업 환경 최적화 모바일/웹 인터페이스 강화 보안 강화\nDevSecOps 통합 개발 초기 단계부터 보안 고려 (Shift Left Security) 지속적인 보안 테스트 자동화 취약점 스캐닝 및 모니터링 고급 접근 제어 세분화된 권한 관리 다중 인증 (MFA) 의무화 감사 로그 강화 코드 서명 및 검증 커밋 서명 의무화 소스 코드 무결성 검증 제3자 종속성 검증 확장성과 성능\n대규모 모노레포 지원 스마트 캐싱 및 부분 클론 분산 저장소 최적화 글로벌 팀 협업 지원 시장 동향\n연간 11.9% 성장률로 2030년까지 27억 달러 시장 규모 예상 클라우드 기반 VCS 수요 증가 AI 통합 도구 시장 확대 모바일 개발 환경 지원 강화 보안 베스트 프랙티스 # 접근 제어\n최소 권한 원칙 적용 정기적인 접근 권한 검토 퇴사자 계정 즉시 비활성화 SSH 키 관리 자동화 코드 보안\n자동화된 보안 스캐닝 의존성 취약점 검사 시크릿 탐지 및 관리 코드 품질 메트릭 모니터링 인프라 보안\n저장소 암호화 네트워크 분리 백업 및 복구 자동화 로깅 및 모니터링 강화 프로세스 보안\n변경 관리 절차 수립 코드 리뷰 의무화 보안 교육 및 인식 제고 인시던트 대응 계획 수립 "},{"id":20,"href":"/docs/SE/repo/REPO/","title":"Repo","section":"The Repo","content":" 4세대 VCS # Monorepo vs Multirepo # 모노레포(Monorepo)와 멀티레포(Multirepo)는 현대 소프트웨어 개발에서 가장 중요한 버전 관리 전략입니다.\n모노레포 (Monorepo) # 정의: 여러 프로젝트의 코드를 단일 저장소에서 관리하는 방식 장점: 코드 공유와 재사용이 용이 원자적 커밋으로 cross-project 변경 관리 가능 통합된 CI/CD 파이프라인 구성 가능 일관된 개발 환경과 도구 사용 단점: 저장소 크기가 커져 성능 이슈 발생 가능 접근 권한 관리가 복잡 빌드 시간이 길어질 수 있음 멀티레포 (Multirepo) # 정의: 각 프로젝트를 독립된 저장소에서 관리하는 방식 장점: 프로젝트별 독립적인 버전 관리 더 명확한 접근 권한 관리 저장소별 가벼운 크기 유지 단점: 코드 재사용이 어려움 프로젝트 간 종속성 관리가 복잡 여러 프로젝트에 걸친 변경사항 관리가 어려움 대규모 기업의 VCS 솔루션 # VFSforGit # Microsoft가 개발한 가상 파일 시스템 기반 Git 확장 대규모 Git 저장소를 효율적으로 관리 필요한 파일만 선택적으로 다운로드하여 작업 가능 Google Piper # Google의 자체 개발 중앙집중식 VCS 수백만 커밋과 페타바이트 규모의 코드 관리 강력한 코드 검색과 분석 기능 제공 현대적 VCS 트렌드 # 하이브리드 접근\n모노레포와 멀티레포의 장점을 결합 메인 프로젝트는 모노레포로, 독립적인 서비스는 멀티레포로 관리 확장성 중심 도구\nGit의 한계를 극복하는 새로운 도구들 등장 클라우드 네이티브 VCS 솔루션 증가 자동화 통합\nCI/CD 파이프라인과의 긴밀한 통합 자동화된 코드 리뷰와 품질 관리 "},{"id":21,"href":"/docs/SE/repo/CI/","title":"Countinuous Integration","section":"The Repo","content":" Contents # GitHub pages 을 만들면서 프로젝트 관리 개념을 익힌다.\n"},{"id":22,"href":"/docs/SE/AI/kaggle/","title":"Data Science","section":"AI","content":" Prerequisites # # 데이터 획득 (Importing a working dataset) 데이터 파악 일변량 (단수변수에 대한 변화) / 다변량 (복수변수의 변화) Summary statistics (기초 통계량, non-graphic) / graphic (시각화) 데이터 변환 모델 적용 (ML) 모델 평가 VSCode with Jupyter extensions # https://code.visualstudio.com/docs/datascience/overview\nVSCode 에 Jupyter extensions 설치하고,\n해당 프로젝트를 github repo 에 저장\n$ python3 -m venv .venv 을 이용해서 virtual 환경 설치\n$ source .venv/bin/activate 으로 virtual 환경 실행\n(.venv)$ pip install ipykerne 으로 Jupyter kernel 설치\n(.venv)$ pip install pandas으로 관련 python 모듈 설치\nJupyter lab (notebook) # https://github.com/jupyterlab/jupyterlab\n$ pip install ipython # or $ pip install jupyter (or notebook) $ pip install jupyterlab $ jupyter lab # or $ jupyter notebook git extension : pip install --upgrade jupyterlab jupyterlab-git\nOther Jupyter # Anaconda 을 설치해서 Jupyter Notebook 사용 (Local) google colab, Kaggle, dacon 에서 제공하는 cloud 커널 을 사용 (Cloud) Jupyter shortcuts # VSCode shortcuts # Kaggel # kaggle 은 Data Science 을 배우기 위한 사이트\nhttps://www.kaggle.com/ - google account https://dacon.io/ - 국내 사이트 Importing a working dataset # kaggle API 1\n$ pip install kaggle 으로 kaggel API 설치\nKaggle API TOKEN을 ~/.kaggle/kaggle.json 에 다운로드,\nkaggle API 을 이용하여 data 다운로드 가능\n# titanic competitions 에서 아래 명령어를 copy 해서 실행 $ kaggle competitions download -c titanic -p /path/to/dest Downloading titanic.zip to /Users/myoungjunesung/pyproject/data 0%| | 0.00/34.1k [00:00\u0026lt;?, ?B/s] 100%|██████████████████████████████████████████████████| 34.1k/34.1k [00:00\u0026lt;00:00, 841kB/s] 적당한 곳에 압축을 풀어서 jupyter nb cell 에서 load\nimport pandas as pd df = pd.read_csv(\u0026#39;./content/titanic/test.csv\u0026#39;) pd 말고 다른 모듈로 로딩하는 경우도 있다.\nUnderstanding the big picture # EDA # raw data 의 description, dictionary 를 통해 데이터의 각 column들과 row의 의미를 이해 결측치 처리 및 데이터필터링 분석 시 필요한 데이터가 수치형 데이터(numerical data)인데 범주형(categorical data)으로 되어 있다면 (데이터 타입이 ‘object’로 뜸) 수치형으로 변환(ex. astype 활용)해줘야 한다. 이해하기 쉬운 시각화 https://www.youtube.com/watch?v=xi0vhXFPegw\nhttps://datascienceschool.net/intro.html\nimport pandas as pd df = pd.read_csv(\u0026#39;./content/titanic/test.csv\u0026#39;) df.shape df.head() df.tail() df.discribe() # 전체적인 통계치 df.info() df.columns # 각 columns 을 보기 indexing\ndf[row index : row index -1] row 출력 df[\u0026#39;row label\u0026#39; : \u0026#39;row label\u0026#39;] lable row 출력 df[\u0026#39;column label\u0026#39;] column label 으로 생각함 (row label 은 오류) df[[\u0026#39;column label\u0026#39;,\u0026#39;column label_2\u0026#39;]] df.column_label # selction by lable df.loc[\u0026#39;row label\u0026#39;] df.loc[[\u0026#39;row lable\u0026#39;,\u0026#39;column label_2\u0026#39;]] # df df.loc[ : , \u0026#39;column label\u0026#39;] # row label 생략 불가 ... df.loc[\u0026#39;row label\u0026#39; : \u0026#39;row label\u0026#39; , \u0026#39;column label\u0026#39; : \u0026#39;column label\u0026#39;] # 연속 df.loc[[\u0026#39;row lable\u0026#39;,\u0026#39;row lable\u0026#39;],[\u0026#39;colum lable\u0026#39;,\u0026#39;column lable\u0026#39;]] # 불연속 # selection by position df.iloc[row index] df.iloc[[row index, row index_2]] # df df.iloc[ : , column index] # row index 생략불가 ... df.iloc[row index : row index-1 , column index : column index -1 ] df.iloc[[row index, rowindex],[row index, row index]] df[[ 'column lable','column lable', ... ]] 을 이용한 column selecting 예\nUseful properties and functions in Pandas\n#수치화모듈 import numpy as np import pandas as pd #pd.set_option(\u0026#39;max_columns\u0026#39;=200) #시각화 모듈 import matplotlib.pylab as plt import seaborn as sns plt.style.use(\u0026#39;ggplot\u0026#39;) .mean() # 평균 .median() # 중앙값 .mode() # 최빈값 plt.hist(titanic.Fare, bin = 5, edgecolor = \u0026#39;gray\u0026#39;) # 히스토그램 plt.xlable(\u0026#39;Fare\u0026#39;) plt.ylable(\u0026#39;Frequency\u0026#39;) plt.show() sns.kdeplot(titanic[\u0026#39;Fare\u0026#39;]) plt.show() plt.boxplot(age) plt.show() Statistics # Variable / Variate # Simple variable(단수 변수) / Multiple Variables (다중변수): X\nunivariate (단/일변량) / multivariate (다변량) : y\n종속변수가 하나이고, 독립변수가 하나인 선형회귀분석 : 단순선형회귀분석( simple liner regression) 종속변수가 하나이고, 독립변수가 2개 이상인 선형회귀분석 : 다중선형회귀분석 (multiple linear regression), 다변수선형회귀분석( multi-variable linear regression) * 다항회귀분석 (polynomial regression). 종속변수가 2개 이상이고, 독립변수가 2개 이상인 회귀분석은 다변량 다중회귀 분석 (multivariate multiple regression). Statistical hypothesis test # : regession / t-test / logistic / chisquare\n통계 검정 방법 설명 적합한 데이터 유형 사용 예시 회귀 분석 변수 간 관계 모델링 및 예측 종속변수: 연속형, 독립변수: 연속/범주형 키와 몸무게 관계, 매출액 예측 t-검정 두 그룹 평균 차이 검정 종속변수: 연속형, 독립변수: 범주형 (2그룹)\n*2그룹 이상 : ANOVA 남녀 학생 키 비교, 교육 방법 효과 비교 로지스틱 회귀 범주형 변수 확률 예측 종속변수: 범주형, 독립변수: 연속/범주형 질병 발병 위험 예측, 고객 이탈 예측 카이제곱 검정 범주형 변수 간 적합성,독립성, 동질성 검정 모든 변수: 범주형 성별과 선호 색상 관계 분석 귀무가설 vs 대립가설 (null hypothesis vs alternative hypothesis) : 알려진 사실 (귀무가설) 상황에서 내가 발견한 것 (대립가설)이 발생할 확률이 유의 수준 (p-value) 보다 작을때, 알려진 사실은 사실이 아닐수도 있지 않을까? Confusion Matrix # Predict Real H0 1 0 H1 0 1 1 0 TF FP 0 1 FN TP https://www.youtube.com/watch?v=xi0vhXFPegw\nhttps://blog.naver.com/dtddtd4861/222985892251\nhttps://github.com/Kaggle/kaggle-api\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":23,"href":"/docs/SE/AI/agent/","title":"Agent","section":"AI","content":" Agent # An AI agent is a system that uses an LLM to decide the control flow of an application. 내용출처\nAgent = LLM + planning + Memory + Tool use : In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components: 내용 출처\nPlanning Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks. Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results. Memory Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn. Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval. Tool use The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more. 3. Agent Type\nFeature LLM Agent (LlmAgent) Workflow Agent Custom Agent (BaseAgent subclass) Primary Function Reasoning, Generation, Tool Use Controlling Agent Execution Flow Implementing Unique Logic/Integrations Core Engine Large Language Model (LLM) Predefined Logic (Sequence, Parallel, Loop) Custom Python Code Determinism Non-deterministic (Flexible) Deterministic (Predictable) Can be either, based on implementation Primary Use Language tasks, Dynamic decisions Structured processes, Orchestration Tailored requirements, Specific workflows Multi-Agent While each agent type serves a distinct purpose, the true power often comes from combining them. You can compose various types of agents derived from BaseAgent to build Multi-agent system Agent Framework # : LLM 이 외부 서비스와 협업을 하면서, 질문에 대한 답을 찾아가게 하는 app, agent 을 구축하기 위해 외부 서비스와 LLM 을 어떻게 조합(?) 할 것인가? There are many frameworks that make agentic systems easier to implement, including: 내용 출처\nLangGraph from LangChain Google ADK agent samples form ADK Langflowis a new, visual framework for building multi-agent and RAG applications. It is open-source, Python-powered, fully customizable, and LLM and vector store agnostic. Microsoft Semantic Kernel is a lightweight, open-source development kit that lets you easily build AI agents and integrate the latest AI models into your C#, Python, or Java codebase. LlamaIndex is a simple, flexible framework for building agentic generative AI applications that allow large language models to work with your data in any format. CrewAI is a lean, lightning-fast Python framework built entirely from scratch—completely independent of LangChain or other agent frameworks. AG2, (formerly AutoGen) is an open-source programming framework for building AI agents Amazon Bedrock\u0026rsquo;s AI Agent framework; Rivet, a drag and drop GUI LLM workflow builder Vellum, another GUI tool for building and testing complex workflows. Marvin is a Python framework for building AI applications with LLMs. Sample Agents # : All the agents in this directory are samples built on different frameworks highlighting different capabilities. Each agent runs as a standalone A2A server.\nBuild an AI agent from scratch in python # : https://youtu.be/bTMPwUgLZf0?si=TZ44h-oOoxAORjoR\nIntegrating REST APIs with OpenAPI # : ADK simplifies interacting with external REST APIs by automatically generating callable tools directly from an OpenAPI Specification (v3.x). This eliminates the need to manually define individual function tools for each API endpoint. 이미지출처\nMCP # The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:\nExpose data through Resources (think of these sort of like GET endpoints; they are used to load information into the LLM\u0026rsquo;s context)\nProvide functionality through Tools (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)\nDefine interaction patterns through Prompts (reusable templates for LLM interactions)\nAnd more!\nPython : https://github.com/modelcontextprotocol/python-sdk\nA2A # https://github.com/google/A2A/\nRAG, Workflow(Chain) vs Agent # 이미지 출처\n이미지 출처\n참고자료 # Google Agent WhitePaper LLM Powered Autonomous Agents\n"},{"id":24,"href":"/docs/SE/AI/vibecoding/","title":"Vibe Coding","section":"AI","content":" What is Vibe Coding # Assembly, C/C++, Python # 물리적인 자원을 더 쉽고, 싸게 사용함에 따라 프로그램밍 언어도 같이 변화 할 수 밖에 없다. 물리적 리소스를 사용하는 컴파일시 더 많은 자원을 사용하고, 코드를 작성하는것은 점점 자연어 (Pseudo code) 코드의 지시형태로 되어 간다.\n0과 1의 기계어로 번역하는 것이 컴파일이라 하면, 자연어를 프로그래밍 syntax 로 변역해 주는 것은 뭐라 불러야 하나?\nAssembley: 컴파일시 물리적 자원 사용은 적지만, 프로그래밍은 난해하다. section .data filename db \u0026#34;test.txt\u0026#34;, 0 ; 파일 이름 content db \u0026#34;test\u0026#34;, 0 ; 쓸 내용 content_len equ $ - content -1 ; 내용 길이 (NULL 문자 제외) section .text global _start _start: ; 파일을 생성하거나 열기 (sys_open) mov rax, 2 ; sys_open 시스템 콜 번호 mov rdi, filename ; 파일 이름 포인터 mov rsi, 0101o ; 플래그 (O_WRONLY | O_CREAT | O_TRUNC) - 쓰기 전용, 없으면 생성, 있으면 내용 삭제 mov rdx, 0644o ; 모드 (rw-r--r--) syscall ; 시스템 콜 호출 mov r12, rax ; 파일 디스크립터를 r12에 저장 (오류 처리 안 함) ; 파일에 쓰기 (sys_write) mov rax, 1 ; sys_write 시스템 콜 번호 mov rdi, r12 ; 파일 디스크립터 mov rsi, content ; 쓸 내용 포인터 mov rdx, content_len ; 쓸 내용 길이 syscall ; 시스템 콜 호출 ; 파일 닫기 (sys_close) mov rax, 3 ; sys_close 시스템 콜 번호 mov rdi, r12 ; 파일 디스크립터 syscall ; 시스템 콜 호출 ; 프로그램 종료 (sys_exit) mov rax, 60 ; sys_exit 시스템 콜 번호 xor rdi, rdi ; 종료 코드 0 syscall ; 시스템 콜 호출 C/C++: 아직까지 syntax 의 벽은 여전히 남아 있다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main() { FILE *fp; fp = fopen(\u0026#34;test.txt\u0026#34;, \u0026#34;w\u0026#34;); if (fp == NULL) { perror(\u0026#34;파일 열기 오류\u0026#34;); return EXIT_FAILURE; } if (fputs(\u0026#34;test\u0026#34;, fp) == EOF) { perror(\u0026#34;파일 쓰기 오류\u0026#34;); fclose(fp); return EXIT_FAILURE; } fclose(fp); return EXIT_SUCCESS; } python 쉽다고 해도, 일상언어는 아니다. try: with open(\u0026#34;test.txt\u0026#34;, \u0026#34;w\u0026#34;) as f: f.write(\u0026#34;test\u0026#34;) except IOError as e: print(f\u0026#34;파일 쓰기 오류: {e}\u0026#34;) Pseudocode: 각 프로그래밍 언어의 syntax 보다 논리적인 구조가 더 중요하게 되었다. 파일 \u0026#34;test.txt\u0026#34;를 쓰기 모드로 연다. 만약 파일 열기에 실패하면, 오류를 출력하고 종료한다. 파일에 \u0026#34;test\u0026#34; 문자열을 쓴다. 파일을 닫는다. vibe coding: 전체적인 context, prompt 등 LLM 적인 요소가 더 중요하게 되었다.\ntest.txt 파일을 열어서 'text'쓰는 코드 작성해줘 Essence and Accident # Pair programming with AI generating code ? Assembly 으로 코딩하던 사람이 C/C++ 으로 코딩하는 것을 보고 어떤 생각이 들었을까? C/C++ 을 사용하지만, Assembly 도 배움. 제품을 위한 코드 보다는 제품 코드를 테스트 하는 코드를 생산 제품을 위한 코드는 의외로 매우 보수적임 (신기술을 적용하기 힘듬) 어떻게 내가 의도하는 코드를 LLM 이 생산하도록 만들것 인가? agent, prompt, context aware, \u0026hellip; Tools # Knowledge Management tool : Notion, Obsidian Access to an LLM : GPT, Claude, Gemini AI Code Editor : Cursor, Windsurf IDE AI Extension : Continue, Cline, AutoPilot, Gemini Code Assist VCS : Git Pre-Vibe Coding Routine # Ideation # 당연히 구현하기 전에 계획은 중요하다. Idea을 작성 지속적으로 구체화하고, 관련자료를 모으고 분류하고, 정보들을 연결한다. 이 모든걸 위해 Knowledge Management tool 이 필요함. Refs. Index # Codebase indexing Online Refs. (e.g., Cursor|Docs) Language Syntax Guide (e.g., Python) Domain Knowledge (e.g., Scipy, Sklearn) Live Refs (e.g., MCP:Brave Search, context7) Persona (Template) # User (e.g., Cursor|User rules) Project (e.g., Cursor|Project rules) \u0026hellip; Product (e.g., Product Requiremet Document) \u0026hellip; Harmonize with SDLC # Design - Code - Test - Build - Deploy Iterative incremental , evolutionary Design # Project \u0026amp; Task management : taskmaster-ai PRD : Notion, Obsidian UI/UX : Figma Diagram : UML, Mermaid Code # Choosing LLM Model AI Code Editor, IDE AI Extentions, Chatbot Cloud vs Local (Open Source) Context-Aware memory Prompt Engineering 잘통하는 prompt는 DB화 할것 Agentic Approch Access to resource (e.g., MCP) Make a Agent (e.g., ADK) Connect Agent to Agent (e.g., A2A) Project Ochestration Managing Non-deterministic Restore checkpoint Human-In-The-Loop AI 생산한 code 의 품질 확보 방안 Build # Android Studio XCode Deploy # App WEB 추가 읽을거리 # kakao AI blog "},{"id":25,"href":"/docs/SE/vibecoding/","title":"Vibe Coding","section":"Job.logging","content":" What is Vibe Coding # Assembly, C/C++, Python # 물리적인 자원을 더 쉽고, 싸게 사용함에 따라 프로그램밍 언어도 같이 변화 할 수 밖에 없다. 물리적 리소스를 사용하는 컴파일시 더 많은 자원을 사용하고, 코드를 작성하는것은 점점 자연어 (Pseudo code) 코드의 지시형태로 되어 간다.\n0과 1의 기계어로 번역하는 것이 컴파일이라 하면, 자연어를 프로그래밍 syntax 로 변역해 주는 것은 뭐라 불러야 하나?\nAssembley: 컴파일시 물리적 자원 사용은 적지만, 프로그래밍은 난해하다. section .data filename db \u0026#34;test.txt\u0026#34;, 0 ; 파일 이름 content db \u0026#34;test\u0026#34;, 0 ; 쓸 내용 content_len equ $ - content -1 ; 내용 길이 (NULL 문자 제외) section .text global _start _start: ; 파일을 생성하거나 열기 (sys_open) mov rax, 2 ; sys_open 시스템 콜 번호 mov rdi, filename ; 파일 이름 포인터 mov rsi, 0101o ; 플래그 (O_WRONLY | O_CREAT | O_TRUNC) - 쓰기 전용, 없으면 생성, 있으면 내용 삭제 mov rdx, 0644o ; 모드 (rw-r--r--) syscall ; 시스템 콜 호출 mov r12, rax ; 파일 디스크립터를 r12에 저장 (오류 처리 안 함) ; 파일에 쓰기 (sys_write) mov rax, 1 ; sys_write 시스템 콜 번호 mov rdi, r12 ; 파일 디스크립터 mov rsi, content ; 쓸 내용 포인터 mov rdx, content_len ; 쓸 내용 길이 syscall ; 시스템 콜 호출 ; 파일 닫기 (sys_close) mov rax, 3 ; sys_close 시스템 콜 번호 mov rdi, r12 ; 파일 디스크립터 syscall ; 시스템 콜 호출 ; 프로그램 종료 (sys_exit) mov rax, 60 ; sys_exit 시스템 콜 번호 xor rdi, rdi ; 종료 코드 0 syscall ; 시스템 콜 호출 C/C++: 아직까지 syntax 의 벽은 여전히 남아 있다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main() { FILE *fp; fp = fopen(\u0026#34;test.txt\u0026#34;, \u0026#34;w\u0026#34;); if (fp == NULL) { perror(\u0026#34;파일 열기 오류\u0026#34;); return EXIT_FAILURE; } if (fputs(\u0026#34;test\u0026#34;, fp) == EOF) { perror(\u0026#34;파일 쓰기 오류\u0026#34;); fclose(fp); return EXIT_FAILURE; } fclose(fp); return EXIT_SUCCESS; } python 쉽다고 해도, 일상언어는 아니다. try: with open(\u0026#34;test.txt\u0026#34;, \u0026#34;w\u0026#34;) as f: f.write(\u0026#34;test\u0026#34;) except IOError as e: print(f\u0026#34;파일 쓰기 오류: {e}\u0026#34;) Pseudocode: 각 프로그래밍 언어의 syntax 보다 논리적인 구조가 더 중요하게 되었다. 파일 \u0026#34;test.txt\u0026#34;를 쓰기 모드로 연다. 만약 파일 열기에 실패하면, 오류를 출력하고 종료한다. 파일에 \u0026#34;test\u0026#34; 문자열을 쓴다. 파일을 닫는다. vibe coding: 전체적인 context, prompt 등 LLM 적인 요소가 더 중요하게 되었다.\ntest.txt 파일을 열어서 'text'쓰는 코드 작성해줘 Essence and Accident # Pair programming with AI generating code ? Assembly 으로 코딩하던 사람이 C/C++ 으로 코딩하는 것을 보고 어떤 생각이 들었을까? C/C++ 을 사용하지만, Assembly 도 배움. 제품을 위한 코드 보다는 제품 코드를 테스트 하는 코드를 생산 제품을 위한 코드는 의외로 매우 보수적임 (신기술을 적용하기 힘듬) 어떻게 내가 의도하는 코드를 LLM 이 생산하도록 만들것 인가? agent, prompt, context aware, \u0026hellip; Tools # Knowledge Management tool : Notion, Obsidian Access to an LLM : GPT, Claude, Gemini AI Code Editor : Cursor, Windsurf IDE AI Extension : Continue, Cline, AutoPilot, Gemini Code Assist VCS : Git Pre-Vibe Coding Routine # Ideation # 당연히 구현하기 전에 계획은 중요하다. Idea을 작성 지속적으로 구체화하고, 관련자료를 모으고 분류하고, 정보들을 연결한다. 이 모든걸 위해 Knowledge Management tool 이 필요함. Refs. Index # Codebase indexing Online Refs. (e.g., Cursor|Docs) Language Syntax Guide (e.g., Python) Domain Knowledge (e.g., Scipy, Sklearn) Live Refs (e.g., MCP:Brave Search, context7) Persona (Template) # User (e.g., Cursor|User rules) Project (e.g., Cursor|Project rules) \u0026hellip; Product (e.g., Product Requiremet Document) \u0026hellip; Harmonize with SDLC # Design - Code - Test - Build - Deploy Iterative incremental , evolutionary Design # Project \u0026amp; Task management : taskmaster-ai PRD : Notion, Obsidian UI/UX : Figma Diagram : UML, Mermaid Code # Choosing LLM Model AI Code Editor, IDE AI Extentions, Chatbot Cloud vs Local (Open Source) Context-Aware memory Prompt Engineering 잘통하는 prompt는 DB화 할것 Agentic Approch Access to resource (e.g., MCP) Make a Agent (e.g., ADK) Connect Agent to Agent (e.g., A2A) Project Ochestration Managing Non-deterministic Restore checkpoint Human-In-The-Loop AI 생산한 code 의 품질 확보 방안 Build # Android Studio XCode Deploy # App WEB 추가 읽을거리 # kakao AI blog "},{"id":26,"href":"/docs/SE/AI/Cursor/","title":"Cursor","section":"AI","content":" LLM 환경 구축 개요 # 이 문서는 다양한 LLM(Large Language Model)을 활용하여 로컬 개발 환경을 구축하는 데 필요한 도구와 기술을 소개합니다. Cloud LLM부터 로컬 실행 도구, 개발 환경 연동 도구까지 폭넓게 다룹니다.\n1. Cloud LLM (클라우드 기반 모델) # 클라우드 서버에서 강력한 성능을 제공하는 상용 LLM입니다. API를 통해 접근하며, 고성능 추론 능력이 필요할 때 유용합니다.\nGPT (OpenAI): https://platform.openai.com/docs/models 주요 특징: 강력한 자연어 이해 및 생성 능력, 다양한 모델(GPT-4, GPT-4o 등) 제공, 광범위한 API 생태계. 가격: 사용량 기반 유료 (API 호출당 과금), ChatGPT는 무료/유료 구독 플랜 제공. 활용: 챗봇, 콘텐츠 생성, 코드 생성, 번역 등. Gemini (Google): https://deepmind.google/technologies/gemini/ 주요 특징: 멀티모달(텍스트, 이미지, 오디오, 비디오) 처리 능력, 다양한 크기(Ultra, Pro, Flash, Nano) 제공, Google 생태계 연동. 가격: 사용량 기반 유료 (Vertex AI API), Google AI Studio 및 Gemini 앱에서 무료/유료 플랜 제공. 활용: 멀티모달 콘텐츠 생성, 복잡한 추론, 데이터 분석, Google Workspace 연동. Claude (Anthropic): https://www.anthropic.com/claude 주요 특징: 안전성 및 윤리성 강조(Constitutional AI), 긴 컨텍스트 처리 능력, 창의적 글쓰기 및 코딩 능력. 가격: 사용량 기반 유료 (API), Claude.ai 웹사이트 및 앱에서 무료/유료 플랜 제공. 활용: 긴 문서 요약/분석, 창의적 글쓰기, 안전한 대화형 AI 개발. Grok (xAI): https://x.ai/grok 주요 특징: 실시간 정보 접근(X 플랫폼 연동), 유머러스하고 반항적인 페르소나, 최신 정보 기반 답변. 가격: X Premium+ 구독 필요. API 접근은 별도 제공될 수 있음. 활용: 최신 뉴스/트렌드 기반 질의응답, 특정 관점의 정보 탐색. Perplexity: https://www.perplexity.ai/ 주요 특징: AI 기반 검색 엔진과 챗봇 기술 결합, GPT-4/Claude 3 등 최신 모델 활용, 실시간 웹 검색 및 Q\u0026amp;A, 복잡한 추론을 위한 o13 시리즈 모델 제공. 가격: 무료 플랜, Pro 구독(일 300회+ Pro 검색), Enterprise 플랜 제공. 활용: 실시간 정보 검색/분석, 학술 연구, 코딩 문제 해결, 복잡한 추론 작업. 차별점: 실시간 웹 검색 통합으로 최신 정보 제공(다른 LLM들의 학습 데이터 제한 극복), 모든 답변에 대한 출처 링크 제공으로 신뢰성 확보, 검색 엔진과 LLM의 하이브리드 접근으로 정확성 향상. 2. Open LLM \u0026amp; Hub (오픈소스 모델과 허브) # 대표적인 Open Source LLM:\nLlama (Meta) GPT-4.5, Claude 3.7 Sonnet 수준의 STEM 성능 달성 128k 토큰의 긴 컨텍스트 윈도우 지원 8개 언어 지원 및 강화된 안전성 기능 탑재 Mistral / Mixtral (Mistral AI) Llama 2 70B 대비 6배 빠른 추론 속도와 더 높은 성능 코드 생성, 수학, 추론 능력에서 뛰어난 성능 140개 이상 언어 지원 및 고급 함수 호출 기능 Gemma (Google) Gemini 기술 기반의 경량 오픈소스 모델 고해상도 비정사각형 이미지 처리 및 향상된 추론 능력 단일 GPU/TPU에서 실행 가능한 최고 성능 모델 Phi (Microsoft) 동일 크기 및 상위 크기 모델 대비 우수한 성능 20만 단어 어휘로 다국어 지원 강화 그룹 쿼리 어텐션, 내장 함수 호출 기능 제공 Qwen (Alibaba) GPT-4o, DeepSeek-V3, Llama-3.1-405B 대비 우수한 성능 텍스트, 이미지, 오디오, 비디오 통합 처리 가능 32k 토큰 컨텍스트와 강화된 추론 능력 HuggingFace: https://huggingface.co/\n오픈소스 LLM 모델과 데이터셋을 공유하고 협업하는 플랫폼입니다.\n주요 특징: 방대한 모델/데이터셋 저장소(Hub), 모델 학습/추론 라이브러리(Transformers, Diffusers 등), 데모 공유(Spaces), LLM 리더보드, 학습 코스 제공. 가격: 대부분 무료, 유료 플랜(추가 기능, 우선 지원 등) 제공. 활용: 오픈소스 모델 탐색/다운로드, 모델 파인튜닝, AI 애플리케이션 개발/배포. 3. Local LLM Launcher (로컬 실행 도구) # 로컬 컴퓨터 환경에서 LLM을 쉽게 다운로드하고 실행할 수 있도록 돕는 GUI/CLI 기반 도구입니다.\nLM Studio: https://lmstudio.ai/\n주요 특징: 사용자 친화적인 GUI, 모델 검색/다운로드/관리 용이, 다양한 모델 포맷 지원(GGUF 등), 내장 채팅 인터페이스 및 API 서버 기능. 지원 모델: HuggingFace 등에서 제공되는 GGUF 포맷 모델 대부분. 가격: 무료. 설치: 웹사이트에서 OS별(Mac, Windows, Linux) 설치 파일 다운로드. Ollama: https://ollama.com/\n주요 특징: CLI 중심의 간편한 모델 실행/관리, 자체 모델 라이브러리 운영, API 서버 기능 기본 제공, 다양한 커뮤니티 통합 지원. 지원 모델: 자체 라이브러리 모델(Llama, Mistral, Gemma 등 다수) 및 GGUF 모델 임포트. 가격: 무료. 설치: 웹사이트에서 OS별(Mac, Windows, Linux) 설치 파일 다운로드 또는 CLI 명령어(curl, brew 등). 비교 요약 (Local LLM Launcher):\n특징 LM Studio Ollama 인터페이스 GUI 중심 (채팅 포함) CLI 중심 (API 서버 주력) 모델 관리 GUI 내 검색/다운로드 CLI 명령어 (pull, run) 주요 사용자층 초보자, GUI 선호 사용자 개발자, CLI 선호 사용자 생태계 자체 기능 중심 다양한 외부 도구 연동 활발 4. LLM 지원 로컬 툴 (개발 환경 연동) # 로컬 개발 환경(IDE, 텍스트 에디터 등) 내에서 LLM 기능을 활용할 수 있도록 돕는 도구들입니다.\nAI Code Editor : Cursor, Windsuf AI Code Extension : Continue, Cline, Copilot, Gemini Code Assist AI luncher : Claud Desk top, Witcy, Enconvo Obsidian + AI community plug-in (SmartComposer, Copilot, \u0026hellip;) 4.1 AI Code Editor (AI 네이티브 에디터) # LLM 기능이 깊숙이 통합된 코드 에디터입니다.\nCursor: https://www.cursor.com/en\n주요 특징: VS Code 기반, AI 기반 코드 생성/편집/리팩토링, \u0026ldquo;Codebase-aware\u0026rdquo; 채팅, 로컬 모델 연동 지원(설정 필요). 지원 모델: OpenAI 모델(기본), Anthropic 모델, Azure OpenAI, 로컬 모델(Ollama, LM Studio 등 연동). 가격: 무료 플랜(제한적 사용), 유료 Pro/Business 플랜. 설치: 웹사이트에서 OS별 설치 파일 다운로드. Cursor 커뮤니티,Cursor MCP, Rule \u0026hellip; 활용예시 : cursor + git + obsidian Windsurf: https://codeium.com/windsurf\n주요 특징: Codeium 개발, 빠른 자동 완성, Context Engine 기반 이해, 다중 파일 편집 지원, 경량화 추구. 지원 모델: Codeium 자체 모델, 로컬 모델 연동 지원 논의 중/개발 중. 가격: 현재 무료 (베타 기간 등 정책 변동 가능). 설치: 웹사이트에서 OS별 설치 파일 다운로드. 비교 요약 (Code Editor):\n특징 Cursor Windsurf (Codeium) 기반 VS Code Fork 자체 개발 (경량화) 핵심 기능 코드베이스 이해, 채팅 중심 빠른 자동완성, 컨텍스트 엔진 로컬 모델 지원 (Ollama, LM Studio 등) 제한적/개발 중 가격 무료/유료 플랜 현재 무료 4.2 Extension, Plug-in (IDE 확장 기능) # 기존 IDE(VScode)에 설치하여 LLM 기능을 추가하는 확장 프로그램입니다.\nContinue: https://www.continue.dev/\n주요 특징: 오픈소스, 다양한 모델(로컬/클라우드) 연결 유연성, 사용자 정의 컨텍스트 제공(파일, 터미널 등), 자동 완성 및 채팅. 지원 모델: OpenAI, Anthropic, Google, Mistral, Ollama, LM Studio 등 다수. 가격: 무료 (오픈소스). 설치: VS Code, JetBrains 마켓플레이스에서 설치. Cline: https://cline.bot/\n주요 특징: 오픈소스, 자율 코딩 에이전트 지향, Plan/Act 모드, 터미널 실행, MCP(Model Context Protocol) 지원. 지원 모델: OpenAI, Anthropic, Google, Ollama, LM Studio 등 다수. 가격: 무료 (오픈소스). 설치: VS Code 마켓플레이스에서 설치. GitHub Copilot: https://github.com/features/copilot\n주요 특징: GitHub/OpenAI 개발, 강력한 코드 자동 완성 및 제안, 채팅 기능(Copilot Chat), 광범위한 언어/IDE 지원. 지원 모델: OpenAI 모델(GPT 기반). 가격: 유료 구독 (개인/비즈니스), 학생/오픈소스 기여자 무료. 설치: 각 IDE 마켓플레이스에서 설치 (VS Code, JetBrains 등). Gemini Code Assist: https://developers.google.com/gemini-code-assist\n주요 특징: Google 개발, 코드 자동 완성, 디버깅 지원, 프로그래밍 개념 학습 지원, GitHub 통합 지원 모델: Google Gemini 가격: 개인 사용자 무료, 기업용 Standard/Enterprise 버전 유료 설치: VS Code, JetBrains IDE, Cloud Shell Editor에서 설치 가능 비교 요약 (Extension, Plug-in):\n특징 Continue Cline GitHub Copilot Gemini Code Assist 개발 주체 커뮤니티 (오픈소스) 커뮤니티 (오픈소스) GitHub/OpenAI Google 핵심 기능 모델 유연성, 컨텍스트 자율 에이전트, MCP 코드 완성, 채팅 코드 완성, 디버깅, 학습 로컬 모델 지원 매우 우수 (Ollama 등) 매우 우수 (Ollama 등) 제한적/미지원 미지원 가격 무료 무료 유료 (일부 무료) 무료 (기업용 유료) 활용 예시:\nOllama 또는 LM Studio를 사용하여 로컬에 Llama 3 모델을 실행시킨 후, Continue 또는 Cline 확장 프로그램을 통해 VS Code에서 해당 로컬 모델을 코드 생성 및 분석에 활용할 수 있습니다. 이를 통해 민감한 코드를 외부로 전송하지 않고 AI 지원을 받을 수 있습니다. 4.3 AI launcher (데스크톱 애플리케이션) # 독립적으로 실행되는 LLM 관련 데스크톱 애플리케이션입니다.\nClaude desktop: https://claude.ai/download\n주요 특징: Anthropic의 Claude 모델 공식 데스크톱 앱, 웹 버전 기능 대부분 제공, 파일 업로드 및 분석 용이, MCP 지원. 지원 모델: Claude 모델. 가격: 웹 버전과 동일 (무료/유료 플랜). 설치: 웹사이트에서 OS(Mac, Windows)별 설치 파일 다운로드. Witsy: https://witsyai.com/\n주요 특징: 다양한 LLM API 키 등록(BYOK) 방식, 채팅, 이미지 생성, 프롬프트 라이브러리, \u0026lsquo;Prompt Anywhere\u0026rsquo; 기능. 지원 모델: OpenAI, Anthropic, Google, Mistral, Ollama 등 다수 API/로컬 모델 연동. 가격: 무료/유료 플랜. 설치: 웹사이트에서 OS(Mac, Windows, Linux)별 설치 파일 다운로드. Enconvo: https://www.enconvo.ai/\n주요 특징: macOS용 AI 에이전트 런처, 150개 이상 내장 도구, 워크플로우 자동화, MCP 지원. 지원 모델: OpenAI, Anthropic 등 Cloud LLM 및 로컬 모델 연동. 가격: 유료 구독. 설치: 웹사이트에서 macOS 설치 파일 다운로드. 비교 요약 (Desktop tools):\n특징 Claude desktop Witsy Enconvo 주요 기능 Claude 모델 접근 다중 LLM 통합, 유틸리티 워크플로우 자동화 (macOS) 개발 주체 Anthropic 개인/팀 개발 개인/팀 개발 플랫폼 Mac, Windows Mac, Windows, Linux macOS 가격 무료/유료 플랜 무료/유료 플랜 유료 구독 5. MCP (Model Context Protocol) # 애플리케이션과 AI 모델 간의 컨텍스트 정보 교환을 표준화하는 개방형 프로토콜입니다.\n주요 특징: LLM이 외부 도구/데이터 소스와 안전하고 표준화된 방식으로 상호작용하도록 지원, 개발 생산성 향상, 도구 간 상호 운용성 증대. 활용: AI 에이전트 개발, 외부 API 연동, 코드베이스/데이터베이스 접근 등. 관련 도구: Cline, Claude desktop, Enconvo 등 MCP를 지원하는 클라이언트/서버 구현체 다수 존재. 공식 사이트: https://modelcontextprotocol.io/ 서버 목록 (GitHub): https://github.com/modelcontextprotocol/servers 서버 레지스트리: https://mcp-get.com/, https://smithery.ai 이 문서는 계속 업데이트될 수 있습니다.\n"},{"id":27,"href":"/docs/SE/hugo/Obsidian/","title":"Obsidian","section":"Hugo Tips","content":" Obsidian + Github + Hugo # 1. Obsidian 기본 정보 (웹 검색 기반):\n로컬 저장: 데이터가 사용자 기기에 직접 저장되어 데이터 소유권과 프라이버시 보장. Live Preview: Source 형태 edit ( VScode) 가 아닌 문서 형태로 edit (Scrivener)가능 마크다운 기반: 표준 마크다운 문법 사용. 양방향 링크 (백링크): 노트 간 연결을 통해 아이디어를 네트워크처럼 구성. 그래프 뷰: 노트 연결 관계 시각화. 플러그인: 다양한 커뮤니티 플러그인을 통한 기능 확장. (예: git, copilot, smart compose \u0026hellip;) 2. 일반적인 Obsidian 사용 시 장점:\n데이터 완전 통제: 클라우드 종속성 및 위험 회피. (로컬저장) 유연성/확장성: 표준 마크다운 호환성, 플러그인을 통한 맞춤 설정. 지식 연결: 아이디어 관계 발견 및 지식 구조화 용이 (예: 제텔카스텐). 오프라인 작업: 인터넷 연결 없이 사용 가능. 3. 일반적인 Obsidian 사용 시 단점:\n학습 곡선: 기능, 플러그인, 마크다운 적응 시간 필요. 동기화 설정: 여러 기기 사용 시 직접 동기화 솔루션 설정 필요 (유료 Obsidian Sync 또는 외부 서비스). 모바일 기능 제한: 데스크톱 대비 기능 제한 가능성. 협업 기능 부족: 기본적으로 개인용 앱. 4. 사용자 Vault 분석 (smjune.github.io):\nSteps : Obsidian 에서 마크다운 글 작성 -\u0026gt; Hugo server 로 로컬에서 Publish 확인 -\u0026gt; GitHub Repository Push -\u0026gt; Github actions: Hugo -\u0026gt; 웹사이트 (Github Pages) 게시 방식으로 추정됩니다. 5. 사용자 Vault 활용 방식의 장점:\n통합 워크플로우: 콘텐츠 생성부터 발행까지 효율적 관리. 버전 관리: Git으로 콘텐츠 변경 이력 관리 및 복구 용이. 무료 배포/호스팅: Hugo/GitHub Pages 활용. (cf.정식 Published site) 6. 사용자 Vault 활용 방식의 단점 (일반 Obsidian 사용 비교):\n지식 연결 기능 활용 제한: 웹사이트 발행 목적에 치중하여 개인 지식 연결/탐색 기능 활용 저하 가능성. 민감 정보 관리 주의: 공개될 수 있는 GitHub 저장소 특성상 비공개 정보 관리에 주의 필요 (.gitignore 등). 동기화 복잡성: Git 기반 동기화 시 충돌 해결 및 모바일 사용 불편 가능성. Obsidian 고유 기능 활용 저하: 웹사이트 관리 위주로 플러그인 활용이 제한될 수 있음. Template : 배포를 위해 Hugo front matter 과 Themes format 을 유지해야 함. 7. 더 생각해 볼것:\nObsidian의 핵심인 개인 지식 연결 기능 활용을 제한할 수 있고, Git 동기화 및 민감 정보 관리에 신경 써야 하는 단점이 있다.\n따라서, obsidian/github/hugo 간 구조을 잘 설정해야 한다.\n구성방식 # git, Obsidian, Hugo 가 모두 한 폴더에 설정, . my_project # git, Obsidian vault, Hugo project ├── .git ├── .obsidian ├── hugo.yml ├── content/posts # publish folder ├── no_publish_folder └── no_sync_folder #.gitignore git 과 Obsidian Vault 가 설정된 하위 폴더로 hugo project (publish 대상 폴더) 와 no_publish 폴더를 구분하여 hugo project 는 hugo 에서 정의한 방식으로 폴더를 구성하고, no_publish 는 일반적인 obsidian 폴더를 구성 . my_project # git, Obsidian vault ├── .git ├── .obsidian ├── publish_folder/ # Hugo Project │ ├── hugo.yml │ └── content/posts ├── no_publish_folder └── no_sync_folder #.gitignore Obsidain 하위에 sync/publish 할 메모 대상으로 만 git 설정 . my_project # Obsidian vault ├── .obsidian ├── sync_publish_folder/ # git, Hugo project │ ├── .git │ ├── hugo.yml │ └── content/posts └── no_sync_publish_folder // . my_project # Obsidian vault ├── .obsidian ├── sync_publish_folder/ # git project │ ├── .git │ ├── publish_folder/ # Hugo project │ │ ├── hugo.yml │ │ └── content/posts │ └── no_publish_folder └── no_sync_folderr git 하위에 Obsidian 과 Hugo 을 구성하여, Publish 을 위해 Hugo 구성할때 VSCode 을 사용하여 obsidian vault 에 있는 메모를 content/posts 으로 복사한다. . my_project # git project └── .git/ ├── Obsidian_Valut/ # Obsidian Vault │ ├── .obsidian │ ├── syn_folder │ └── no_syn_folder (.gitignore) └── Hugo_project / # Hugo project ├── hugo.yml └── content/posts 사용하고 있는 구조 # . smjune.github.io # git, Obsidian vault ├── .git ├── .obsidian ├── Hugo/ # Hugo Project │ ├── hugo.yml │ └── content # published │ ├── docs │ └── posts ├── Source # sync but not yet publish └── Local #.gitignore 주의할 점 : Hugo 관련 명령어는 Hugo 폴더로 이동하여 수행한다. (gh-pages.yml(workflow) 에서 주의할것) Hugo 로 이동하는 md 는 Hugo themes 에 맞는 front matter 을 갖추어야 한다. 이를 위해 사전에 template 을 정의 하고, obsidian 의 insert template 을 사용한다. --- title: \u0026#34;{{Title}}\u0026#34; description: date: \u0026#34;{{date:YYYY-MM-DD}}T{{time:HH:mm:ss}}+09:00\u0026#34; draft: true --- Community Plug-In # 활용법: AI Plug-In 인 SmartComposer 로 gemini-20-flash-thinking 으로 관련 내용을 생성\nSmartComposer output (gemini-20-flash-thinking)\nGit: Obsidian Vault를 Git 저장소로 만들어 버전 관리 및 GitHub 등과의 동기화를 가능하게 합니다. .git 폴더를 Obsidian Vault 안에 생성하여 Git 명령어를 Obsidian 내에서 실행하거나 외부 Git 도구와 연동할 수 있습니다. 이를 통해 노트 변경 이력 관리, 협업, 백업 등에 유용하게 활용됩니다. Templater: 템플릿 기능을 제공하여, 노트 작성 시 미리 정의된 템플릿을 불러와 빠르게 내용을 채울 수 있게 합니다. 날짜, 제목, 사용자 정의 변수 등을 템플릿에 활용하여 생산성을 높이고, 반복적인 문서 양식을 효율적으로 관리할 수 있습니다. 코드 스니펫, frontmatter, 정형화된 보고서 등에 유용합니다. Copilot: OpenAI Codex 모델 기반으로 코드 및 텍스트 자동 완성 기능을 제공합니다. Obsidian에서 글을 쓸 때 문맥을 파악하여 자연스러운 문장 완성을 돕고, 코드 작성 시에도 자동 완성 및 추천 기능을 제공하여 생산성을 향상시킵니다. 아이디어 구상, 초안 작성, 코드 작성 등 다양한 상황에서 활용 가능합니다. Smart Composer: 노트 작성을 위한 다양한 편집 기능을 제공합니다. 문장 병합, 분할, 순서 변경, 스타일 변경 등 고급 편집 기능을 통해 글쓰기 흐름을 개선하고 효율적인 문서 작성을 지원합니다. 긴 문서를 다듬거나, 아이디어를 구조화하고 재구성할 때 유용합니다. Cursor 결과와 비교\nCursor output (sequential thinking, brave-search)\nGit: Obsidian 노트 저장소를 Git으로 버전 관리합니다. 자동 커밋 및 동기화 기능을 제공하여 백업 및 협업을 용이하게 합니다. 변경 이력을 추적하고 이전 버전으로 복구할 수 있습니다. GitHub, GitLab 등 다양한 Git 호스팅 서비스와 연동 가능합니다. Templater: 노트 작성을 자동화하는 강력한 템플릿 플러그인입니다. 변수, 함수, JavaScript 코드를 사용하여 동적인 템플릿을 만들 수 있습니다. 반복적인 작업을 줄이고 일관된 형식의 노트를 생성하는 데 유용합니다. 날짜, 시간, 파일 정보 등 다양한 내장 변수와 함수를 제공합니다. Copilot: AI 기반 글쓰기 보조 플러그인입니다. 노트 내용 요약, 아이디어 생성, 문장 완성 등 다양한 AI 기능을 제공합니다. OpenAI 등 여러 LLM 모델을 지원하며, Vault 내 노트를 기반으로 답변을 생성할 수 있습니다. (Vault QA 모드) 개인 정보 보호에 중점을 둔 AI 어시스턴트입니다. Smart Composer: AI 기반의 맥락 인식 글쓰기 보조 플러그인입니다. Cursor AI와 유사하게, Vault 내 특정 파일이나 폴더를 참조하여 대화하고 편집 제안을 받습니다. AI가 제안한 내용을 클릭 한 번으로 적용할 수 있습니다. Vault 내용 기반 대화, 시맨틱 검색, 로컬 모델 지원 등의 기능을 제공합니다. 최근 Gemini 모델 및 이미지 지원이 추가되었습니다. ] LM studio + Local LLM # SmartComposer 에서 Cloud LLM 을 사용하지 않고, Local LLM 을 사용하기 위해 local 환경 구축\nLM Studio 에서 자신에 local 환경에 맞는 모델을 download 하여 실행한다. Obsidian | community plug-in | Smart Composer 에서 lm-studio 을 설정하고 해당 모델을 입력 한다. Clould LLM 과 Local LLM 비교\n각 LLM 의 성능 차이는 분명히 존재 한다. 같은 모델을 Cloud 와 Local 에서 비교해 보면 좋을것 같은데, 성능이 좋은 LLM 의 경우 Local 에서 운영하는데는 한계가 있다.\n\u0026ndash; gemini-20-flash-thinking (Cloud) 한번에 원하는 대답을 보여준다.\n오늘 추가된 내용은 다음과 같습니다.\nObsidian, Github, Hugo 간 구조 설정에 대한 고민과 함께 발생할 수 있는 개인 지식 연결 기능 활용 제한 및 Git 동기화/민감 정보 관리의 단점을 \u0026ldquo;7. 더 생각해 볼것\u0026rdquo; 섹션에 추가했습니다. Obsidian Community Plugin 섹션을 추가하여, AI Plug-in 인 SmartComposer 와 Cursor 의 플러그인 검색 결과를 비교 분석했습니다. Git, Templater, Copilot, Smart Composer 플러그인에 대한 두 검색 결과의 요약 내용을 비교했습니다. LM Studio 와 Local LLM 섹션을 추가하여, SmartComposer 에서 Cloud LLM 대신 Local LLM 을 사용하는 방법에 대한 안내와 함께, Gemini (Cloud LLM) 와 Gemma (Local LLM) 의 SmartComposer 출력 결과를 비교했습니다. \u0026ndash; lmstudio:gemma3_12b_it (Local : LM studio) 바로 한번에 바로 요약해 주시 못하는데, 뭔가 자세하게 말해야 할 것 같다. (agent 모드 가 안되는 것으로 보인다.)\n\u0026ndash; MCP 같은 툴을 사용하지 못하는 것이 아쉽다. -\u0026gt; think 모드가 지원되는 모델을 사용해야 할듯\n최근 추가된 내용은 다음과 같습니다:\nObsidian 플러그인(Git, Templater, Copilot, Smart Composer) 사용법과 LM Studio를 활용하여 Obsidian 내 AI 지원을 강화하는 방법에 대한 설명입니다. 각 플러그인의 기능과 클라우드 LLM과 로컬 LLM의 차이점을 비교합니다.\n"},{"id":28,"href":"/posts/empathy/","title":"사람들은 자신이 무엇을 원하는지 모른다","section":"Writing.logging","content":" \u0026ldquo;소비자는 자신이 원하는 것을 직접 보기 전까지는 자신이 무엇을 원하는지 조차 모른다\u0026rdquo;\n사실 이런 명제에 대해 오래전부터 마케팅쪽 (소비심리학에서는 \u0026lsquo;소비자의 말을 믿지 말라\u0026rsquo; 라고 말한다) 에서 논의되고 있고, 계속해서 연구되었던 것이였는데, 어느순간 오로지 한 개인의 경영철학처럼 뉴스에 회자되면서 유명해 졌다.\n처음 이말을 들었을때 나는 무척 혼란스러웠다. 회사에서 제품을 만드는 일을 하고 있는 사람이지만, 나 또한 한 사람의 소비자이기도 하기 때문이다. 과연 나도 내가 원하는 것을 직접보기 전까지 내가 무엇을 원하는지 모르고 있는 걸까? 그렇다며는 왜 그런것일까? 생산/소비의 영역에 대해서만 그런것일까? 과연 이 말을 사람들 속에서 살아가는 한 사람으로써 어떤 의미로 받아 들여야 할찌 무척 당황스러웠다.\n나는 이 문장을 오로지 이해하기 위해 범위를 확대시켜 쉽게 이해할 수 있는 단순한 문장으로 바꿔 보았다. \u0026ldquo;사람들은 자신이 무엇을 원하는지 모른다.\u0026rdquo; # ※ 아래 동영상 줄거리\n어느 한 노인이 길거리에서 도움을 구하고 있다. 그는 더군다나 앞을 보지 못한다.\n\u0026lsquo;I\u0026rsquo;m Blind, Please help\u0026rsquo; 라고 써있는 푯말을 있었지만, 그의 주변에 어느 누구도 그에게 별로 관심이 없다.\n어느 한 여성이 그에게 관심을 보인다.\n그러곤 그와 세상의 유일한 소통도구인 푯말에 무언가를 열심히 쓴 후 사라진다.\n그녀가 사라진 뒤 무슨 마법의 가루가 뿌려진 것처럼 사람들이 그에게 도움을 주기 시작한다.\n그녀가 다시 돌아오고 그 앞에 섰을때 그는 묻는다. \u0026ldquo;도대체 내 푯말에 뭐라고 썼나요\u0026rdquo;\n그녀는 \u0026ldquo;같은 말이에요. 저는 단지 단어만 바꿨을 뿐이에요\u0026rdquo; 라고 말한다.\n\u0026#x1f3ac; 동영상 보기 : http://www.youtube.com/watch?v=CKvvSLC29Ws\n\u0026#x1f6ab; (2023.2 안타깝게도 현재 이 동영상은 사라지고 없다.)\n흔히 사람들이 원하는 것이 \u0026lsquo;진실\u0026rsquo; 혹은 \u0026lsquo;사실\u0026rsquo; 이라고 믿고 있다. 다시 말해 \u0026lsquo;진실\u0026rsquo;, \u0026lsquo;사실\u0026rsquo; 만으로 사람들이 행동을 유발시킬 수 있다고 믿는 것이다. 하지만 그것 만으로는 부족하다. 사실을 이해한다고 해서 쉽게 행동으로 이어지지는 않기 때문이다. 위 동영상에서 주변 사람들이 혹시 이렇게 생각하고 있지는 않은지\u0026hellip;.\u0026ldquo;당신이 앞을 보지 못하는 것은 사실이고, 이해했습니다. 그러나 왜 도움을 주고 싶은 마음이 생기지 않을까요?\u0026rdquo;\n항상 옳은 일이라고 생각된다고 반드시 이루어 지는 것은 아닌듯 하다. 전 직장에서 업무 프로세스를 바꾸면 업무가 쉬어지고, 효율적으로 변화 될 수 있다는 것을 많은 현장 실무자들 (주로 \u0026lsquo;현업을 모른다\u0026rsquo;라는 이유로 반대하는 사람들) 에게 설득해야만 했다. 이를 위해 나는 회사내 데이터들을 모으고, 이를 거부할 수 없는 공학이론에 입각하여 증명을 하려고 전전긍긍하고 있었을때, 사장님께서 오시더니 이런 말씀을 하셨다. 그 때는 절대 이해 할 수 없었던 말\u0026hellip;\n\u0026ldquo;이론으로 증명해 내려고 하지 마라. 이미 이론은 많은 사람들에게서 옳다고 증명되었다.\n자네가 좋다고 느낀것을 그들도 똑같이 느낄수 있는 방법을 찾아봐라\u0026rdquo;\n( 2023.2, 지금 생각해 보니, 에토스/파토스/로고스 에 관하여 말씀해주신 것 같다.)\n출처: 다음 웹툰 \u0026lsquo;미생\u0026rsquo; 120수 중에서, 그때 나도 오차장의 노하우 \u0026ldquo;감정적 지불\u0026quot;을 알았더라면\n(※ 감정적 지불 : \u0026lsquo;스튜어트 다이아몬드\u0026rsquo;의 저서 \u0026lsquo;어떻게 원하는 것을 얻는가\u0026rsquo;의 협상 전략 중 청취자가 감정적으로 변하면 상대의 말을 듣지 않게 되므로, 공감과 사과와 같은 행동으로 청취자가 다시 이성적인 판단을 할 수 있도록 유도하는 것을 말함.)\n혹시 동영상의 사람들과 전 직장의 동료들을 포함하여 사람들은 \u0026lsquo;사실의 전달, 이해\u0026rsquo; 보다 \u0026lsquo;감정의 공유, 감동\u0026rsquo;을 더 원하고 있는 것이 아닐까? 따라서 나는 위의 명제를 다시 바꿔보았다.\n사람들이 원하는 것은 \u0026lsquo;사실의 전달 보다 감정의 공유\u0026rsquo;이다. 그러나 그것을 본인 조차 인정하지 않는다. # \u0026ldquo;아빠 무서워 ~ \u0026quot;\n어린 아들이 천둥 \u0026#x1f4a5; , 번개 \u0026#x26a1; 가 치는 밤이 무섭다고 한다. 진정 이 아이가 원하는 것은 무엇일까? \u0026ldquo;구름이 움직이다가 아래쪽으로 (지면) 음전하 채워지고 위쪽은 양전하로 대전된단다. 이때 아래쪽의 음전하와 땅 위의 양전하의 기전력의 차이에 의해 방전이 일어나게 되는데 이것을 번개라고 해. 천둥이라는 것은 번개가 나타날 때 같이 나타나는 소리인데 번개가 칠 때의 30000K의 고온이 발생하기 때문에 주변 공기가 팽창하게 되어 천둥을 울리게 되는 것이야. 단순한 기상 현상이니까 무서워할 필요 없어.\u0026rdquo;\n아이가 원하는 것이 위와 같은 기상현상의 과학적 설명 아니면 \u0026lsquo;번개는 하느님께서 사진찍으시는 것이니 무서워 말고 웃어 \u0026ldquo;김치~\u0026rdquo; \u0026lsquo;류의 허무 개그는 아닐 것이다.\n출처: \u0026lsquo;하늘이 보내준 딸\u0026rsquo; 네이버 영화\n아이가 원하는 것은 감정의 공유. 즉, 자신의 공포감을 같이 공감해 주고, 보살핌 (사랑) 을 달라는 것이다. 그냥 아무말 없이 꼬~옥 안아주는 것이 최선이 아닐까? \u0026lsquo;애야 사실은 아빠도 무섭단다. 하지만 우리 같이 있으니까 혼자 일때 보다 무섭지 않는데.\u0026rsquo; 라고 이야기 해주면서 말이다. (그런후 점진적으로 번개가 무서운개 아니라는 것을 좋아하는 캐릭터를 이용하여 설명해 주거나, 관련 책을 함께 일어주면 좋다.)\n아이들은 표현에 솔직하다. 자신의 감정을 있는 그대로 반복적으로 표현한다. 아이들보다 더 능숙한 협상가를 나는 본적이 없다. 자신이 원하는 것을 정확하게 알고 있으며, 어떻게 하면 쉽게 얻어낼 수 있는지도 잘 알고 있다. \u0026lsquo;국내 약 60% 초등학생이 오늘처럼 천둥번개가 치는 밤을 무서워 하고, 성인의 약 20%도 그렇다는 조사 결과가 있습니다. 초3학년인 제가 오늘 같은 밤 무서워 하는것은 당연합니다. 그러니 \u0026hellip; \u0026rsquo; 라고 사실적이고, 객관적이면서 이성적인 대화를 시도하진 않지만 적어도 자신의 감정에 솔직하다. 계속해서 \u0026lsquo;무서워, 무섭단 말이야\u0026rsquo; \u0026hellip;.. 만 소리를 지르며 되풀이 하면서.\n언제부턴가 우리는 자신의 감정을 숨기고 이성적으로 살아야 한다고 배워왔던것 같다. 그리고 그 배움의 결과로 우리 사회는 좋아지고 있으며, 더 합리적으로 바뀌었다고 생각한다. 그리고 사람들은 자신이 늘 이성적이고, 또 그래야만 한다고 생각한다. 하지만 사실은 감정적인 것에 더 영향을 받고 있다. 우리가 무언가를 판단하고 선택하는데 있어서 이성적이기보다 감성적인면에 의해 결정한다는 것에 동의를 못하시겠다면, 한가지 예를 들어 보겠다.\n사람들은 자신이 이성적이라고 생각하지만, 감정에 얼마나 많은 판단과 선택을 맞기고 있는지 모르고 있다. Empathy : 사람들을 움직이는 마술 같은 힘 # 거금을 주고 산 휴대폰이 간단한 버튼이 고장이 났다고 하자, 당신은 AS센터에 가서 고장난 버튼에 대해 이성적으로 당신이 무상 수리를 받아야 한다는 것에 대해 논리적으로 설명할 것이다. 그러면 센터 직원은 고장의 내용을 확인하고, 버튼의 제질은 어떻고, 가공한 기술이 저떻고 하며 논리적이고 합리적인 설명과 함께 수리를 해 준다. 당신은 만족하였는가?\n※ 최근 기즈모도 기사에 등장한 고객 대응 매뉴얼을 보면, 먼저 고객과 감정을 공유해야 한다고 적혀 있다.\n출처 :\u0026lsquo;How To Be a Genius: Secret Employee Training Manual\n어쩌면 당신은 AS센터에서 보상받고 싶은것은 완벽한 제품의 수리가 아닐것이다. 혹시 당신의 마음에 난 상처(?)에 대한 공감일것이다. 더 정확하게 자신이 했던 판단에 대한 또 한번의 확신이다. 100만원이나 되는 제품을 사기위해 무수히 많은 정보를 검색하고, 주변의 의견을 듣고, 먼저 구입한 사람의 것을 써보면서 이것 저것 장단점을 비교한 후 결정을 내렸을 것이다. 자신의 결정으로 산 제품이 단 일주일만에 고장이 났다는 것은 자신의 결정이 틀릴수도 있다는 것을 의미한다. 비록 AS 센터에 가서 버튼이 튼튼하지 않다는등 불만을 이야기 하지만, 정작 원하는 것은\n\u0026lsquo;제가 이제품을 사기위해 몇달을 고민하고, 몇일간 정보를 분석하여 결정한건데 일주일만에 고장나면, 저는 제대로 물건을 보지 못하는 사람이 되어 버립니다. 「내가 한 판단이 옳으며 나는 물건을 제대로 고를줄 아는 사람이다」 라는 신념(혹은 자부심)이 받은 상처를 치료해 주세요\u0026rsquo;\n일 것이다.\n그러나 절대 그렇게 말하지 않는다.\n(적어도 내 경우는 이렇게 말하고 싶지만, 바보 취급 받을것 같아서 말하지 않는다.)\n비슷하게 쿼드코어, HD 아몰레드, 이런 기술적 설명들은 사용자에게 의미가 없어 보인다. 문제는 그것들이 나를 얼마나 Cool 하게 보여지게 만들어 주느냐인 것이다. 감정을 이해하기보다, 사용자의 만족감을 추구하기보다 (그럴려면 많이 들어야 한다.) 기술을 뽐내기 위해 지식을 장황하게 설명하지는 않았는지 반성해 봐야 한다.\n배 만드는 법을 알려주지 말고, 바다에 대한 동경을 심어주어라 - 생떽쥐베리 # 소프트역량이라는 의미를 나 나름대로 생각해 본다면 지금까지 말한 감성을 중심으로 한 접근방법을 말하는 것이 아닐까 생각한다. 최근 감성마케팅 (emotional marketing) 은 좋은 예 일것 같다. \u0026ldquo;이런 차를 타고 다니면 이런 이미지로 당신은 다른 사람들에게 보여질 수 있습니다. \u0026quot; ~ 류의 광고가 많은 이유이다. 브레이크가 어쩌구, 강판이 저쩌구, 엔진이 이러쿵 저러쿵.. 다 쓸때 없는 이야기이다. 우리는 물건을 사기도 하지만 그 물건이 주는 이미지를 사기도 한다. 퇴근한 남편 혹은 아빠가 뜬굼없이 시금치 한단을 사왔다. 왜 사왔냐고 했더니, 오는길에 할머니가 야채를 길에서 팔고 계시는데 돌아가신 어머니 생각이 나서 그냥 샀다는 것이다. 이 사람은 시금치를 산것이 아니라 어머니에 대한 그리움을 (감정) 산것이다.\n이제 글의 마지막으로 가면서 나에게는 2가지 질문이 남는다.\n첫째는 사람들이 원하는것, 정확하게 공유하고자 하는 감정을 쉽게 찾아 낼 수 있는 방법은 무엇일까? 둘째는 내가 느낀것(혹은 찾아낸것)을 다른 이들도 똑같이 느끼게 할 수 있는 방법은 (어떤한 행동을 유발하기 위해) 무엇일까? 출처: 감성이 더해진 날씨 정보 www.takeweather.com\n\u0026#x26c4; \u0026#x1f4a6; 얼음이 녹으면 \u0026hellip;, 뭐가 되는지 알아?\u0026hellip;\n첫째 질문에 답은 대상에 대한 많은 정보가 바탕이 되어야 한다는 것이다. 지니어스들의 매뉴얼 사례 (Human Beings 101 부분) 에서 보여지듯이 사람들은 자신이 원하는 것을 정확하게 표현하지 못한다 하더라도 사람들은 자신이 원하는 것에 대한 무수한 많은 흔적을들 (혹은 무의식적 행동) 남기게 된다. 이런 흔적을 초능력과 같은 신비한 힘으로 알아차리는 사람들도 있었지만, (우리들도 대상이 가족, 친구 혹은 적을때는 쉽게 가능하겠지만, 불특정 다수의 수백,수천만명을 대상으로 한다면 전문가에게 의뢰해야 한다.)\n최근 디지털 소비가 증가하면서 사람들이 무의식중에 남긴 디지털 부스러기들을 차곡차곡 쌓고 이를 분석하므로 어느정도 예상할 수 있게 되었다. (맨 위 동영상에서 푯말을 고친 여성이 주변 사람들이 좋은 날씨에 대해 다른 친구들과 주고 받는 Twitter 나 Facebook, 혹은 takeweather (http://www.takeweather.com/) 을 분석해서 공감 포인트인 \u0026ldquo;날씨\u0026rdquo; 를 찾은건 아닐까 상상해 본다. 물론 직감적으로 그것을 알아 감지해 내는 사람도 있다.) Big Data를 이용한 소비자의 행동 패턴을 분석하는 것도 어쩌면 사람들의 감성적 성향, 공감 포인트를 찾기위함인 것이다.\n※ 우리는 이런 bond 가 없기에 교감하기 위해 뭔가 다른 방법이 필요하다.\n출처 : Naver 영화 AVATAR 2009 중\n이렇게 얻어진 대상 감정를 쉽게 공감하게 만드는 방법중에 하나는 바로 이야기를 이용하는 것이다. 생떽쥐베리의 말을 바탕으로 생각해 보면, 어떻게 바다에 대한 동경을 심어 줄것인가를 생각해 보면 간단하게 답이 나올것 같다. 바다에 관련된 영웅전, 탐험가들의 이야기를 이야기해 주고, 아름다운 바다의 모습 사진, 그림을 보여 주면 가능 하지 않을까? 심적 이미지를 이용한 이야기전달이 사람들로 하여금 쉽게 공감을 얻을 수 있을 것이다. (이미 우리는 어렸을때 동화책을 보며 익숙해져왔던 것들이다. 그런데 왜 어른이 되어선 잊고 지냈을까? 아마도 성장하면서 이성적이어야 한다는 것을 강요받은 것은 아닐런지) 이야기로 전달 할때 몇가지 Tip이 필요하다. 먼저 이야기에는 주인공이 있어야 되며, 그 주인공의 새로운 도전과 방해 세력, 이들과의 갈등과 극복이 있어야 한다.\n(누군가를 설득하고, 생각과 행동의 변화를 이끌어 내기 위해서는 진심어린 감정의 공유 (공감) 와 이를 전달할 수 있는 심적 이미지, 그리고 이야기가 필요하다. 그것이 사람들이 진정 원하는 것이다. )\n"},{"id":29,"href":"/posts/story/","title":"호랑이는 죽어서 가죽을 남기고, 사람은 죽어서 이야기를 남긴다","section":"Writing.logging","content":"[많은 사람들이 이야기를 기억하고 있는 영화 \u0026lsquo;인생은 아름다워\u0026rsquo;]\nSTORY # \u0026ldquo;2차 세계대전 이탈리아, 나치의 유태인 말살정책에 의해 한 남자와 아내, 그리고 어른들 세상의 변화를 아직은 이해할 수 없는 나이의 어린 아들, 이렇게 세식구는 살던 마을을 떠나 유대인 수용소로 강제 수용된다. 자신이 온 곳은 어디이며, 왜 왔는지 궁금해하는 아들을 위해 아버지는 자신들은 게임을 하기위해 선발된 것이며, 이곳에서 게임을 하면서 1,000점을 먼저 따는사람은 탱크을 받게 된다고 이야기해 준다.\u0026rdquo;\n이 이야기는 1997년 개봉한 (국내 1999년 개봉) 영화 \u0026lsquo;인생은 아름다워\u0026rsquo; 의 기본 줄거리 입니다. 15년이 지난 이 영화의 기본적인 줄거리는 많은 사람들이 기억하지만 주인공인 바로 그 한 남자의 이름을 기억하는 사람은 많이 않을 것 입니다. 그렇다면 사람은 죽어서 남기는 것은 무엇일까요? 이름? 이야기?\nQUESTION # 이렇듯 우리는 왜 이야기 듣기에 익숙해져 있으며, 또한 흥미를 가지고 목말라하는 것일까요? 이유는 태어나면서 부터 우리는 이야기를 듣는것에 익숙해져 있기 때문입니다.\n※ 물론 사람의 뇌중 측두엽이 이야기 구조를 잘 기억한다던가, 인지심리학적 이론에서 이미 많이 주장되었던 내용이다.\n[ 어린시절 읽었던 동화 백설공주와 최근 헐리우드에 불고 있는 시리즈들]\n아니 어머니의 뱃 속에서부터 흥미진진한 모험과 사랑 이야기를 느끼기 시작하여, 태어나면서 저를 포함하여 이 세상의 모든 부모님들이 그렇듯 읽어 주시는 이야기에 무릎에 앉아서 혹은 잠자리에 누워 그분들의 목소리에 귀기울이며 백설공주을 내쫓고 웃는 계모의 웃음 소리에 움찔하거나, 백마를 탄 왕자님의 등장에 가슴이 두근 거리곤 했기 때문일 것입니다.\n바로 그 이야기를 통해 사랑, 행복, 설래임, 분노 같은 감정을 배워 왔기에 다른 이의 이야기를 듣기를 원하고 이야기를 들음으로써 심리적 공감을 찾는 것은 어찌보면 당연하게 생각됩니다. 이렇게 우리는 사람으로써 느낄수 있는 온갖것들을 어린시절 이야기를 통해서 배워왔던 것입니다.\nNARRATIVE # 우리가 세상을 인식하는 방식도 바로 \u0026lsquo;이야기\u0026rsquo; 입니다.\n위에서 소개해드린 \u0026lsquo;인생은 아름다워\u0026rsquo;에서 귀도(아버지)가 아들 조슈아에게 세상의 변화를 이야기로 이해시켜 줍니다. 아들은 이를 믿고 아버지가 이야기준 대로 그토록 갖고 싶었던 탱크를 받기위한 게임으로 수용소에서의 생활을 즐겁게 잘 버텨내며, 마침내 마지막 숨바꼭질 게임 후 다음날 아침 탱크를 선물(?)로 받게 됩니다.\n위에서 언급한 \u0026ldquo;세상을 이야기로 인식한다\u0026quot;는 사상을 바탕으로 \u0026lsquo;스토리\u0026rsquo;라는 책 (티모시 윌슨, 웅진지식하우스) 에서는 이를 이용한 심리학적 행동 개선 방법을 제시하고 있습니다.\n책에서는 사람들은 벌어진 사실에 대해서 이야기로 (Narrative 혹은, Story) 인식하며, 이 이야기를 약간만 외부에서 조정 (Stroy edit) 해 줌으로써 좋은 방향으로 사실을 인식시켜 행동을 개선할 수 있다고 합니다. 예를 들어 대학교에 입학하자 마자 치룬 시험에 D학점을 받은 학생이 \u0026lsquo;역시 나의 한계는 여기까지인가 보다 고등학교에서 처럼 여기서는 통한지 않나보다\u0026rsquo; 라고 생각 할 수도 있고, \u0026lsquo;공부 하는 방식을 옛날 방식을 그대로 했기 때문에 이렇게 된것 같아, 이제 공부 방식을 바꿔고 이것에 익숙해 지면 성적은 더 좋아질거야\u0026rsquo; 라고 생각 할 수도 있습니다. 핵심은 후자인 좋은 이야기를 스스로 만들어 낼 수 있도록 (당사자가 눈치채지않고) 주변에서 적절한 도움을 주어야 한다는 것 입니다.\n※ 이 외 육아와 청소년, 그리고 사회 관계에서의 이야기를 통한 행동 개선 처방전이 더 있다. 개인적으로 초등학생 아이을 둔 아버지로써, 아이들에 대한 행동 교정을 위한 보상과 처벌에 대한 부분은 매우 흥미로왔다. 이제부터라도 아이에게 그들이 이해할 수 있는 이야기로 설명을 해 주어야 겠다.\n우리가 세상을 이야기로 받아들이고, 바로 그 이야기를 통해 누군가를 설득하거나, 행동을 변하게 할 수 있다면 어떻게 이야기를 만들어서 전달할 것인가는 매우 중요일이 되버렸습니다.\nTELLING # 자신이 하는일에 대해서 사람들이 쉽게 이해할 수 있는 이야기를 만들어 내고, 적절하게 전달한다는 것은 분명 쉬운 일은 아닙니다. 그러나 적절한 이야기 구성폼과 이를 쉽게 정리할 수 있는 도구가 있다면 그렇게 어려운 일 또한 아닙니다.\n흔이 이야기를 함으로써 전달하고자 핵심가치와 이를 대변할 수 있는 주인공, 그 와 상반되는 적대 세력과 조력자, 그리고 적대 세력과의 갈등 속에서 주인공이 조력자의 도움을 통해 핵심 가치를 찾아가는 과정이 있어야 한다고 합니다.\n다시 말해 앞에서 언급한 \u0026lsquo;인생은 아름다워\u0026rsquo;의 이야기를 쉽게 기억하고, 그 의미가 잘 전달되었는 이유는 아래와 같은 이야기 구조를 갖고 있기 때문 입니다. 주인공이 처한 제한적인 상황 : 2차 세계대전 불안전한 주인공 : 유대인으로 수용소에 갖힘 새로운 도전 : 수용소의 생활에서 가족과 함께 살아남기 (1,000점을 따기 위한 게임) 조력자 : 아버지 방해세력 : 나치 (수용소) 갈등극복 : 전쟁에서 살아 남음 이러한 이야기 구조는 \u0026lsquo;인생은 아름다워\u0026rsquo; 뿐만 아니라 다른 영화에서도 발견할 수 있습니다.\n하지만 나열식이 아닌 적절한 툴을 이용하여 표현해 보겠습니다.\n[스타워즈, 타이타닉, 아바타 에서의 스토리 전개 방식]\n( 2023.3, 그림내 오타 수정 : 조지 루카스 -\u0026gt; 루크 스카이워커 )\nMIND MAP # 이야기 구조를 잘 표현하고, 구조적이면서 생각의 발생을 쉽게 표현할 수 있으며, 도식화할 수 있는 툴이 있다면 이야기 말들기는 더 쉬워질 수 있습니다.\nMind Map 은 이야기 구조를 표현하는데 아주 훌륭한 툴입니다. 말 그대로 마음의 지도 인데, 이것이 곧 우리가 외부 세계를 인식하는 형상화된 모습이며, 이 형상화 된 모습을 시간의 흐름, 혹은 인과관계 등로 표현한다면 하나의 훌륭한 \u0026ldquo;STORY\u0026rdquo; 가 만들어 질 수 있기 때문 입니다.\n[마인드맵은 토니 부잔이 1960년대 만들어 학교 및 IBM, 골드만삭스, 보잉, GM 등 글로벌 기업들이 사원교육에 활용중이다.]\n위 그림은 Mind Map을 설명한 간단한 Mind Map 입니다. 단순하게 나열하는 설명보다 도식화된 요소들이 쉽게 눈에 들어 오고, 보는 사람에 따라 그림을 보고 쉽게 적절한 이야기로 설명할 수 있지 않을까요.\n누군가에게 프리젠테이션을 하거나, 보고서를 쓰거나, 적절한 설명이 필요할 때, 이에 알맞는 이야기를 만들어 제공한다면, 그 효과는 매우 클것이라는 것을 우리는 알고 있습니다. 또한 그러한 이야기를 만들기 위해서는 적절한 구성 요소가 갖춰져야 하고, 이를 잘 표현할 수 있는 툴이 있다면 이러한 과정은 생각보다 쉬울 수 있습니다. "},{"id":30,"href":"/posts/coffee/","title":"이공계는 글쓰기가 두렵다","section":"Writing.logging","content":"\u0026ldquo;출처:David McCandless\u0026rdquo;\n주변에 커피 전문점이 급속도록 번성하면서 커피를 마시는 기회가 많아졌다. 그 만큼 커피의 선택도 많아질 수 밖에 없을 것이다. 최근까지 달콤한 맛에 반해 \u0026lsquo;카페모카\u0026rsquo;를 즐겨 마셨지만, 정작 그 속에 뭐가 들어 가는지는 모르고 있던 차에 한장에 그림을 보게 되었는데, 이 그림을 통해 그 전에 그렇게 설명을 들어도 기억 나지 않았던 \u0026lsquo;카페모카\u0026rsquo; 의 내용물 (?) 에 대해 쉽게 이해 하게 되고, 예전 말로만 설명을 들었을때 처럼 기억 못하는 일이 없어 졌다.\n최근들어 위와 같은 Data visualizatioin류 기술(?) 들이 사람들의 관심을 끌고 있다. 그 분야중 수 많은 관련 정보를 한장의 그림으로 표현하는 Infographics 는 그 효용가치에 많은 사람들이 사용하고, 급기야 서울시 12년 예산안 (아래 Tree 중 왼쪽 그림) 으로도 사용되기도 했다. 관련하여 지금 소개하는 동영상은 위 커피 그림을 그린(?) David McCandless (http://www.davidmccandless.com/ ) 의 TED에서 강연한 내용인데 그의 경력만큼이나 재미난 이야기들이 있다. 이 글의 제목과 대표 이미지인 \u0026lsquo;정보는 아름답다\u0026rsquo; (Information is beautiful) 는 최근 그의 Infographics 의 사례집으로 아래 동영상에서 소개되는 흥미로운 사례들을 포함 하여 많은 그림(?) 들이 있다. (참고로 이런 visual 류를 좋아하는 사람들이라면 www.visualizing.org 도 방문해 보는것도 좋다.)\n대부분의 사람들은 넘처나는 정보로 인하여 어려움을 겪고 있지만, 이를 해결하기 위한 간단한 방법이 있으며, 그것은 바로 지금보다 더 많이 시각을 이용하는 것이다. 정보를 시각화 하므로 패턴과 그 사이의 의미 있는 관계를 알아 낼 수 있습니다. 이를 더욱 그럴듯하게 만들거나, 이야기를 전달하게 하거나, 중요한 점에 집중할 수 있도록 디자인 할 수 있습니다. 그렇지 못한다 하더라도 그 차체로도 정보는 아름답습니다.\n이글을 읽는 대부분의 독자들이 저와 같은 Engineer 라는 점을 생각한다면, 지금까지의 이야기는 어떤 면에서 그림에 떡을 수도 있다. 물론 어느 누구에 뒤지지 않을 많큼 많은 데이터를 가지고 있고, 또한 관련자들에게 (혹은 이해 수준이 초,중학생 수준인 해당 영역의 비 관련자에게도) 그 내용을 요점만 정리하여 이해를 시켜야 하는 책임이 있음에도 불구하고 이러한 것들이 그림에 떡으로 밖에 느껴질 수 없는 이유는 아마도 본인에게는 그 만큼의 많은 데이터가 없다고 오해하거나, 본인에게 디자인이란 재능도 없고, 번거롭고, (공대생이였던) 대학시절 인문대 식당에서 밥을 먹는 것 만큼 오글거림을 주기 때문은 아닐까?\n먼저 몇몇분들이 지금 하고 있는 업무가 곤란을 겪을 만큼의 많은 량의 정보를 다루지도 않다고 생각하는 것에 데이터의 물리적 량으로만 기준을 삼는다면 옳은 말일 수 도 있다. 하지만 데이터의 량이 작다고 해서 그것을 정리하고 한눈에 보기 좋게 만들거나, 누구나 (초,중학생) 이해할 수 있는 정도의 그걸듯한 모습으로 변화 시켜야하는 필요성이 없다고 말할 수 없고, 또 조금만 더 주위를 둘러 보면 이미 충분한 데이터를 가지고 있게 마련이다. 하루에 받는 메일 수 하며, 내가 작성하는 문서, 그리고 그 속에 담긴 관련 정보들을 하나 하나 나열하다 보면 충분히 시각적인 요소가 필요하다는 것을 느낄수 있을 것이다. 그래도 데이터량이 작다고 생각이 든다면 하루, 한달, 일년의 긴 시간을 두고 진행하는 롱텀 업무에 대해 생각해 보길 권하겠다.\n그리고 두번째로 디자인이라는 미적요소에 대해 \u0026lsquo;엔지니어들이 어떻게 디자인을 할 수 있겠는가?\u0026rsquo; 라는 의문에 대해서도 충분히 동감한다. 하지만 디자인을 보는 관점을 적절한 요소들의 선정과 배치 라는 keyword만을 놓고 본다면 이야기는 달라질 수 있다. 물론 색감, 다양한 도형과 이미지, 일러스트와 같은 미적인 요소를 배제하고서 디자인이라 말할 수 없다라고 생각 할 수도 있다. 그러나 정작 중요한 것은 내가 전달하고자 하는 의미에 맞게 각 요소들이 나눠져 있고, 또한 적절히 모아져 있으며, 이것들이 보기 좋게 배치 되어 있는가을 생각한다면 이 디지인이라 요소도 그렇게 어려운 요소만은 아닐것이다.\n그렇다고 엔지니어도 디자인을 배워야 한다고 주장하고 싶지는 않다. 몇 해 전에는 이공계에게 글쓰기를 강조하던 분위기였는데 거기에다 이젠 디자인까지 \u0026hellip; 물론 글쓰기와 디자인적인 Liberal 한 재능이나 소양이 이미 있다면 고마운 일이지만 어찌되었건 이공계 출신으로써 살아가기가 점점 힘들어지는 것 같다. 그렇다고 언제까지 새로운 트랜드를 강건너 불구경하듯 뒷짐지고 바라만 보고 있을수는 없는 노릇이기에 우리의 도전은 또 시작된다. 이런 도전을 쉽게 해결할 수 있는 방법을 하나 제시한다면 바로 Mind Map 이다. 넘처나는 정보의 시대에 한사람이 다루어야 할 정보의 량이 몇년전 보다 몇 배는 증가한 상황에서 이를 적절히 시각화해야 하는 필요성은 날로 높아만 지고 있다. 이를 쉽게 지원해 줄 수 있는 툴이 Mind Map 이다. 굳이 예쁜 디자인이 들어가지 않는다 하더라도 충분히 시각화에 의한 전달력에 있어서 경쟁력이 있다.\nInfographics # Infographics의 구성을 가만히 살펴 보면 Mind Map에서 제공하는 포맷과 매우 유사한점이 많다. 그렇다고 해서 Infographics 에서 제공하는 Full HD급 이미지를 완벽하게 재현 할 수 있다는 듯은 아니다. Liberal 한 요소에 목마른 엔지니어들의 목을 축일 정도의 디자인적 요소를 갖추고 있는 것으로도 충분히 사용해 볼만하다.\n여러가지 형태의 Infographics 가 있을 수 있지만 대표되면 몇가지를 추려 보면 Tree 형태, Time line 형태, Clustering(constrast) 형태로 분류할 수 있는데. 이런 형태는 쉽게 Mind Map 으로도 표현이 가능한 부분이다.\nHierachy (Tree) # 아래 그림을 보자 왼편에 Infographics와 오른편에 그와 유사한 Mind Map 형식을 배치해 보았다. 혹시 왼편의 Infographics을 만들기 위해 디자이너에게 보낸 원장(Origial content) 의 모습이 혹시 오른편의 Mind Map 이 였다면 이것을 받은 디자이너도 심미적인 요소만을 고려하여 쉽게 디자인 할 수 있지 않을까? (She said \u0026hellip; 도 들어봐야 하겠지만 말이다.)\n큰 의미를 중앙에 배치하고, 서브 요소들을 Tree 형태로 배치하는 것은 Mind Map의 큰 특징이기고 하다. Table (표) 형태와 쉽게 컨버전 되는 형태이기도 하다.\nTime Line # 두번째는Time Line 형태로 변화된 모습이나 사건을 시간의 축으로 배치하는 형태이다. (공간의 제약상 좌우가 아닌 상하로 배치함)\nClustering # 세번째는 군집형태이다. 위 Tree와 다른 점이라면 중심에 서브를 배치하기 보다 관계를 표현하는 것이다. 군집 표현에서 각 노드의 색을 군집별로 같은 색으로 지정한다면 쉽게 구분이 될 수 있으므로 적극 활용하기를 권한다.\n최근들어 Infographics와 비슷하게 많은 관심을 받고 있는 Social Service 가 있는데 바로 \u0026ldquo;Curation\u0026rdquo; 이다. Pinterest (www.pinterest.com) 로 대표 되는 Curation 은 이미지 중심의 의사전달 방식의 Social Media에서의 본격적인 진입이라 볼 수 있다. (패션, 여행, 음식, 인테리어 등 여성이 관심이 많은 분야중심으로 활용되는터라 타 SNS(Google+ 는 남탕)와 비교하여 여성의 비율이 높다는 요소도 흥미로운 점이지만) 이제는 140자 단문도 길어서 한장의 이미지로 의사소통을 하는 것을 선호하는 것을 볼때 더욱 Infographics의 활용은 증가 할 것이다. 나 자신도 어느때 부터인가 Text 검색 보다 Image 검색을 더 선호하고, 바로 Text 검색을 하기 보다 이미지를 먼저 찾은 다음 그와 연결된 text cotent를 찾아가기 시작했다. (이미지 검색 후 해당 이미지를 가지고 있는 뉴스, 블로그 등 으로 이동 한다.) 이제는 글을 쓰더라고 자신의 글을 대표하는 이미지 없이 글을 쓴다는 것은 바다를 향해 소리치는 공허한 메아리가 되는 것은 아닌지 고민해 볼만하다. "},{"id":31,"href":"/posts/trash/","title":"쓰레기 고고학","section":"Writing.logging","content":" \u0026ldquo;하인리히 슐리만, 옛 트로이, 영화 트로이\u0026rdquo;\n트로이의 발굴자 하인리히 슐리만 (Heinrich Schliemann, 1822 ~ 1890) , 트로이 옛모습, 영화 트로이 : 지금까지 증거가 없다고 모든 것이 다 신화이며 허구인것만은 아니다, 때때로 누군가에 의해 그런 오해는 깨뜨려지기 마련이다.\n엉뚱한 이야기 같지만, 고등학교 시절 \u0026lsquo;쓰레기 고고학 (Garbage Archaeology)\u0026rsquo; 라는 것에 흥미를 갖었던 적이 있었다. 쓰레기를 조사하면 그 지역 사람들의 삶과 생활상을 알아낼수 있다는 간단한 논리인데 사춘기였던 그 시절 이것을 접하고 내 방 쓰레기통을 스스로 살펴본 결과, 큰 충격을 받았던 기억이 있다. 누가 보더라도 쉽게 알수 있을 정도로 나의 관심사와 생활들이 쓰레기통에 적나라하게 흔적으로 남아 있었기 때문이다.\n그 때문인지는 모르겠으나 지금까지도 Windows의 쓰레기통 이나, IE의 접속 log를 살펴보는 버릇이 있다. (아들녀석이 무엇을 검색했으며, 어느 사이트에 잘 접속을 하고, 무엇을 보는지\u0026hellip; 궁금하기 때문이다. 다행인지 아직 초등5인 아들 녀석은 컴퓨터를 쓴 후 증거를 삭제하는 방법을 모르는듯 하다.)\n이제는 그 동안 우리가 Garbage 로 생각했던, 혹은 Noise 라고 생각했던 Log 파일들, 실패한 실험 데이터, 무수히 많은 기기들에서 발생되는 신호들을 체계적으로 적재하고 분석할 수 있는 기술을 갖게 되었다. (참고 : Minority Report로 풀어보는 Big Data) 그러나 누구에겐 여전히 쓰레기에 불과한 것들 일것이고, 누구에게는 엄청난 가치를 찾아낼 수 있는 원석이 되기도 할 것이다. Bit Data # 과거의 가시화를 통한 미래예측은 Big Data 분석의 핵심이 되어 버렸다.\nBig Data라는 단어는 최근에 회자되고 있지만 사실 그 방식은 예전부터 해왔던 일들이다. 단지 대상이 빠르고, 다양하게 커지고 있다는 차이일 뿐이다. 10여년전에 Package SW회사에서 근무했던적이 있었다. Package SW에서 중요한 의사결정 중 하나는 출시시점(RTM : Release To Manufacture) 을 정하는 일이며, 이와 밀접하게 관련된는 판단 요소가 \u0026lsquo;제품의 품질\u0026rsquo;, 쉽게 말해서 \u0026lsquo;프로그램에 있는 오류 수\u0026rsquo;이다. (Package SW는 MS Office 나 AhnLab V3같이 CD 등 으로 사용자에게 배포되어 PC에 설치, 사용하는 SW를 말한다. 기업에서 업무를 컴퓨터 프로그램화 하는 System Integration 분야와 모발기기 HW에 포함되어지는 Embedded SW 등과 구별된다.) 출시전까지 개발팀은 자신이 가지고 있는 모든 역량을 동원하여 가능한 많은 오류를 제거하려 하지만, 과연 제품에 포함된 오류의 총량은 얼마나 되는지, 그 중에 찾을 수 있는 오류는 다 찾은것인지, 고객에게 전달된 오류는 얼마나되며, 그것을 위한 유지보수 인력은 어떻게 준비해야 하는지 등등 에 대한 의문은 여전히 개발 담당자의 육감(?) 혹은 PM의 대담함(?)에 의존할 수 밖에 없었다. 내가 근무했던 회사도 상황은 마찬가지였다. 이미 정해진 출시일까지 밤을 세워가며 최선을 다해 오류를 찾고 수정하는 지루한 작업이 반복될 뿐이였다. 이를 극복할 수 있는 방법으로 프로젝트를 진행하면서 발생되었던 데이터들를 활용하여 앞으로 프로젝트가 진행될 방향을 예측해보자는 시도가 있었다. \u0026lsquo;과거 데이터로 가설을 세우고, 이를 현재의 데이터로 보정해 가면 앞으로의 결과를 예측할 수 있다\u0026rsquo;라는 널리 알려진 방법론을 바탕으로 몇가지 통계모델을 프로젝트 데이터에 적용해 본 결과 프로젝트가 진행되던 약 3/5시점에서 약 98%의 확률로 종료 시점을 예측할 수 있게 되었다.\n아래 그림은 해당 방법론이 적용된 제품의 14주차 시점(왼쪽)의 예측 그래프와 30주차 시점(오른쪽)의 실제 오류 추이 그래프이다. 그래프 상으로 출시 시점을 결정할 수 있는 두번의 기회 (A, B시점)가 있었으며 각각 2주(1st 시점)과 6주 (2nd 시점) 후 출시 가능성을 예측할 수 있었다. (그러나 실제로 30주차에 출시되었고, 우리는 예측이 주는 이익을 얻지는 못했다.) 또한 제품에 총 오류수는 900개이며 그 중 현재 가용한 리소스로 찾을 수있는 오류는 약 550개 정도에 불과한것으로 예상되었다. 그리고 왼쪽 그래프에서 보는 봐와 같이 예상은 비교적 정확했다. 파랑 실선 : 예상 추이 / 빨강 점 실선 : 실제 오류 누적 추이 / 파랑 점선 : 최대, 최소 오류 예상 값 오류가 포함된 제품을 출시한다는 것이 말이 안되는 것일 수도 있으나, 전수검사를 할 수 없다는 점을 가만한다면 이해가 가는 부분이기도 하다. 위 내용은 이 글에서 예시로 사용된 내용이므로 더 자세하게 쓸 수는 없지만 다른 글을 통해 공유할 기회가 있을 것으로 생각한다. 이렇듯 간단하게 입력된 오류수 만을 가지고 통계모델(Rayleigh Model)으로 예측을 한것이지만, 경험에만 의존하던 당신 상황에서는 개발팀에게 그전에 갖지못했던 Insight을 주기에는 충분하였다.\n현재 해당 분야에서 그때는 활용하지 못했던 빠르고, 다양한 용량이 큰 데이터들, 예를 들어 오류를 찾는데 들어간 시간이나, 코드의 변경 정도, 오류 수정시간, 오류 내재기간, 개발팀 내 메일량, 회의 시간 등등 을 가지고 여러가지 실시간 (혹은 배치) 분석 모델로 수백 ~ 수천회 시뮬레이션을 단기간에 할 수 있다는 것이고, 그러므로 더 정확한 예측과 미처 일지 못했던 개발팀의 습관 조차도 알수 있는 시대가 된것이다. Change with Big Data # Big Data 는 우리의 업무시스템 환경을 변화시킬 수도 있다.\n개인적인 의견이지만 이제 정보화 나 SI (System Integration) 접근 방식에도 발상의 전환이 필요할 것이다. 기존의 시스템들 (RDBMS 기반) 은 수집할 수 있는 데이터 중 (혹은 발생시키는 데이터 중) 일부만을 (경영환경에 필요하다고 판단되는) 명확한 필터 (데이터 입력 기준정보) 을 통해서 수집하고, 정해진 구조(Schema)에 적재하는 방식이였다. 그래서 필요할때 마다 그때 그때 따라 다양하게 구축된 DB들은 곧 시스템 그 자체가 되어 버렸다. 이럴경우 기업경영 환경변화에 따라 추가적인 데이터 (아마도 기준에 부합되여 버려졌던) 수집이 불가능 하게 되여 (이미 버렸기 때문에) 분석할 수 있는 데이터의 한계에 빠져 알고자 했던것만 알 수 밖에 없는 상황이 되었던 것이다. 따라서 이런 RDBMS 중심의 환경에서는 또 다른 DB, 즉 시스템들이 지속적으로 만들어져야만 했고, 때론 사라져야만 했다. (우리 주변에 수많은 비슷한 시스템들의 구축과 폐기로 이를 위한 중복 입력 작업이 늘 떨쳐버릴 수 없었던 이유가 혹시 이 때문은 아닐까?)\n하지만 사전에 아무것도 필터링하지 않고 발생하는 모든것을 기록하여 적재한 다음 (설령 추가 데이터라 필요하더라도 스토리지에 적재후 분석만 다시하면 된다.) 필요에 따라 꺼내서 분석을 할 수 있다면 상황은 상당이 다르게 변할 것이다. 지금까지 (스토리지 운영방식으론 모든것을 기록하기 위해 상당히 많은 비용이 들기 때문에) DB중심으로 중요한 데이터만을 선택하여 적재하고 분석할 수 밖에 없었던 시스템 중심적 (정확하게 RDBMS 중심적) 상황에서 서서히 저 비용의 분산 시스템과 오픈소스의 병렬 분석 SW을 활용하여 데이터 중심(정확하게 데이터의 생산과 소비의 주체인 사람 중심)의 Big Data 시스템으로 변화해야 할 것이다.\n3M이 Post It 이 과거의 실패한 실험으로 부터 나온것은 모두가 잘 알고 있는 사실이다. 비슷한 사례는 이것 말고도 쉽게 찾아 볼 수 있다. 어찌보면 실패한 실험 데이터는 쓰레기로 간주하여 버릴수 있는법한데 그렇게 하지 않은것이다. 만약 이런 실패한 연구 데이터를 모두 저장하고, 나중에 쉽게 찾아 보고, 분석할 수 있는 인프라가 구축 되어 있다면 더 많은 사례들이 나타날 것이며, 따라서 실패가 실패가 아닌 과정으로써 인정받는(?) 분위기가 쉽게 만들어지지 않을까? (또한 퇴직, 전배한 임직원들의 연구 데이터를도 보관/검색/분석 할 수 있다면 더욱 좋을 것이다.)\n의료 서비스에서의 사례 , 출처 : \u0026lt;시사기획 창\u0026gt;\u0026ldquo;빅 데이터, 세상을 바꾸다\u0026rdquo;. (2012. 1. 31). 「 KBS 」 전체 영상 보기 : http://news.kbs.co.kr/tvnews/ssam/2012/01/2428163.html\n실험실 장비에서 10초 단위로 발생하는 데이터을 연구원이 30분에 한번씩 실험실에 방문하여 이를 받아 적고, 또 자리로 돌아와 DB에 넣은 후 이를 토대로 분석을 진행하는 경우와 10초 단위로 발생한 모든 데이터를 온라인으로 모아 적재한 다음 이를 분석하는 경우를 비교해 본다면 누가 더 나은 연구결과를 얻을 것인가는 쉽게 상상할 수 있다.\nThere is no silver bullet # : 모든 문제를 한번에 해결할 수는 없다.\nBig Data가 정보화의 새로운 방향을 제시하는 것 뿐만 아니라 우리의 생활을 변화 시켜줄것이라 것에 대한 많은 사람들이 기대를 하고 있는 것은 사실이지만, 도입하면 모든 문제들이 저절로 술술 풀어지지는 않을 것이다. 관련 자료를 모으고, 정리하는 과정 중에 끊임없이 답을 찾기 위해 맴돌았던 몇가지 질문들을 제시하고 답을 해 봄으로서 비슷한 고민을 하고 있는 분들과 더 깊은 공감을 하고자 한다. (사실 이것들 말고도 더 증명해야할 질문들은 많다.)\n\u0026lsquo;우리 조직에도 Big Data 시스템이 필요한가?\u0026rsquo;\n: 지금까지 Big Data란 지금까지 경제적 효율성 때문이였던, 혹은 그 엄청난 규모 때문이였던 우리가 눈여겨 보지 않아 버려져야만했던 대상을 저장, 분석할 수 있는 기술과 이를 통해 새로운 의미를 찾고자하는 활동이라 정리하였다. 이제는 우리에게도 필요한가라는 질문으로 그 동안 잊고 간과하고 있던 부분을 짚어 보고 싶다. 앞서 1편에서 예로 설명했던 \u0026lsquo;online\u0026rsquo; 단어찾기의 예를 다시 들어 설명한다면, 새로운 시스템과 방법론으론 지금까지 알 수없었던 \u0026lsquo;online\u0026rsquo; 이란 단어와 가장 가까이 있는 단어를 찾을 수는 있지만 그것이 나에게 (찾고자 하는 사람에게) 어떤 의미가 있는가는 또 다른 별개의 문제가 되버린다. 과연 \u0026lsquo;online\u0026rsquo; 이란 단어에 가장 가까이 있는 단어가 나에게 어떠한 가치를 줄수 있을 것인가? 여기서 외부 블로거의 말을 인용하여 대신하고자 한다. (관련 사이트)\n\u0026quot; 빅데이터라는 말이 굉장히 기술적인 용어같지만, 결국 어떤 트렌디한 말이나 기술이 중요한 것이 아니라, 핵심은 실제로 고객에게 어떤 가치를 줄 것인지를 고민하고 그 가치를 만들어 내는 수단으로 데이터가(사람이 아닌 시스템 단에서 자동으로) 잘 활용될 수 있도록 서비스를 디자인하는 것. 그것이 핵심이라고 생각한다.\u0026quot;\n이전글과 연관지어 생각하여 보자. Big Data의 4단계 구성을 5W1H를 맞추어 본다면 아직 언급하지 못한 것은 바로 \u0026ldquo;Why\u0026rdquo; 와 \u0026ldquo;When\u0026rdquo; 이다. 바로 이부분이 기술이 아닌 사람중심(고객 ?)의 접근이 필요한 부분이라 생각한다.\n범죄 예방을 위해서는 예지몽이 아니더라도 또 다른 데이터 소스를 활용하여 범죄예방 시스템을 구축 할 수 있을 것이다. (예: www.crimemapping.com) 그에 따라 필요한 H/W, S/W 그리고 필요인력이 정해질 것이다. 그러나 반드시 그 전에 왜 그것을 정말로 삶에 도움이되는지 고민되어야 한다.\n\u0026lsquo;어떻게 Big Data 시스템을 구축할 수 있는가?\u0026rsquo; 필요성이 명확하고 무엇을 도움 받을지 결정이 되었다면, 구체적인 구축방법이 필요할 것이다. 아래와 같이 4가지로 분류해 보았다. 먼저 말하고 싶은 것은 자신의 상황에 따라 다양한 방법으로 도입할 수 있다는 것이다. 천편일률적으로 이것이 정답이고, 이것 아니면 도입이 아니다라고 말할 수 없기 때문이다. 솔류션을 제공하는 업체의 특징을 잘 파악하고 자신의 환경에 맞는 서비스를 선택해야 한다. ① Hadoop 기술에 참여, Google, Yahoo, Amazon, Facebook 처럼 일부 Ecosystem에 기여하며 자체 구축 :\n데이터 수집부터 시각화까지 전부 자체적으로 도입하는 방법이다. 주로 아파치 하둡 초기 주도적인 업체들과 이를 활용한 서비스를 제공하는 곳에서 사용한다. 말 그대로 1단계부터 4단계까지 모두 자신의 요구사항에 맞게 도입 (혹은 필요에 따라 추가적인 Ecosystem 모듈을 개발) 하게 된다. 수집 방법부터 분산 시스템 구축, 분석 SW 설치 및 적절한 application 개발까지 결코 쉽거나 단기간에 완성되는 방법이 아니다. 먼저 간단한 가상 분산 시스템을 이용하여 분석 SW을 설치하고 전체적인 프레임웍을 이해하고, 익힌 다음 본인의 업무에 맞은 방식을 찾아내어야 한다.\nTIP 하둡 아파치 프로젝트의 각 업체별 기여도\n② Hadoop 참여 기업들 중 구축 노하우를 제공하는 업체와 제휴 :\n주요 하둡 선도기업의 노하우, 컨설팅을 통해 도입하는 방법이다. SW 자체가 오픈 소스기 때문에 배포판을 제공하는 업체들은 주로 SW에 대한 수익이 아닌 이를 이용한 컨설팅, 교육으로 수익을 발생시키는 모습입니다. 자신의 조직에서 분산시스템을 갖추고 있거나, 혹은 쉽게 하드웨어 구성(2단계) 하고 이 위에 하둡을 구성하는 방식이다. Cloudera, Hortonworks 등으로 대표 되는 업체들은 자신들이 Hadoop ecosystem의 모듈들을 검증하여 쉽게 사용할 수 있는 배포판을 제공한다. (자신들만의 노하우가 들어간 관리 tool 도 일부 포함된다.)\nOpen 소스 기반 Hadoop Ecosystem 의 주요 배포 업체 (각 요소별 가용한 버전을 맞추는 번거로움이 없다. 무료이다)\n③ Hodoop 기술이 적용된 기존 HW 기반의 Global Vendor 도입:\n기존 IT업체 중심으로 자신들의 솔류션에 포함하는 형식 혹은 Appliance (HW+SW) 형식으로 제공하는 채택, 도입할 수 있다. Oracle (Big Data Appliance), HP(AppSystem), IBM (Big Insight), EMC (Greenplum Data Computing Appliance) 등 같은 기업들은 분산시스템을 하나의 랙으로 구성한 다음, 위에서 언급한 하둡 배포판 제공업체 (예: Cloudrea) 의 배포한을 설치하여 (혹은 자신들이 직접 구성) 제공하는 형태이다. 표 출처 : (첨부) 빅데이터 기업의 솔류션 및 서비스 추진 현황 (한국정보화진흥원 빅데이터 전략연구센터, 2012.09) Big Data 관련 기업\n④ 서비스로써의 Hodoop 사용:\n이미 구축된 2,3단계 시스템을 활용하여 big data 분석 서비스를 사용하는 방식이다. 단, 분석하고 싶은 큰 데이터만 있으면 된다. Google, Amazon 등 H/W와 S/W 의 자체 기술를 보유한 기업들이 제공한다. 최근 미 대선에서 Amazon의 서비스 (AWS) 를 활용한 Big Data 분석은 오마바가 대선에 승리한 주요 요인으로 평가되고 있다. (관련 정보)\n\u0026rsquo; 은행 계좌 정보도 Big Data 시스템으로 구축 해야 하는가? \u0026lsquo; 목표도 있고, 구축 하는 방법도 결정했다면, 지금 사용하는 시스템은 어떻게 해야 하는지 궁금할 것이다. 다시 한번 RDBMS를 비롯한 NoSQL 에 대한 정의(?, 분류) 가 이야기 되어야 할 것 같다. 이를 위해 CAP 이론 (Consistency, Availability, Partition tolerance / 아래표 참고)이 사용되곤 하는데, 간단하게 말한다면 데이터 특성에 따라 적절한 DB 형태가 적용되어야 한다는 것이다. 기존의 중요자료와 새롭게 발견되는 가치있는 정보는 빠르게 접근되어야 하므로 기존의 RDBMS로 유지 될것이다. CAP 이론 (분산시스템이 보장해야할 3가지 특징 중 2가지만 보장할 수 있고, 3가지 모두를 보장하는 것은 불가능 하다는 이론) 에 의한 DB 분류, 관련 정보1 관련정보2\n아마도 Big Data 시스템의 정형적인 모습은 아래 eBay의 사례처럼 기존의 RDBMS 와 비정형 스토리지 및 NoSQL 이 공존하는 모습이 되지 않을까 생각한다.\neBay 의 Data Platforms (출처 Extreme Analytics at eBay, Tom Fastner) 1. 엔터프라이즈 데이터 웨어하우스 (EDW): 사용자의 구매이력, 상품의 매출 데이터 등 트랜잭션 데이터(구조화 데이터)를 저장한다. 2. 싱귤래리티(Singularity) : 사용자의 행동 이력 등 반구조화 데이터를 저장하는 데이터 웨어하우스. 3. 하둡(Hadoop) : 범용 HW에 하둡 클러스터를 구축, 사용자 행동 이력 데이터나 EDW로 부터 특정 데이터를 복사해추적한다. 주로 텍스트 분석으로 기계학습 어플리케이션을 사용\n마지막으로 영화에서 영원히 완벽할 것으로 생각되었던 Pricriem 시스템이 데이터를 수집함에 있어서 개인의 Privercy 문제(혹은 인권)를 가볍게 생각하여 하루 아침에 사라지게 되었고, 최근에는 스마트폰의 음성 검색 서비스에 대해 I기업에서는 임직원의 해당 서비스 사용를 금지하는 해프닝도 벌어지기도 했다. (관련기사) Minority Report 로 시작하였으니, Minority Reprot의 결말을 생각해 보면 이미 우리는 Big Data 의 결론을 알고 있는 것은 아닐까? 스스로 \u0026ldquo;BIG THINK\u0026quot;가 필요한 부분이다.\n"},{"id":32,"href":"/posts/minority/","title":"마이너리티 리포트","section":"Writing.logging","content":" 인터넷의 발달 이후로 우리들은 많은 데이터 속에서 살아가고 있습니다. 더욱이 모바일 기기의 출현은 데이터의 증가 속도를 더 빠르게 진행시키고 있으며, 발생되는 량 또한 기하급수적으로 증가 시키고 있습니다. 따라서 다양한 Digital device 을 통해 발생되는 데이터 속에서 자신이 원하는 정보를 찾는 일은 점점 더 힘들어 지고 있다는 것은 사실입니다. 반면 이런 변화가 그져 고통스럽고, 억울하기만한 상황이 아닌것 같습니다. 위기가 곧 기회이듯, 이런 변화의 중심에 있는 바로 그 데이터를 적절히 가공한다면 의미 없고, 짜증의 대상이였던 것들 속에서 지금까지 알지 못했던 새롭고 흥미로운 Insight을 발견할 수도 있기 때문입니다. 이런 데이터 홍수 속에서 새로운 Insight를 찾으려는 노력들은 최근 들어 많은 글로벌 Top 기업들의 사업영역 변화 혹은 확장으로, 또는 수 많은 Start Up 의 기회로 시도 되고 있습니다. 그들이 찾고자하는 Insight 란, 주로 미래 예측 입니다.\nScenery # 몇년전부터 \u0026lsquo;Big Data\u0026rsquo; 로 불리우기 시작한 이러한 IT 트랜드가 이미 약 10여년 전에 제작된 영화 속에서 다루어 졌다면 믿으시겠습니까? 제작된지 10년이 지났음에도 불구하고 ( 2023년 현재, 이 글을 쓴지도 벌써 10여년이 지났다 ) 지금의 시각에서 봐도 시대에 뒤떨어지기는 커녕 아직까지도 그 예언의 유효함에 감탄할 수 밖에 없었던 영화 \u0026hellip; \u0026lsquo;Minority Report\u0026rsquo; (2002)\n캐캐묵은 영화 이야기를 꺼내는 이유는 영화속에서 표현된 범죄 예측 시스템이 주었던 Insight 때문이다. 영화에서 표현된 범죄 예측 시스템인 Precrime 시스템은 그 구성과 운영원리가 다음과 같다. 미래를 볼 수 있는 3명의 예지인(Precog)들이 유동액 풀에 반의식 상태에서 꾸는 예지몽은 기계장치에 의해 범죄 예방 경찰국 (Precrime) 컴퓨터에 연결되어 영상화된다. 바로 이 예지인(Precogs)들이 꾸는 예지몽을 소스로 하여 이를 모으는 한편 동일한 꿈을 꾼 경우 피해자와 피의자의 이름을 나무공에 각인하고, 또한 그 유명한 모션 UI로 단편적인 영상을 조합하여 사건의 정황을 분석, 범죄 현장을 찾아내어 범죄 발생 이전에 피의자 ( 용의자가 더 맞을듯 합니다) 를 체포하게된다. 이 과정 중 대개 세명의 예지인(Precogs)들이 동일한 미래를 보지만 예언이 엇갈리는 경우나, 전의 것과 비슷한 영상들은 이미 해결된 사건을 중복해서 꾸는 Echo Image라 하여 소수의견(Minority Report )으로 간주, 파괴한다. 이와 같은 일련의 Pricrime 시스템의 과정은 아래 그림과 같이 4부분으로 간단하게 표현할 수 있다. 네가지 : 수집,저장,분석,표현 # 이러한 4단계 구성은 상당히 논리적인 시스템 운영 구조로 받아들여진다. (영화 저변에 깔린 논리를 파헤쳐 보는 것도 재미난 일이다.) 첫번째로 보이는 항목은 \u0026ldquo;① 명확한 소스 (수집 대상) 데이터 정의\u0026quot;이다. 3명의 예지인들(Precogs)에서 발생하는 예지몽이 그 대상이라 할 수 있다. 두번째로 그런 예지몽을 \u0026ldquo;② 수집,저장하는 기기 장치들\u0026rdquo; 이다. 예지인(Precongs)을 위한 가수면 유지 장치부터 인체에서나오는 신호를 수집하고 이를 메인 컴퓨터로 전송, 저장하기 까지의 모든 인프라가 이에 속한다. (아마 이때 아니로그 신호로 수집되었던 인체신호들을 디지털화된 데이터로 변환했을 것이다) 세번째가 디지털화된 데이터을 여러가지 변환, 분석 알고리즘 이용해 영상화하고, 이를 \u0026ldquo;③ 적절히 분석하여 정보\u0026quot;로 만들어 내는 단계이다. (사건 시간, 피의자/피해자 파악, Minority report 필터링 등 기계적인 1차분석 수행) 마지막으로 시스템 사용자에게 Insight (영화에서는 사건 장소를 ad-hoc query로 찾을 수 있도록 하는 것이였죠) 를 줄 수 있는 \u0026ldquo;④ Visualization 및 UI \u0026quot; 단계가 될것이다. (영화에서 가장 볼거리가 많은 부분이고, 대표되는 장면이기도 하다.) 다소 복잡해 보일 수도 있는 Pricrime 시스템을 \u0026lsquo;예지몽 데이터를 수집, 저장하고 이를 적절히 변환, 분석하여 미래에 발생될 범죄에 대한 정보를 제공하는 System\u0026rsquo; 으로 간단하게 표현해 본다면, 여기서 \u0026lsquo;예지몽\u0026rsquo;과 \u0026lsquo;범죄\u0026rsquo;라는 특정 단어만을 변경하였을때 \u0026lsquo;Pricrime 시스템\u0026rsquo; 이란것은 앞서 말한 IT분야에 최고의 관심사인 Big Data 가 말하는 것과 매우 흡사하게 보여진다. 다시 일반화된 용어로 바꾸어고 앞에 \u0026lsquo;빅\u0026rsquo; 자를 넣어서 다시 읽어 보면 \u0026ldquo;빅 데이터 소스를 수집, 저장하고 이를 적절히 변환, 분석하여 미래에 대한 Insight를 제공하는 System\u0026rdquo;. 적어도 나에게는 그럴듯해 보이고, 뭔가 그 자체로도 Insight을 주는듯 하다. 그렇다면 위의 Pricrime 시스템의 4단계 구조를 기초로 하여 대부분 사람들이 이해하기 쉽게 일반화된 Big Data 시스템의 정형적인 모습으로 표현해 본다면 아래 표와 같이 정의할 수 있지 않을까?\n1단계는 데이터 다양한 형식에 (M2M Log, Signals, Image 등) 따라 그만큼의 다양한 수집방법이 존재\nHodoop은 분산 시스템을 포함하고 있지는 않지만, 분산 시스템에서 운영되기에 한꺼번에 고려되어야 함.\n4단계는 분석에 목적에 맞는 적절한 사용자 인터페이스가 적용되어야함.\n위의 표에 언급된 내용 이외에 각 단계별로 더 고민해 봐야 할 사항들이 있는데. 먼저 1단계에서는 데이터를 수집함에 있어 추가적인, 인위적인 작업이 없어야 한다는 것이다. 구체적인 예를 든다면 IOT (Internet of Things, 관련글 ) 기반의 Life logging과 같은 센서 및 M2M log 수집 환경 등이 될것이다. (Crowdsourcing 기반으로 인류의 일상에 대한 데이터를 모아 분석해보는 The Human Face of Big Data 라는 재미있는 project도 있다.) 만약 영화에서 예지인들이 예지몽을 꾸고 그 것을 문서로 작성하여 컴퓨터에 입력한다고 가정해 본다면 이 단계에서 꼭 풀어야 할 문제가 무엇인지 쉽게 상상할 수 있을 것이다.\n2단계에서는 수집 가능한 모든 데이터를 저장하기 위해 확장이 자유로운 Infrastructure 가 지원되어야 한다. 어떤 이유에서든 그동안 수집하지 않았던 다양한 형태의 대용량 데이터들을 빠른 주기로 즉시 저장하어야 하기 때문에 필요할 때 바로바로 확장할 수 있는 서버가상화 기반의 Cloud Computing 기술이 제시되고 있는 이유이기도 하다. (뒤에 언급하겠지만 Big Data Service를 다양한 Cloud 형태로 제공하는 기업들이 등장하고 있음)\nBig Data 서비스도 2단계 인프라 (H/W) 뿐만 아니라 3단계 분석 플랫폼, 4 단계 Application 까지 Cloud 서비스가 확대 됨.\n즉, 가상 서버로 Scale-Out이 자유로운 원격 분산 Cluster 구성이 채택되고 있는 것이다. 3단계에서는 이런 원격 분산 Cluster에 데이터를 저장할 수 있는 파일구조와 이를 병렬 처리할 수 있는 다양한 분석 방법이 (Software Platform) 필요하다. 바로 이러한 이유 때문에 Apach Hadoop Project (관련 사이트)가 주목을 받기 시작했고, 이제는 Big Data 를 언급하면서 빼놓고 말할수 없는 것이 되어 버렸다. Hadoop의 등장으로 비로소 Big Data 에 대한 가시적인 실체가 나타나기 시작한 것이다. (영화에서 표현된 상상이 이제 서서히 현실화 되기 시작한 것이다.) 따라서 2,3단계는 Hadoop으로 대표 될 수 있다고 생각한다. 마지막으로 4단계에서는 결과를 시각화 하고, 분석결과가 잘 전달되기 위한 사용자 UI가 필요하다. 영화에서는 분석 결과인 동영상를 잘 다룰 수 있게 모션 UI을 채택하였다. 이런 인터페이스가 아닌 마우스로 클릭를 해야만 하는 인터페이스이였다면 우리가 느끼는 시스템 전체의 이미지가 반감되었을 것이다. 더불어 서로 다른 영역의 분석결과를 쉽게 Mash up 할 수 있는 기능도 좋을 것 같다.\n네가지 중 두가지 : 분산시스템과 병렬처리 # \u0026lsquo;Big Data가 Hadoop이고, Hadoop이 Big Data 이다\u0026rsquo; 라고 할 정도로 성장한 Hadoop은 앞에서 정의한 Big Data 구성의 2,3단계를 대표할 수 있다라고 생각한다. 이러한 생각은 Hadoop Ecosystem 관점에서는 1,4단계에 대한 다양한 모듈도 제공하지만, 핵심은 HDFS (Hadoop Distributed File System)과 MapReduce 이기 때문이다. Hadoop의 탄생 계기는 서버 및 스토리지의 운영비, 즉 바로 \u0026lsquo;돈\u0026rsquo; 때문이다라고 주장한다면 너무 지나친 표현일까? 그렇다면 \u0026lsquo;기존 스토리지 운영(Scale-up)의 한계와 이를 위한 운영비 증가\u0026rsquo;로 좀 순화하여 표현해야겠다. 하여튼 이런 문제를 본격적으로 다루기 시작한 업체들은 이런 운영비에 민감할 수밖에 없는 Google, Yahoo와 같은 검색 솔류션 업체들이였다. 그야말로 World Wide Web에 있는 어마어마하고 다양한 데이터 정보를 저장하고 그것을 분석, 분류하기 하기 위해서는 기존의 RDB 기술로써는 한계가 있었다. (이후 Facebook과 Amazon으로 확대되어짐) 따라서 기존의 스토리지 운영방식에서 감당할 수 없는 (scale 이든, $ 이든) 많은 량의 데이터를 핸들링 하기 위해 값싼 다수의 저가 x86서버 혹은 PC들로 이루어진 분산 스토리지 시스템과 이 속에 데이터를 저장하고 분석할 수있게 해주는 File 시스템 및 병렬 프로그래밍 모델이 필요하게 되었고, 이를 GFS (Google File System)와 MapReduce 으로 실현한 Google을 시작으로 Yahoo 의 후원속에 Apach Hadoop project로 발전하게 되었던 것이다.\n기존의 RDBMS을 무한히 확장 (Scale-up) 해서, 그것도 값싸게 사용할 수 있었다면 아마도 우리는 지금 Big Data와 Hadoop를 논할 필요가 없었을 것이다. 그러나 현실은 그렇지 못해서 (스토리지 운영비용이 비싸서) 꼭 필요한 데이터만을 선별하여 이미 정의된 구조 (Schema)속에 넣고, 빼고 (OLTP), 한정된 분석 (OLAP) 만 가능했었다. 반면에 데이터가 증가하면 증가하는 데로 별도의 낱개 PC를 추가하여 (Scale-out) 기존에 감당할 수 없었던 많은 량의 즉각적이고도 다양한 형태의 데이터 저장 (HDFS)과 이와 같은 분산환경을 위한 데이터 분석 기술(MapReduce)이 제공되므로 기존 스토리지 한계를 극복하게 되었고 비로서 Big Data 가 본격적으로 수면위로 등장하게 된 것이다.\n아래 그림 왼쪽은 기존 Schema 중심의 Datawarehouse를 Scale up (디스크를 추가 하여 용량 증가 시킴) 확장으로 표현한 것이며, 오른쪽 그림은 Scale out (디스크를 가진 노드를 추가하여 용량을 증가 시킴) 확장의 분산 시스템과 Hadoop 관련 모듈을 매핑 시켜본 그림이다.\n위의 그림을 문자들의 집합을 대상으로 오버랩하여 다시 상상해 본다면, 해당 문자에 대한 내용, 크기, 폰트, 사이즈 등을 정형화 하여 DB화 하는 경우 (아래 왼쪽 그림) 와 존재하는 비정형태 그대로 저장하는 경우(아래 오른쪽 그림)로 나눠 다시 그려 볼 수 있다. 다양한 크기, 색, 모양의 문자열군 (오른쪽)과 이를 정형화하여 축적한 테이블형태 (왼쪽)\n오른쪽 비정형 형태 그대로를 저장하기 위해선 왼쪽 정형적인 형태보다 더 많은 인프라 (스토리지)가 필요해 보이고, 분석하여 정보를 얻어내기가 더 어렵다. (실제로 \u0026lsquo;Online\u0026rsquo; 이란 단어를 찾아보자) 그러나 \u0026ldquo;\u0026lsquo;Online\u0026rsquo; 이란 문자의 색이 무엇이냐?\u0026rsquo; 라는 질문을 할 경우 왼쪽 형태에서는 빠르고 정확하게 답변할 수 있지만, (왼쪽 Table에 11열, Color 항목 참고) \u0026lsquo;\u0026ldquo;Online\u0026rdquo; 아래에 위치한 문자는 무엇이냐?\u0026rdquo;, \u0026quot; \u0026lsquo;Online\u0026rsquo; 단어와 가장 가까이 있는 단어는 무엇이냐?\u0026rdquo; 라는 질문의 답은 왼쪽 형태에서 얻을 수 없다. (왼쪽 Table에 저장되어 있지 않음) 이처럼 여러가지 이유로 처음부터 입력되지 않았던 정보들이 이제는 새로운 Insight을 얻기 위해 필요하게 되었다면 무엇을 어떻게 해야 할 것인가?\n지금까지의 이야기를 정리해 보면 Big Data 시스템은 4단계로 구성할 수 있고, 그 중 핵심은 2,3단계로 Hadoop으로 대표되는 대용량 데이터를 위한 분산 시스템과 병렬 처리(저장,분석) 라 할 수 있다. 또한 데이터 처리 과정에 있어서도 사전에 정해진 틀(Schema)을 만들고 정합(Integrity)된 데이터를 수집, 분석하는 것이 아니라 발생하는 모든 데이터를 그 형태에 맞게 모두 저장한 후 필요에 따라 Ad-hoc Query 로 분석할 수 있다는 것이다. 이러한 내용은 심도있는 연구을 위한 정보화, 고객의 구매 의도 예측, 교통량 예상, 질병의 조기 발견 등 각 활용분야 마다 데이터 정의 (어떤 성격을 가지고 있는지), 수집방식 및 분석 방법 등에 있어서 약간씩의 변화와 차이는 있을 수 있으나 기본적인 틀은 큰 변화가 없을것이라 생각한다.\n다음 2편에서는 위의 예 중 \u0026lsquo;Online\u0026rsquo;과 가까운 단어를 찾는것이 나에게 어떤 의미가 있는가? 라는 물음을 포함하여 자료를 정리하며 스스로 끊임없이 되물었던 질문들과 Big Data 시스템의 다양한 적용방법에 대해서 공유하고자 한다. 이번 1편의 마지막으로 지금까지 영화 \u0026lsquo;Minority Report\u0026rsquo; 로 풀어본 Big Data 시스템 구성을 아래 한장의 그림으로 정리해 보았다. (Hadoop Ecosystem과 기존 RDBMS 도 같이 배치해 보았다. Hadoop Ecosyste 도 2편에서 자세히 다루고자 한다.)\n많은 분들이 이해에 도움이 되었으면 하는 바램이며, Minority Report 가 2002년 상영된 이후, Apach Hadoop Project 의 발단이 된 Google의 논문 \u0026ldquo;The Google File System\u0026rdquo; (http://research.google.com/archive/gfs.html) 과 \u0026ldquo;MapReduce: Simplified Data Processing on Large Clusters\u0026rdquo; (http://research.google.com/archive/mapreduce.html) 가 각각 2003년, 2004년 연이어 발표된 것을 보면 단순히 영화를 영화로만 볼 것이 아니라 미래의 복선으로 봐도 되지 않을까 싶다. 물론 단순한 우연일 수 도 있지만 최근 발표된 재미있는 사례가 (관련 사이트) 이런 공상을 더 재미있게 만든다. "},{"id":33,"href":"/posts/metric/","title":"단순 수치에 의한 업무 평가?","section":"Writing.logging","content":" 유명한 Global S/W 회사의 한국 지사에서 System Testing Engineer 로 일할때 일화이다. 그 곳에서 나는 사무 프로그램 패키지 제품군중 하나의 제품에 대한 품질을 책임 지고 있었다. 당시에는 단순히 제품이 한국에서 팔리기전 내가 최종 승인을 한다는 것에 대한 매력이 나를 지탱하는 유일한 것이었다. 하지만 그것 보다 그곳에서 내가 생각한 것 이상의 것을 배웠고, 시간이 지나고 이제서야 그 중요성을 깨닫게 되었던 가르침 중 하나을 소개 하고자 한다.\n한국에 제품 출시가 임박해질수록 모든 S/W 개발실이 그러듯이 매우 분주해 지며, 구성원들의 신경은 날카로워 지기 시작한다. 우리는 전체 제품군이 주간 단위의 Bug Review Meeting을 수행했고, 제품군 전체의 품질을 책임지고 있는 이사님이 주제하시는 이 자리가 여간 곤욕스러운 자리로 여기고 있었다. 그 분께서는 한주간 등록된 bug에 대한 data 을 가지고 review 을 진행 하셨는데, 그분의 review 는 주로 이런 것이였다.\n“이봐, 일본은 (일본어 버전 품질을 책임지고 있는 engineer 을 칭함) 지난주 100개 bug 을 새롭게 등록 했는데, 이게 뭐야, 당신은 20개야. 한글 버전은 이렇게 출시 해도 제품의 품질에 자신있어? 이 수치 책임 질 수 있어?”\n당시 한국의 전체 Resource는 일본 전체 1/2 수준이였으므로 일본 bug 보고량의 약 1/2가 한국측의 목표였었다. 따라서 적어도 50개의 오류를 보고해야 하는데 그렇지 못한 것에 대한 질책인 것이다. 다시 말해 일본 사용자가 겪지않을 약 30개의 오류가 한국 사용자에게 전달되어도 괜찮냐는 뜻으로 해석 될 수도 있다. (나중에 안 것 이고, 뒤에서 설명하겠지만, 다음 개발 Phase 로 넘어가도 괜찮냐는 뜻이기도 했었던 것 같다.)\n이러한 지적에 대해서 각 제품별 담당자들의 반응 약간씩 달랐지만, 그것은 정도의 차이지 모두가 불평섞인 하소연 혹은 불만이 전부였다. 회의의 마치고 나오면서 우리들끼리 나눈 이야기는 대충 기억 하자면 이런 것 들뿐이었다.\n“월급을 일본처럼 많이 줘봐, 그 만큼 찾아 주지”\n“나는 다른 이슈들을 처리하느라 bug 을 찾지 못했는데 이러한 자세한 업무를 이해 못하고 단순 버그수로 사람을 평가 한다는 것은 잘못된거 아냐? 이치에도 안맞고.”\n“bug 만 많이 찾으면 되는 거지, 알았어!, 원하는 만큼 찾아 주지”\n“일본 Engineer는 내가 알기로 그 제품만 맞고 있고, 난 2~3개 더 맞고 있는데 1/2 수치는 처음부터 잘못된 목표였어”\n지적 당시 아무런 말 없이 지적을 당했던 우리는 누가 먼저랄 것 없이 자신의 입장을 변호하기 시작한 것이다. 그때 당시에는 오류량에 대한 단순 비교로 업무의 특성이나, 업무 상황등을 고려하지 않은 옳지 못한 방식의 일정 관리에 지나지 않는 것이라 생각했다. 아마 이러한 상황은 비단 그곳에서만 일어나는 것이 아닐것이다. 우리 주변에서 항상 되풀이 되는 상황일 것이다.\n지금도 어느 프로젝트 관리자가 아래와 같은 오류 처리량 그래프를 첨부해서 팀 구성원에게 다음과 같은 메시지를 보낸다면,\n“아래 그래프의 주간 오류 처리량으로 판단 하건대 당신의 업무량이 상대적으로 많다고 할 수 없습니다.”\n그 프로젝트 관리자에게 돌아 오는 실무자의 반응은 아마도 아래와 같을 것이다.\n“개인의 생산성라는 것을 단순 처리 건수에 따라 측정해서는 안된다고 생각합니다. 팀의 생산성이라는것은 그래프나 정량적인 방법으로 측정이 가능하겠지만, 개인의 생산성이라는것은 많은 변수가 따르지 않을까요? 예를들면 똑같은 팀원이지만 누군가는 현재 유지보수만을 담당하고 있고, 누군가는 새로운 프로젝트를 진행 할수도 있으며, 또 누군가는 필요에 의해 여러개의 프로젝트를 담당할수도 있는 문제입니다. 또한 개개인에게 할당되는 문제의 난이도도 천차 만별일텐데 이러한 요소를 간과하고 건수로만 개인의 능력치를 평가한다는것은 잘못된 방법이 될수 있을것입니다. 다른 방법의 잣대를 찾아 보아야 할 것 같습니다.”\n표현은 약간씩 다르겠지만, 주 내용은 별로 틀리지 않을 것이라 생각합니다. 위에서 언급한 불만과 지금의 이 의견은 문제는 제시하지만 해답을 제시 못하는 시간 소모적인 언급에 불과 합니다. 누구나가 쉽게 생각 할 수 있는 이야기 이며, 전혀 상황에 도움이 되지 않는 분석이며, 불평 불만의 다른 표현일 뿐입니다. (직설적인 불평을 하면, 자신이 아마추어처럼 보일 것 같아서, 약간의 짧은 지식으로 포장한 것에 불과하다.) 앞에서 언급한 나의 반응과 전혀 다른점이 없다고 생각합니다. (감히 충고 하건데 위와 같은 말을 상사에게 절대 하지 말것을 권한다. 이미 그는 내가 생각한 것을 예상하고 있고, 그 것에 따라 이미 정해저있는 분류 규칙에 의해 나는 분류 되고 있을 것이다. 더군다나 나에게 부정적인 요인으로 작용할 수 있는 쪽으로 말이다.)\n그렇다면, 위와 같은 두가지 사례에서 어떻게 대처해야 하며, 두 사례에서의 관리자들이 원하는 것은 진정 무엇일까? 일본 보다 많은 오류 보고량 일까? 아니면 다른 사람 보다 많은 오류 처리량 일까?\n먼저 정답부터 말하자면, “아니다” 이다.\n다시 첫번째 사례로 돌아 가서 (나는 첫번째 사례에서 비록 그 관리자가 의도 했건 안했건 간에 정답을 경험 했으며, 두번째 사례에서도 그러한 정답이 나오길 기대 한다.) 이야기를 진행한다면, 처음 아무 말도, 대답도 하지 못하고 자리를 지키고 있던 우리가 서서히 변하기 시작한 것이다. 비록 함께 모여 있을 때는 서로의 불평을 공유 했지만 자리로 돌아온 우리들은 누가 먼저 할 것없이 자신의 업무에 대해서 정리하고, 파악 하기 시작했다. 변화는 다음 Bug Review Meeting 에서부터 나타 나기 시작했다. 먼저 번과 다름 없이 이사님께서는 우리에게 단순한 수치를 바탕으로 지적하시기 시작하셨다.\n“이거 아직도 일본에 미치지 못하는데, 어떻게 된 거에요? 금주에는 30개 차이로 더 벌어 졌는데. 한국 제품은 안정된 것이고, 그렇게 보고해도 됩니까?”\n하지만, 상황은 변했다.\n“아닙니다. 이사님, 아시다시피 현재 일본의 경우 DBCS polite 성격으로 진행 되고 있습니다. 따라서 이미 모든 기능에 대해 Freeze 가 선언된 상태이며, 최종 UI bash 을 약 2주가 진행 중에 있습니다. 일본에서 보고 되고 있는 오류는 약 90% 가 DBCS specific 과 일본어 localization UI 버그이며 우리는 아직까지 보고 되는 오류 중 기능오류가 약 80% 인 기능위주의 테스팅이 진행 되고 있습니다. 이러한 현상은 우리와 개발 단계가 비슷하게 진행 되고 있는 중국도 같은 상황입니다. 우리는 약 3주 후에 기능 Freeze 가 선언될 예정 입니다. 이후 현재 보여지고 있는 버그 격차는 줄어들 것이라 예상되며, 이것을 위해 별도 한국어 Localization test case 보강작업과 DBCS 공통 버그 regression test case 보강을 기능 테스트와 병행하고 있어 현재의 일본 대비 버그 개수 격차는 어느 정도 인정 할 수 밖에 없습니다.”\n누군가가 현재 자신의 프로젝트 진척 상황에 따른 오류 상황, 현재 중점적으로 진행하고 있는 업무, 그리고 앞으로 진행될 업무에 대한 사전 작업 등에 대해서 보고하기 시작한 것이다. 이에 대한 반응은 그전 우리가 받았던 feedback과 크게 달라진건 당연한 결과였다.\n“아직 추가 되지 않은 기능이 몇 개가 있는지 list-up 하신 후, 기능 Freeze 이전에 반드시 완료 될 수 있도록 신경써 주시고, DBCS 이슈이지만 일본어 specific 으로 잘못 traciking 되고 있는 사항이 있는지, DBCS 이슈중 일본에서는 수정되었지만, 한국어에선 재현 되는 부분이 많이 있습니다. 이부분 확실하게 Regress 되게 준비 해 다음주에 보고해 주세요.”\n나중에서야 나는 이해할 수 있게 되었다. 사실 이사님은 첨부터 버그 갯수 같은 걸 비교해 보고싶어 하는 게 아니었다. 단지 우리들이 모든 상황을 통제하고 있는지 알고 싶은 것이였다. 그의 방법은 우리가 현재 상황에 대해서 더이상 모른다고 시인할때까지 점점 어렵고, 난처하고, 극단적인 질문으로 우리를 코너에 몰고 가는 것이였다. 그리고 우리가 스스로 미진하다는걸 인실직고해서야 그 질문을 그만두곤 했던것 뿐이였다. 이것은 Progress (Performance) index 와 Achievement Goal 의 혼동에서 오는 Miscommunication 일수 도 있고, 심리학에서 이야기하는 과잉정당화 (Overjustification) 일수도 있다. "},{"id":34,"href":"/posts/lostproject/","title":"프로젝트속에서 길을 잃다","section":"Writing.logging","content":"오래 전 저를 포함하여 친한 친구 4명이 자동차로 낯선 곳으로 여행을 했던 적이 있었습니다. 우리들은 저마다 역할을 나누어 누구도 알지 못하는 목적지를 향해 밤 세워 운전을 하여야 했습니다. 운전을 하는 녀석, 조수석에서 운전 하는 녀석이 졸지 않게 말을 걸어 주고, 혹시 운전을 하는 친구가 놓칠 수 있는 milestone 이나 Landmark을 같이 봐주는 친구, 뒷좌석에서 지도를 보며 우리가 현재 어디까지 왔으며, 앞으로 얼마나 가야하고, 어디를 거쳐 가야 하며, 앞자리에 앉아 있는 친구들 (운전수와 조수) 에게 길을 찾는 판단을 쉽게 할 수 있도록 서포트 하는 친구, 그리고 자동차에 대해서 잘 알고 있어서 우리가 예상치 못한 자동차 고장이나, 타이어 갈아 끼우는 것, 스노우 체인 장책하는 등의 일을 하는 친구. (실제로 그 친구는 진부령 못 미처서 스노우 체인 장착을 손 쉽게 하므로 그 역할을 훌륭히 해 냈다. )\n[영화 세얼간이 중에서] 어느 정도 본격적인 여정에 들어 스며서 우리의 모든 관심은 목적지에 대한 계획으로 부풀어 가고 있었다. 새로운 환경, 새로운 재미 그리고 그것들이 우리에게 줄 수 있는 희열, 성취감 등 저마다 정도의 차이는 있었지만 여정이 진행 될수록 우리는 우리가 성취한 결과물에 대해서만 흥분되고 있었던 것이다.\n그런 흥분에서 서서히 깨어나기 시작하자 문제가 발생 한 것을 알게 되었다. 운전을 하던 친구가 길을 잃은 것 같다고 말했기 때문이다. 정작 그때까지 지도를 보지도 않고, 관심도 없던 사람들도 지도를 보고면서 우리의 위치를 파악하려고 노력 했고, 그 결과에 대해선 의견이 분분했다. 지도를 보고 길을 잡아 가던 친구는 맞는 길이다 라고 계속 주장했고, 이 사람 저 사람 모두 자신의 논리를 앞세우며, 길을 잃었다, 잃은 것이 아니다. 이 길로 가야한다, 저 길로 가야한다, 주장하기에 이르렀으며, 급기야 한적한 곳에 차를 세워 본격적으로 논쟁하기 시작했다. 이미 우리의 공통 목적지는 각자의 주장에 묻혀 잊혀진 것이다.\n나는 가끔 프로젝트를 진행하면서 나와 같이 여행을 같이 했던 친구들을 떠 올린다. 실제 코딩을 하는 프로그래머, 정해진 일정에 의해 완성된 코드를 테스트 하는 테스터, 전체적인 계획을 잡고, 주기적으로 프로젝트 완성 정도를 설정하는 PM, 그리고 프로젝트를 진행을 도와주는 개발 지원팀(빌드 서버 관리자, 타 팀의 리뷰자 등) 이들과 프로젝트를 진행하면서 그 때 그 일처럼 우리는 길을 잃곤 한다. 그리고, 프로젝트가 잘못 되어 가고 있다는 것을 깨닫는 순간, 팀은 공통의 목표와 자신의 역할을 잊은 채 서로의 분야에 대해서 각자의 논리로 논평하기 시작하고, 결국에 가서는 프로젝트 참여자 각자가 서로 공유 했던 목적과 분명히 다른 논리의 승자, 힘의 승자의 목적으로 변질되어 버린다. 우리의 프로젝트가 너만의 프로젝트, 나만의 프로젝트가 되는 것이다.\n[SW 개발과정] 그때 나와 나의 친구들은 어떻게 다시 길을 찾아 우리의 목적지에 도달했을까?\n어느 정도 심한 언쟁이 오고 간 뒤, 모두 잠시 서로에 대한 섭섭함으로 침묵하고 있을 때, 누군가가 제안을 했다. 모두가 길을 잃지 않았다고 생각하는 지점까지 되돌아 가자고, 거기서부터 다시 길을 찾아 가자고, 물론 이 의견에 대해서도 동의 하지 않는 친구도 있었지만, 실행에 옮기기에 충분한 합의를 얻을 수는 있었다. 내 기억으론 각자가 목적지에 대한 성취에 들떠 각자가 생각하는 미래의 성취를 생각하기 시작한 곳이었던 것 같다. 그 곳부터 우리는 공통의 목적을 잃은 것일 테니까. 길을 되돌아 가면서 다시 우리는 공유된 목적에 대해서 서로의 역할에 충실 하게 되었으며, 예상 밖으로 빨리 길을 찾게 되었고, 목적지에 도착하게 되었다.\n친구들과의 추억을 떠올리며 난 우리 프로젝트 팀원들 모두에게 아래와 같은 메일을 보내고 있다. “저에게 누군가가 현재 프로젝트가 어떤 상황인지, 지금 우리가 제품 출시를 위해 얼마나 더 가야 하는지 묻는다면, 저는 “우리는 길을 잃었다” 라고 말하고 싶습니다. 얼마나 더 가야 하는지 알 수 없으며, 현재 우리가 어디에 있는지 알 수 없습니다. 길을 잃었을 때 보통 사람들이 쉽게 빠지는 생각은.\n1. 바로 저기만 넘으면 우리가 원하는 곳이야. 마지막 힘을 내서 가야 한다.\n2. 빨리 길을 찾아야 한다. 쉬지 말고 계속해서 뛰어야만 길을 찾을 수 있다.\n3. 정해진 시간만큼 걸었으니 이쯤이 내가 찾던 곳일 것이다.\n하지만 저의 생각은 이렇습니다. 지금 우리가 있는 곳에서 잠시 숨을 돌리고, 지금까지 우리가 걸어왔던 길을 되 돌아 보는 것입니다. 어디서부터 잘못 됐는지, 어디까지 내가 확실히 알고 있는 길 이였는지, 그럼 다음 되돌아 가야 합니다. 자신이 왔던 길을 되돌아 간다는 것은 참으로 내리기 힘든 결정입니다. 왠지 앞으로 조금만 더 가면 될 것 같지만, 그런 유혹은 우리를 더 알지 못하는 곳으로 인도 할 뿐입니다. (어떤 이는 원하는 곳을 찾을 수도 있을 것입니다. 하지만 그 사람의 운은 거기까지 입니다. 다시는 일어 나지 않을 일을 기대 하는 잘못된 경험만 줄뿐 차라리 찾지 못한 것 보다 그 사람을 가르침을 주지 못합니다.)\n되돌아 가서 계획 없이 걸었던 것을 상기 하면서, 처음 길을 찾아 가야 하는 이를 도와 주면서, 다시 시작 해야 합니다. 확신이 서지 않을 때 확신하는 곳까지 되돌아 가는 거야 말로 내가 원하는 곳으로 가는 가장 빠른 지름길입니다. “\n"},{"id":35,"href":"/posts/mac/","title":"iMAC, Late 2009 upgrade","section":"Writing.logging","content":" Mac OS # ㅁ Snow leopard (10.6.8) 에서 High Sierra (10.13.6) 까지 업그레이드\nㅁ iMac Late 2009 는 최대 High Sierra 까지 가능\n(High Sierra 이후 MacOs 는 iMac 2012 부터 가능)\nㅁ backup on 10.6\n- iClould 는 10.7 이상에서 지원 x\n- 외장SSD는 10.10 이상에서 지원 x\n- 외장HDD 혹은 USB memory, DVD 굽기..\n✓\t- iMac Late 2009 는 SD memory card slot 지원 *\nㅁ Steps (Snow leopard 10.6 -\u0026gt;)\n0. Backup Bootcamp with USB and iPhoto with SD card\n1. El Capitan (10.11.6) 으로 업그레이드\nhttps://support.apple.com/ko-kr/HT206886\n2. High Sierra (10.13.6) 으로 업그레이드\nhttps://support.apple.com/ko-kr/HT208969\n✓\t-\u0026gt; 성공\nGo further # 1. Mojave - Dark mode / iWork - 그러나 scrivener 가 High sierra 와 최신 Catalina 간 차이가 있네 (Dark mode) - Theme (scrtheme) export / import 가 가능할까? 2. SD card 추가 구매 ✓\t3. Scrivener 라이센스 구매 (Win/Mac) 49,900 4. scapple 라이센스 구매 (Win ? / Mac ?) 5. Bootcamp 가 필요한가 ? (Win10 는 iMac 2012 이후 가능) ✓\t6. Table 구매 220,000 ✓\t7. iMac RAM upgrade ✓\tso-dimm PC3-8500 DDR3 1066Mhz 4Gx2 : 48,100 ✓\t8. iMac SSD upgrade ✓\tOWC iMac 2009 late kit + 256GB SSD : 96$ = 115,000 ✓\t2.5 SSD, SATA - USB 연결 케이블 : 9,800 ✓\tSuperduper : HDD -\u0026gt; SDD (HFS+ ? APFS ? ) . SATA -\u0026gt; HFS+ -\u0026gt; TRIM . PCI -\u0026gt; APFS (default TRIM) ✓\tSD card + USB booting 백업 ✓\t9. Magic Trackpad2 구매 : 149,000 10. 원래 Mac HDD + 기존 연결케이블 (Sata, USB 2) : Time machine 용 11. 신규 SSD (구매필요) + 허브 + 신규 케이블 (8번 Sata-USB 3) : secondary 외장 SSD - SSD 500G 81,000 / 포터블 SSD T7 500G 153,300 / SD card 512G 89,000 / USB 256 48,800 / HDD 1T 79,000 - 허브 USBF4U092bt 125,000 12. Notebook 거치대 25,000 13. iWork 설치 14. 가족 공유 "}]