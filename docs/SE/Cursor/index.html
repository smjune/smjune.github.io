<!doctype html><html lang=en dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="LLM 사용을 위한 로컬 환경 구축 가이드"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://smjune.github.io/docs/SE/Cursor/"><meta property="og:site_name" content="MJ. Breadcrumbs"><meta property="og:title" content="Cursor"><meta property="og:description" content="LLM 사용을 위한 로컬 환경 구축 가이드"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2025-04-12T09:23:10+09:00"><meta property="article:modified_time" content="2025-04-25T22:01:17+09:00"><title>Cursor | MJ. Breadcrumbs</title>
<link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://smjune.github.io/docs/SE/Cursor/><link rel=stylesheet href=/book.min.e1139f93982fd362719f88c60dab8e0226b8024de46e42eb47bb4f697a18fec1.css integrity="sha256-4ROfk5gv02Jxn4jGDauOAia4Ak3kbkLrR7tPaXoY/sE=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.1ebfd0915886dff4f61329c67d70fe57c123a959deed95d5e92dfd15fee641af.js integrity="sha256-Hr/QkViG3/T2EynGfXD+V8EjqVne7ZXV6S39Ff7mQa8=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>MJ. Breadcrumbs</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li class=book-section-flat><a href=/docs/SE/>Job.logging</a><ul><li><a href=/docs/SE/hello/>Hello GitHub</a></li><li><a href=/docs/SE/gitlab/>Push to Gitlab</a></li><li><a href=/docs/SE/gitbook/>Gitbook</a></li><li><input type=checkbox id=section-0590d23097cd9a656856c869f5eb6946 class=toggle>
<label for=section-0590d23097cd9a656856c869f5eb6946 class="flex justify-between"><a href=/docs/SE/hugo/>Hugo Tips</a></label><ul><li><a href=/docs/SE/hugo/book/>Hugo-book Theme</a></li><li><a href=/docs/SE/hugo/papermod/>PaperMod Theme</a></li></ul></li><li><a href=/docs/SE/git/>Git command Tips</a></li><li><a href=/docs/SE/pyenv/>Python with Pyenv</a></li><li><a href=/docs/SE/docker/>Docker</a></li><li><input type=checkbox id=section-772819a1dfe456a467414ffb423082ae class=toggle>
<label for=section-772819a1dfe456a467414ffb423082ae class="flex justify-between"><a href=/docs/SE/repo/>The Repo</a></label><ul><li><a href=/docs/SE/repo/VCS/>VCS</a></li><li><a href=/docs/SE/repo/REPO/>Repo</a></li></ul></li><li><input type=checkbox id=section-b5b586e1e415262ed46bc98d0a676fb3 class=toggle>
<label for=section-b5b586e1e415262ed46bc98d0a676fb3 class="flex justify-between"><a href=/docs/SE/CI/>Countinuous Integration</a></label><ul><li><a href=/docs/SE/CI/localbuild/>Local build</a></li><li><a href=/docs/SE/CI/PostCI/>Post CI</a></li><li><a href=/docs/SE/CI/Branch/>Branches</a></li><li><a href=/docs/SE/CI/Presubmit/>Presubmit</a></li><li><a href=/docs/SE/CI/CD/>Delivery & Deployment</a></li></ul></li><li><a href=/docs/SE/kaggle/>Data Science</a></li><li><a href=/docs/SE/Cursor/ class=active>Cursor</a></li><li><a href=/docs/SE/Obsidian/>Obsidian</a></li></ul></li><li class=book-section-flat><a href=/docs/ENG/>Eng.logging</a><ul><li><input type=checkbox id=section-5316120ef730e623d87facb7e14429fb class=toggle>
<label for=section-5316120ef730e623d87facb7e14429fb class="flex justify-between"><a href=/docs/ENG/daily/>Daily</a></label><ul><li><a href=/docs/ENG/daily/daily1/>Daily1</a></li></ul></li><li><a href=/docs/ENG/grammarly/>Grammarly</a><ul></ul></li></ul></li></ul><ul><li><a href=/posts/>Writing.logging</a></li><li><a href=https://github.com/smjune/ target=_blank rel=noopener>Github Repo</a></li><li><a href=https://gohugo.io/ target=_blank rel=noopener>Powered by Hugo</a></li><li><a href=https://themes.gohugo.io/hugo-book// target=_blank rel=noopener>and hugo-book</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label><h3>Cursor</h3><label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#llm-환경-구축-개요>LLM 환경 구축 개요</a><ul><li><a href=#1-cloud-llm-클라우드-기반-모델>1. Cloud LLM (클라우드 기반 모델)</a></li><li><a href=#2-open-llm--hub-오픈소스-모델과-허브>2. Open LLM & Hub (오픈소스 모델과 허브)</a></li><li><a href=#3-local-llm-launcher-로컬-실행-도구>3. Local LLM Launcher (로컬 실행 도구)</a></li><li><a href=#4-llm-지원-로컬-툴-개발-환경-연동>4. LLM 지원 로컬 툴 (개발 환경 연동)</a></li><li><a href=#5-mcp-model-context-protocol>5. MCP (Model Context Protocol)</a></li><li><a href=#6-agent>6. Agent</a></li></ul></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h2 id=llm-환경-구축-개요>LLM 환경 구축 개요
<a class=anchor href=#llm-%ed%99%98%ea%b2%bd-%ea%b5%ac%ec%b6%95-%ea%b0%9c%ec%9a%94>#</a></h2><p>이 문서는 다양한 LLM(Large Language Model)을 활용하여 로컬 개발 환경을 구축하는 데 필요한 도구와 기술을 소개합니다. Cloud LLM부터 로컬 실행 도구, 개발 환경 연동 도구까지 폭넓게 다룹니다.</p><h3 id=1-cloud-llm-클라우드-기반-모델>1. Cloud LLM (클라우드 기반 모델)
<a class=anchor href=#1-cloud-llm-%ed%81%b4%eb%9d%bc%ec%9a%b0%eb%93%9c-%ea%b8%b0%eb%b0%98-%eb%aa%a8%eb%8d%b8>#</a></h3><p>클라우드 서버에서 강력한 성능을 제공하는 상용 LLM입니다. API를 통해 접근하며, 고성능 추론 능력이 필요할 때 유용합니다.</p><ul><li><strong>GPT (OpenAI):</strong> <a href=https://platform.openai.com/docs/models>https://platform.openai.com/docs/models</a><ul><li><strong>주요 특징:</strong> 강력한 자연어 이해 및 생성 능력, 다양한 모델(GPT-4, GPT-4o 등) 제공, 광범위한 API 생태계.</li><li><strong>가격:</strong> 사용량 기반 유료 (API 호출당 과금), ChatGPT는 무료/유료 구독 플랜 제공.</li><li><strong>활용:</strong> 챗봇, 콘텐츠 생성, 코드 생성, 번역 등.</li></ul></li><li><strong>Gemini (Google):</strong> <a href=https://deepmind.google/technologies/gemini/>https://deepmind.google/technologies/gemini/</a><ul><li><strong>주요 특징:</strong> 멀티모달(텍스트, 이미지, 오디오, 비디오) 처리 능력, 다양한 크기(Ultra, Pro, Flash, Nano) 제공, Google 생태계 연동.</li><li><strong>가격:</strong> 사용량 기반 유료 (Vertex AI API), Google AI Studio 및 Gemini 앱에서 무료/유료 플랜 제공.</li><li><strong>활용:</strong> 멀티모달 콘텐츠 생성, 복잡한 추론, 데이터 분석, Google Workspace 연동.</li></ul></li><li><strong>Claude (Anthropic):</strong> <a href=https://www.anthropic.com/claude>https://www.anthropic.com/claude</a><ul><li><strong>주요 특징:</strong> 안전성 및 윤리성 강조(Constitutional AI), 긴 컨텍스트 처리 능력, 창의적 글쓰기 및 코딩 능력.</li><li><strong>가격:</strong> 사용량 기반 유료 (API), Claude.ai 웹사이트 및 앱에서 무료/유료 플랜 제공.</li><li><strong>활용:</strong> 긴 문서 요약/분석, 창의적 글쓰기, 안전한 대화형 AI 개발.</li></ul></li><li><strong>Grok (xAI):</strong> <a href=https://x.ai/grok>https://x.ai/grok</a><ul><li><strong>주요 특징:</strong> 실시간 정보 접근(X 플랫폼 연동), 유머러스하고 반항적인 페르소나, 최신 정보 기반 답변.</li><li><strong>가격:</strong> X Premium+ 구독 필요. API 접근은 별도 제공될 수 있음.</li><li><strong>활용:</strong> 최신 뉴스/트렌드 기반 질의응답, 특정 관점의 정보 탐색.</li></ul></li><li><strong>Perplexity:</strong> <a href=https://www.perplexity.ai/>https://www.perplexity.ai/</a><ul><li><strong>주요 특징:</strong> AI 기반 검색 엔진과 챗봇 기술 결합, GPT-4/Claude 3 등 최신 모델 활용, 실시간 웹 검색 및 Q&amp;A, 복잡한 추론을 위한 o13 시리즈 모델 제공.</li><li><strong>가격:</strong> 무료 플랜, Pro 구독(일 300회+ Pro 검색), Enterprise 플랜 제공.</li><li><strong>활용:</strong> 실시간 정보 검색/분석, 학술 연구, 코딩 문제 해결, 복잡한 추론 작업.</li><li><strong>차별점:</strong> 실시간 웹 검색 통합으로 최신 정보 제공(다른 LLM들의 학습 데이터 제한 극복), 모든 답변에 대한 출처 링크 제공으로 신뢰성 확보, 검색 엔진과 LLM의 하이브리드 접근으로 정확성 향상.</li></ul></li></ul><h3 id=2-open-llm--hub-오픈소스-모델과-허브>2. Open LLM & Hub (오픈소스 모델과 허브)
<a class=anchor href=#2-open-llm--hub-%ec%98%a4%ed%94%88%ec%86%8c%ec%8a%a4-%eb%aa%a8%eb%8d%b8%ea%b3%bc-%ed%97%88%eb%b8%8c>#</a></h3><ul><li><p><strong>대표적인 Open Source LLM:</strong></p><ul><li>Llama (Meta)<blockquote><ul><li>GPT-4.5, Claude 3.7 Sonnet 수준의 STEM 성능 달성</li><li>128k 토큰의 긴 컨텍스트 윈도우 지원</li><li>8개 언어 지원 및 강화된 안전성 기능 탑재</li></ul></blockquote></li><li>Mistral / Mixtral (Mistral AI)<blockquote><ul><li>Llama 2 70B 대비 6배 빠른 추론 속도와 더 높은 성능</li><li>코드 생성, 수학, 추론 능력에서 뛰어난 성능</li><li>140개 이상 언어 지원 및 고급 함수 호출 기능</li></ul></blockquote></li><li>Gemma (Google)<blockquote><ul><li>Gemini 기술 기반의 경량 오픈소스 모델</li><li>고해상도 비정사각형 이미지 처리 및 향상된 추론 능력</li><li>단일 GPU/TPU에서 실행 가능한 최고 성능 모델</li></ul></blockquote></li><li>Phi (Microsoft)<blockquote><ul><li>동일 크기 및 상위 크기 모델 대비 우수한 성능</li><li>20만 단어 어휘로 다국어 지원 강화</li><li>그룹 쿼리 어텐션, 내장 함수 호출 기능 제공</li></ul></blockquote></li><li>Qwen (Alibaba)<blockquote><ul><li>GPT-4o, DeepSeek-V3, Llama-3.1-405B 대비 우수한 성능</li><li>텍스트, 이미지, 오디오, 비디오 통합 처리 가능</li><li>32k 토큰 컨텍스트와 강화된 추론 능력</li></ul></blockquote></li></ul></li><li><p><strong>HuggingFace:</strong> <a href=https://huggingface.co/>https://huggingface.co/</a></p><p>오픈소스 LLM 모델과 데이터셋을 공유하고 협업하는 플랫폼입니다.</p><ul><li><strong>주요 특징:</strong> 방대한 모델/데이터셋 저장소(Hub), 모델 학습/추론 라이브러리(Transformers, Diffusers 등), 데모 공유(Spaces), LLM 리더보드, 학습 코스 제공.</li><li><strong>가격:</strong> 대부분 무료, 유료 플랜(추가 기능, 우선 지원 등) 제공.</li><li><strong>활용:</strong> 오픈소스 모델 탐색/다운로드, 모델 파인튜닝, AI 애플리케이션 개발/배포.</li></ul></li></ul><h3 id=3-local-llm-launcher-로컬-실행-도구>3. Local LLM Launcher (로컬 실행 도구)
<a class=anchor href=#3-local-llm-launcher-%eb%a1%9c%ec%bb%ac-%ec%8b%a4%ed%96%89-%eb%8f%84%ea%b5%ac>#</a></h3><p>로컬 컴퓨터 환경에서 LLM을 쉽게 다운로드하고 실행할 수 있도록 돕는 GUI/CLI 기반 도구입니다.</p><ul><li><p><strong>LM Studio:</strong> <a href=https://lmstudio.ai/>https://lmstudio.ai/</a></p><ul><li><strong>주요 특징:</strong> 사용자 친화적인 GUI, 모델 검색/다운로드/관리 용이, 다양한 모델 포맷 지원(GGUF 등), 내장 채팅 인터페이스 및 API 서버 기능.</li><li><strong>지원 모델:</strong> HuggingFace 등에서 제공되는 GGUF 포맷 모델 대부분.</li><li><strong>가격:</strong> 무료.</li><li><strong>설치:</strong> 웹사이트에서 OS별(Mac, Windows, Linux) 설치 파일 다운로드.</li></ul></li><li><p><strong>Ollama:</strong> <a href=https://ollama.com/>https://ollama.com/</a></p><ul><li><strong>주요 특징:</strong> CLI 중심의 간편한 모델 실행/관리, 자체 모델 라이브러리 운영, API 서버 기능 기본 제공, 다양한 커뮤니티 통합 지원.</li><li><strong>지원 모델:</strong> 자체 라이브러리 모델(Llama, Mistral, Gemma 등 다수) 및 GGUF 모델 임포트.</li><li><strong>가격:</strong> 무료.</li><li><strong>설치:</strong> 웹사이트에서 OS별(Mac, Windows, Linux) 설치 파일 다운로드 또는 CLI 명령어(<code>curl</code>, <code>brew</code> 등).</li></ul></li><li><p><strong>비교 요약 (Local LLM Launcher):</strong></p><table><thead><tr><th style=text-align:left>특징</th><th style=text-align:left>LM Studio</th><th style=text-align:left>Ollama</th></tr></thead><tbody><tr><td style=text-align:left><strong>인터페이스</strong></td><td style=text-align:left>GUI 중심 (채팅 포함)</td><td style=text-align:left>CLI 중심 (API 서버 주력)</td></tr><tr><td style=text-align:left><strong>모델 관리</strong></td><td style=text-align:left>GUI 내 검색/다운로드</td><td style=text-align:left>CLI 명령어 (<code>pull</code>, <code>run</code>)</td></tr><tr><td style=text-align:left><strong>주요 사용자층</strong></td><td style=text-align:left>초보자, GUI 선호 사용자</td><td style=text-align:left>개발자, CLI 선호 사용자</td></tr><tr><td style=text-align:left><strong>생태계</strong></td><td style=text-align:left>자체 기능 중심</td><td style=text-align:left>다양한 외부 도구 연동 활발</td></tr></tbody></table></li></ul><h3 id=4-llm-지원-로컬-툴-개발-환경-연동>4. LLM 지원 로컬 툴 (개발 환경 연동)
<a class=anchor href=#4-llm-%ec%a7%80%ec%9b%90-%eb%a1%9c%ec%bb%ac-%ed%88%b4-%ea%b0%9c%eb%b0%9c-%ed%99%98%ea%b2%bd-%ec%97%b0%eb%8f%99>#</a></h3><p>로컬 개발 환경(IDE, 텍스트 에디터 등) 내에서 LLM 기능을 활용할 수 있도록 돕는 도구들입니다.</p><ul><li>AI Code Editor : Cursor, Windsuf</li><li>AI Code Extension : Continue, Cline, Copilot, Gemini Code Assist</li></ul><ul><li>AI luncher : Claud Desk top, Witcy, Enconvo</li><li>Obsidian + AI community plug-in (SmartComposer, Copilot, &mldr;)</li></ul><h4 id=41-ai-code-editor-ai-네이티브-에디터>4.1 AI Code Editor (AI 네이티브 에디터)
<a class=anchor href=#41-ai-code-editor-ai-%eb%84%a4%ec%9d%b4%ed%8b%b0%eb%b8%8c-%ec%97%90%eb%94%94%ed%84%b0>#</a></h4><p>LLM 기능이 깊숙이 통합된 코드 에디터입니다.</p><ul><li><p><strong>Cursor:</strong> <a href=https://www.cursor.com/en>https://www.cursor.com/en</a></p><ul><li><strong>주요 특징:</strong> VS Code 기반, AI 기반 코드 생성/편집/리팩토링, &ldquo;Codebase-aware&rdquo; 채팅, 로컬 모델 연동 지원(설정 필요).</li><li><strong>지원 모델:</strong> OpenAI 모델(기본), Anthropic 모델, Azure OpenAI, 로컬 모델(Ollama, LM Studio 등 연동).</li><li><strong>가격:</strong> 무료 플랜(제한적 사용), 유료 Pro/Business 플랜.</li><li><strong>설치:</strong> 웹사이트에서 OS별 설치 파일 다운로드.</li><li><a href=https://forum.cursor.com>Cursor 커뮤니티</a>,<a href=https://cursor.directory>Cursor MCP, Rule &mldr;</a></li><li>활용예시 : cursor + git + obsidian
<img src=./cursor.png alt="cursor 활용"></li></ul></li><li><p><strong>Windsurf:</strong> <a href=https://codeium.com/windsurf>https://codeium.com/windsurf</a></p><ul><li><strong>주요 특징:</strong> Codeium 개발, 빠른 자동 완성, Context Engine 기반 이해, 다중 파일 편집 지원, 경량화 추구.</li><li><strong>지원 모델:</strong> Codeium 자체 모델, 로컬 모델 연동 지원 논의 중/개발 중.</li><li><strong>가격:</strong> 현재 무료 (베타 기간 등 정책 변동 가능).</li><li><strong>설치:</strong> 웹사이트에서 OS별 설치 파일 다운로드.</li></ul></li><li><p><strong>비교 요약 (Code Editor):</strong></p><table><thead><tr><th style=text-align:left>특징</th><th style=text-align:left>Cursor</th><th style=text-align:left>Windsurf (Codeium)</th></tr></thead><tbody><tr><td style=text-align:left><strong>기반</strong></td><td style=text-align:left>VS Code Fork</td><td style=text-align:left>자체 개발 (경량화)</td></tr><tr><td style=text-align:left><strong>핵심 기능</strong></td><td style=text-align:left>코드베이스 이해, 채팅 중심</td><td style=text-align:left>빠른 자동완성, 컨텍스트 엔진</td></tr><tr><td style=text-align:left><strong>로컬 모델</strong></td><td style=text-align:left>지원 (Ollama, LM Studio 등)</td><td style=text-align:left>제한적/개발 중</td></tr><tr><td style=text-align:left><strong>가격</strong></td><td style=text-align:left>무료/유료 플랜</td><td style=text-align:left>현재 무료</td></tr></tbody></table></li></ul><h4 id=42-extension-plug-in-ide-확장-기능>4.2 Extension, Plug-in (IDE 확장 기능)
<a class=anchor href=#42-extension-plug-in-ide-%ed%99%95%ec%9e%a5-%ea%b8%b0%eb%8a%a5>#</a></h4><p>기존 IDE(VScode)에 설치하여 LLM 기능을 추가하는 확장 프로그램입니다.</p><ul><li><p><strong>Continue:</strong> <a href=https://www.continue.dev/>https://www.continue.dev/</a></p><ul><li><strong>주요 특징:</strong> 오픈소스, 다양한 모델(로컬/클라우드) 연결 유연성, 사용자 정의 컨텍스트 제공(파일, 터미널 등), 자동 완성 및 채팅.</li><li><strong>지원 모델:</strong> OpenAI, Anthropic, Google, Mistral, Ollama, LM Studio 등 다수.</li><li><strong>가격:</strong> 무료 (오픈소스).</li><li><strong>설치:</strong> VS Code, JetBrains 마켓플레이스에서 설치.</li></ul></li><li><p><strong>Cline:</strong> <a href=https://cline.bot/>https://cline.bot/</a></p><ul><li><strong>주요 특징:</strong> 오픈소스, 자율 코딩 에이전트 지향, Plan/Act 모드, 터미널 실행, MCP(Model Context Protocol) 지원.</li><li><strong>지원 모델:</strong> OpenAI, Anthropic, Google, Ollama, LM Studio 등 다수.</li><li><strong>가격:</strong> 무료 (오픈소스).</li><li><strong>설치:</strong> VS Code 마켓플레이스에서 설치.</li></ul></li><li><p><strong>GitHub Copilot:</strong> <a href=https://github.com/features/copilot>https://github.com/features/copilot</a></p><ul><li><strong>주요 특징:</strong> GitHub/OpenAI 개발, 강력한 코드 자동 완성 및 제안, 채팅 기능(Copilot Chat), 광범위한 언어/IDE 지원.</li><li><strong>지원 모델:</strong> OpenAI 모델(GPT 기반).</li><li><strong>가격:</strong> 유료 구독 (개인/비즈니스), 학생/오픈소스 기여자 무료.</li><li><strong>설치:</strong> 각 IDE 마켓플레이스에서 설치 (VS Code, JetBrains 등).</li></ul></li><li><p><strong>Gemini Code Assist:</strong> <a href=https://developers.google.com/gemini-code-assist>https://developers.google.com/gemini-code-assist</a></p><ul><li><strong>주요 특징:</strong> Google 개발, 코드 자동 완성, 디버깅 지원, 프로그래밍 개념 학습 지원, GitHub 통합</li><li><strong>지원 모델:</strong> Google Gemini</li><li><strong>가격:</strong> 개인 사용자 무료, 기업용 Standard/Enterprise 버전 유료</li><li><strong>설치:</strong> VS Code, JetBrains IDE, Cloud Shell Editor에서 설치 가능</li></ul></li><li><p><strong>비교 요약 (Extension, Plug-in):</strong></p><table><thead><tr><th style=text-align:left>특징</th><th style=text-align:left>Continue</th><th style=text-align:left>Cline</th><th style=text-align:left>GitHub Copilot</th><th style=text-align:left>Gemini Code Assist</th></tr></thead><tbody><tr><td style=text-align:left><strong>개발 주체</strong></td><td style=text-align:left>커뮤니티 (오픈소스)</td><td style=text-align:left>커뮤니티 (오픈소스)</td><td style=text-align:left>GitHub/OpenAI</td><td style=text-align:left>Google</td></tr><tr><td style=text-align:left><strong>핵심 기능</strong></td><td style=text-align:left>모델 유연성, 컨텍스트</td><td style=text-align:left>자율 에이전트, MCP</td><td style=text-align:left>코드 완성, 채팅</td><td style=text-align:left>코드 완성, 디버깅, 학습</td></tr><tr><td style=text-align:left><strong>로컬 모델 지원</strong></td><td style=text-align:left>매우 우수 (Ollama 등)</td><td style=text-align:left>매우 우수 (Ollama 등)</td><td style=text-align:left>제한적/미지원</td><td style=text-align:left>미지원</td></tr><tr><td style=text-align:left><strong>가격</strong></td><td style=text-align:left>무료</td><td style=text-align:left>무료</td><td style=text-align:left>유료 (일부 무료)</td><td style=text-align:left>무료 (기업용 유료)</td></tr></tbody></table></li><li><p><strong>활용 예시:</strong></p><ul><li><code>Ollama</code> 또는 <code>LM Studio</code>를 사용하여 로컬에 <code>Llama 3</code> 모델을 실행시킨 후, <code>Continue</code> 또는 <code>Cline</code> 확장 프로그램을 통해 VS Code에서 해당 로컬 모델을 코드 생성 및 분석에 활용할 수 있습니다. 이를 통해 민감한 코드를 외부로 전송하지 않고 AI 지원을 받을 수 있습니다.</li></ul></li></ul><h4 id=43-ai-launcher-데스크톱-애플리케이션>4.3 AI launcher (데스크톱 애플리케이션)
<a class=anchor href=#43-ai-launcher-%eb%8d%b0%ec%8a%a4%ed%81%ac%ed%86%b1-%ec%95%a0%ed%94%8c%eb%a6%ac%ec%bc%80%ec%9d%b4%ec%85%98>#</a></h4><p>독립적으로 실행되는 LLM 관련 데스크톱 애플리케이션입니다.</p><ul><li><p><strong>Claude desktop:</strong> <a href=https://claude.ai/download>https://claude.ai/download</a></p><ul><li><strong>주요 특징:</strong> Anthropic의 Claude 모델 공식 데스크톱 앱, 웹 버전 기능 대부분 제공, 파일 업로드 및 분석 용이, MCP 지원.</li><li><strong>지원 모델:</strong> Claude 모델.</li><li><strong>가격:</strong> 웹 버전과 동일 (무료/유료 플랜).</li><li><strong>설치:</strong> 웹사이트에서 OS(Mac, Windows)별 설치 파일 다운로드.</li></ul></li><li><p><strong>Witsy:</strong> <a href=https://witsyai.com/>https://witsyai.com/</a></p><ul><li><strong>주요 특징:</strong> 다양한 LLM API 키 등록(BYOK) 방식, 채팅, 이미지 생성, 프롬프트 라이브러리, &lsquo;Prompt Anywhere&rsquo; 기능.</li><li><strong>지원 모델:</strong> OpenAI, Anthropic, Google, Mistral, Ollama 등 다수 API/로컬 모델 연동.</li><li><strong>가격:</strong> 무료/유료 플랜.</li><li><strong>설치:</strong> 웹사이트에서 OS(Mac, Windows, Linux)별 설치 파일 다운로드.</li></ul></li><li><p><strong>Enconvo:</strong> <a href=https://www.enconvo.ai/>https://www.enconvo.ai/</a></p><ul><li><strong>주요 특징:</strong> macOS용 AI 에이전트 런처, 150개 이상 내장 도구, 워크플로우 자동화, MCP 지원.</li><li><strong>지원 모델:</strong> OpenAI, Anthropic 등 Cloud LLM 및 로컬 모델 연동.</li><li><strong>가격:</strong> 유료 구독.</li><li><strong>설치:</strong> 웹사이트에서 macOS 설치 파일 다운로드.</li></ul></li><li><p><strong>비교 요약 (Desktop tools):</strong></p><table><thead><tr><th style=text-align:left>특징</th><th style=text-align:left>Claude desktop</th><th style=text-align:left>Witsy</th><th style=text-align:left>Enconvo</th></tr></thead><tbody><tr><td style=text-align:left><strong>주요 기능</strong></td><td style=text-align:left>Claude 모델 접근</td><td style=text-align:left>다중 LLM 통합, 유틸리티</td><td style=text-align:left>워크플로우 자동화 (macOS)</td></tr><tr><td style=text-align:left><strong>개발 주체</strong></td><td style=text-align:left>Anthropic</td><td style=text-align:left>개인/팀 개발</td><td style=text-align:left>개인/팀 개발</td></tr><tr><td style=text-align:left><strong>플랫폼</strong></td><td style=text-align:left>Mac, Windows</td><td style=text-align:left>Mac, Windows, Linux</td><td style=text-align:left>macOS</td></tr><tr><td style=text-align:left><strong>가격</strong></td><td style=text-align:left>무료/유료 플랜</td><td style=text-align:left>무료/유료 플랜</td><td style=text-align:left>유료 구독</td></tr></tbody></table></li></ul><h3 id=5-mcp-model-context-protocol>5. MCP (Model Context Protocol)
<a class=anchor href=#5-mcp-model-context-protocol>#</a></h3><p>애플리케이션과 AI 모델 간의 컨텍스트 정보 교환을 표준화하는 개방형 프로토콜입니다.</p><ul><li><strong>주요 특징:</strong> LLM이 외부 도구/데이터 소스와 안전하고 표준화된 방식으로 상호작용하도록 지원, 개발 생산성 향상, 도구 간 상호 운용성 증대.</li><li><strong>활용:</strong> AI 에이전트 개발, 외부 API 연동, 코드베이스/데이터베이스 접근 등.</li><li><strong>관련 도구:</strong> Cline, Claude desktop, Enconvo 등 MCP를 지원하는 클라이언트/서버 구현체 다수 존재.</li><li><strong>공식 사이트:</strong> <a href=https://modelcontextprotocol.io/>https://modelcontextprotocol.io/</a></li><li><strong>서버 목록 (GitHub):</strong> <a href=https://github.com/modelcontextprotocol/servers>https://github.com/modelcontextprotocol/servers</a></li><li><strong>서버 레지스트리:</strong> <a href=https://mcp-get.com/>https://mcp-get.com/</a>, <a href=https://smithery.ai>https://smithery.ai</a></li></ul><h3 id=6-agent>6. Agent
<a class=anchor href=#6-agent>#</a></h3><blockquote><p>An AI agent is a system that uses an LLM to decide the control flow of an application.
<a href=https://blog.langchain.dev/what-is-an-agent/>내용출처</a></p></blockquote><p>There are many frameworks that make agentic systems easier to implement, including:</p><ul><li><a href=https://langchain-ai.github.io/langgraph/>LangGraph</a> from LangChain;</li><li>Amazon Bedrock&rsquo;s <a href=https://aws.amazon.com/bedrock/agents/>AI Agent framework</a>;</li><li><a href=https://rivet.ironcladapp.com/>Rivet</a>, a drag and drop GUI LLM workflow builder; and</li><li><a href=https://www.vellum.ai/>Vellum</a>, another GUI tool for building and testing complex workflows.
<a href=https://www.anthropic.com/engineering/building-effective-agents>내용 출처</a></li></ul><p>Workflow(Chain) vs Agent</p><p><img src=chainagent.png alt="Chain vs Agent">
<a href=https://python.langchain.com/v0.1/docs/use_cases/tool_use/>이미지 출처</a></p><hr><p>이 문서는 계속 업데이트될 수 있습니다.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/smjune/smjune.github.io/commit/c964fce901a878ed4e360b5806e6a7600f5b4a8a title='Last modified by 성명준 | April 25, 2025' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt>
<span>April 25, 2025</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments><script src=https://giscus.app/client.js data-repo=smjune/smjune.github.io data-repo-id=R_kgDOI5LWbA data-category="Show and tell" data-category-id=DIC_kwDOI5LWbM4CUfYm data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#llm-환경-구축-개요>LLM 환경 구축 개요</a><ul><li><a href=#1-cloud-llm-클라우드-기반-모델>1. Cloud LLM (클라우드 기반 모델)</a></li><li><a href=#2-open-llm--hub-오픈소스-모델과-허브>2. Open LLM & Hub (오픈소스 모델과 허브)</a></li><li><a href=#3-local-llm-launcher-로컬-실행-도구>3. Local LLM Launcher (로컬 실행 도구)</a></li><li><a href=#4-llm-지원-로컬-툴-개발-환경-연동>4. LLM 지원 로컬 툴 (개발 환경 연동)</a></li><li><a href=#5-mcp-model-context-protocol>5. MCP (Model Context Protocol)</a></li><li><a href=#6-agent>6. Agent</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>